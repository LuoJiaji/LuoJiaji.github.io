[{"title":"用Python搭建一个简易的深度学习相机","date":"2017-12-22T05:07:58.000Z","path":"2017/12/22/用Python搭建一个简易的深度学习相机/","text":"本片博客介绍了一个基于树莓派和YOLO框架的智能相机的制作过程。原文见参考资料[1] 亚马逊刚刚发布了DeepLens，这是一款智能网络摄像头，它利用机器学习来检测物体、人脸以及一些活动。DeepLens还没有上市，但智能相机的想法令人兴奋。今天，我们将搭建一个深度学习摄像头，它可以探测到在网络摄像头图像中出现的鸟类，然后保存这只鸟的照片。最终的结果是这样的: 深度学习相机是一个全新的机器学习平台的开始。DeepLens的计算能力有100GFlops的计算能力，这只是一个有趣的深度学习相机计算机所必需的计算能力的开始。在未来，这些设备将变得更加强大，并具有每秒推断数百张图像的能力。但是谁愿意等待未来呢? 傻瓜相机和智能推理我们会使用一个简易计算机(比如9美元的树莓派)，把它连接到网络摄像头，然后通过WiFi发送图像，而不是在我们的相机中直接建立一个深度学习模型。在一定延迟的情况下，我们可以构建一个和Deeplens高年相似的原型，而且更加便宜。所以在今天的博客，我们就这么做。们用Python编写一个web服务器，将图像从树莓派发送到另一台计算机进行推理或图像检测。 另一台拥有更多处理能力的计算机将使用一种名为YOLO的神经网络架构来对输入图像进行检测，并判断是否有一只鸟在摄像机的图片内。我们将从YOLO框架开始，因为它是最快速的检测模型之一。模型的端口是基于Tensorflow，因此很容易安装和运行在许多不同的平台上。另外，如果你使用我们在这篇文章中使用的精简模型，你也可以在CPU上进行检测，无需昂贵的GPU。回到我们的原型中。如果在相机的图像中发现了一只鸟，我们将保存这张照片以便以后进行分析。这只是一个真正智能的深度学习相机的开始，非常基础。现在就开始着手做第一个版本的原型。 检测与成像 正如我们已经说过的，DeepLens的成像被植入了计算机。因此它可以进行基础水平检测，并通过自带的计算能力来确定这些图像是否符合你的标准。但是，像树莓派这样的处理器，它的计算能力无法做到实时检测。因此，我们将使用另一台计算机来推断图像。在这个例子中，使用了一个简单的Linux计算机，它带有一个摄像头和wifi接入(树莓派3和一个便宜的网络摄像头)，并服务于用于图像推断的深度学习计算机。这是一个很好的方案，因为它允许在野外使用许多便宜的相机，并且在同一个地方的台式机上进行计算。 摄像头图像处理方案如果你不想使用树莓派的摄像头，同样可以在树莓派上安装OpenCV 3。作为旁注，我必须禁用CAROTENE的编译，以便在我的树莓派上获得3.3.1。你可能需要做同样的事情。完成之后，我们只需要安装Flask的web服务器，这样我们就可以从网络摄像头中加载图像了。使用了Miguel Grinberg的优秀网络摄像头服务器代码作为基础，并创建了一个简单的jpg端点，而不是一个动态的jpeg端点:1234567891011121314151617181920212223242526272829#!/usr/bin/env pythonfrom importlib import import_moduleimport osfrom flask import Flask, render_template, Response# uncomment below to use Raspberry Pi camera instead# from camera_pi import Camera# comment this out if you're not using USB webcamfrom camera_opencv import Cameraapp = Flask(__name__)@app.route('/')def index(): return \"hello world!\"def gen2(camera): \"\"\"Returns a single image frame\"\"\" frame = camera.get_frame() yield frame@app.route('/image.jpg')def image(): \"\"\"Returns a single current image for the webcam\"\"\" return Response(gen2(Camera()), mimetype='image/jpeg')if __name__ == '__main__': app.run(host='0.0.0.0', threaded=True) 如果你想要使用树莓派的视频摄像头，请确确保使用from camera_pi代码。并且注释掉from camera_opencv你可以通过python3 app.py来运行程序，或者使用gunicorn，就像Miguel Grinberg的文章中提到的那样。它只是利用米格尔的出色的相机管理来关闭摄像头，当没有请求的时候，它还可以管理线程，如果我们有不止一台机器对来自网络摄像头的图像进行推断的话。一旦我们在树莓派上启动它，我们就可以测试并确保服务器首先发现它的IP地址，然后尝试通过我们的web浏览器来实现它。URL应该类似于http://192.168.1.4:5000 image.jpg: 从相机服务器中提取图像并进行推断现在我们已经有了一个端点来加载网络摄像头的当前图像，我们可以构建脚本来获取并运行这些图像的推断。我们将使用requests模块，一个伟大的Python库，用于从url中抓取文件；以及Darkflow，在Tensorflow上实现的YOLO模型。不幸的是，不能通过pip来安装Darkflow，所以我们需要复制代码到本地，然后在本地编译和安装，并进行图像的检测和推理。在安装了Darkflow之后，我们还需要下载我们将要使用的YOLO版本的权重和模型。在这个例子中，使用了YOLO v2微型网络，因为我想在一台较慢的计算机上运行我的检测和推理的程序，使用CPU，而不是GPU。这个微小的网络与完整的YOLO v2模型相比，它的精度要低一些。此外，我们还需要在检测计算机上安装Pillow、numpy和OpenCV模块。最后，可以编写代码来运行探测程序了:12345678910111213141516171819202122232425262728293031from darkflow.net.build import TFNetimport cv2from io import BytesIOimport timeimport requestsfrom PIL import Imageimport numpy as npoptions = &#123;\"model\": \"cfg/tiny-yolo-voc.cfg\", \"load\": \"bin/tiny-yolo-voc.weights\", \"threshold\": 0.1&#125;tfnet = TFNet(options)birdsSeen = 0def handleBird(): passwhile True: r = requests.get('http://192.168.1.11:5000/image.jpg') # a bird yo curr_img = Image.open(BytesIO(r.content)) curr_img_cv2 = cv2.cvtColor(np.array(curr_img), cv2.COLOR_RGB2BGR) result = tfnet.return_predict(curr_img_cv2) print(result) for detection in result: if detection['label'] == 'bird': print(\"bird detected\") birdsSeen += 1 curr_img.save('birds/%i.jpg' % birdsSeen) print('running again') time.sleep(4) 到此，我们就有了一个非常基本的第一版图片检测的代码。我们可以在控制台看到树莓派的检测，我们也可以看到每一个被看到的鸟类被保存在我们的硬盘上。之后，我们可以运行一个程序来对YOLO已经检测到的鸟类的图像进行标记。 调整参数需要注意的一点是，我们创建的选项字典中的阈值键。这个阈值表示我们需要检测的物体的置信度。出于测试的目的，我将它设置为0.1。但是这个门槛的低会给我们带来很多错误的信息。更糟糕的是，我们用于检测的精简YOLO模型比真正的YOLO模型的准确度要低一些，因此我们将会有一些错误的检测。降低或提高阈值可以提高或降低模型的总输出，这取决于想要构建的内容。在这个例子中，倾向于更多的假阳性结果，更喜欢得到更多的鸟的图片而不是更少的。可以根据需要调整这些参数以满足特定的需要。 等待检测结果让鸟飞到鸟食器里花了很长时间。我想我在后院放了几只鸟，在几小时内把食物放出来。相反，它花了几天时间。松鼠一直在吃我不吃的食物，在最初的几天里，我几乎没有看到天空中有一只鸟。最后，把二只鸟喂食器放在一个更加显眼的地方。通过这个，我终于得到了一些图片，就像在文章开头的那些图片一样。 下一步这篇文章的代码同样可以在Github上获得。这篇文章是一系列课程的开始，我将使用深度学习相机尝试与鸟类互动。 参考资料: Building a Deep Learning Camera with a Raspberry Pi and YOLO","tags":[{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"TesorFlow","slug":"TesorFlow","permalink":"http://luojiaji.github.io/tags/TesorFlow/"}]},{"title":"Python实现GAN对抗网络","date":"2017-10-28T11:18:22.000Z","path":"2017/10/28/Python实现GAN对抗网络/","text":"GAN（对抗生成网络：Generative Adversarial Networks）是一类无监督学习的神经网络模型。生成对抗网络是目前一种非常受欢迎的网络模型，它最早在NIPS 2014 paper by Ian Goodfellow, et al中被提到，之后又出现了许多GAN的改进版本：DCGAN，Sequence-GAN, LSTM-GAN。 在GAN中第一个网路叫做生成网络$G(Z)$，第二个网络叫做鉴别网络$D(X)$ $$\\min _G \\max _D V(D,G) =\\mathbb E _{x \\sim p _{data}(x)}[\\log D(x)] + \\mathbb E _{x \\sim p _x(x)}[log(1-D(G(z)))]$$ GAN实现：根据GAN的定义，需要两个网络模型。这可以是任何形式，可以是像卷积网络一样复杂的网络模型，也可以是简单的两层神经网络。这里使用两层的神经网络：1234567891011121314151617181920212223242526272829303132333435# Discriminator NetX = tf.placeholder(tf.float32, shape=[None, 784], name='X')D_W1 = tf.Variable(xavier_init([784, 128]), name='D_W1')D_b1 = tf.Variable(tf.zeros(shape=[128]), name='D_b1')D_W2 = tf.Variable(xavier_init([128, 1]), name='D_W2')D_b2 = tf.Variable(tf.zeros(shape=[1]), name='D_b2')theta_D = [D_W1, D_W2, D_b1, D_b2]# Generator NetZ = tf.placeholder(tf.float32, shape=[None, 100], name='Z')G_W1 = tf.Variable(xavier_init([100, 128]), name='G_W1')G_b1 = tf.Variable(tf.zeros(shape=[128]), name='G_b1')G_W2 = tf.Variable(xavier_init([128, 784]), name='G_W2')G_b2 = tf.Variable(tf.zeros(shape=[784]), name='G_b2')theta_G = [G_W1, G_W2, G_b1, G_b2]def generator(z): G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1) G_log_prob = tf.matmul(G_h1, G_W2) + G_b2 G_prob = tf.nn.sigmoid(G_log_prob) return G_probdef discriminator(x): D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1) D_logit = tf.matmul(D_h1, D_W2) + D_b2 D_prob = tf.nn.sigmoid(D_logit) return D_prob, D_logit 代码中generator(z)输入100维的向量，并返回784维的向量，表示MNIST数据（28x28），z是$G(Z)$的先验。discriminator(x)输入MNIST图片并返回表示真实MNIST图片的可能性。 然后声明GAN的训练过程。论文中的训练算法如下： 代码实现如下：123456G_sample = generator(Z)D_real, D_logit_real = discriminator(X)D_fake, D_logit_fake = discriminator(G_sample)D_loss = -tf.reduce_mean(tf.log(D_real) + tf.log(1. - D_fake))G_loss = -tf.reduce_mean(tf.log(D_fake)) 损失函数加符号是因为公式来计算最大值，然而TensorFlow中优化器只能计算最小值。 然后根据上面的损失函数来训练对抗网络：1234567891011121314# Only update D(X)'s parameters, so var_list = theta_DD_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)# Only update G(X)'s parameters, so var_list = theta_GG_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)def sample_Z(m, n): '''Uniform prior for G(Z)''' return np.random.uniform(-1., 1., size=[m, n])for it in range(1000000): X_mb, _ = mnist.train.next_batch(mb_size) _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict=&#123;X: X_mb, Z: sample_Z(mb_size, Z_dim)&#125;) _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict=&#123;Z: sample_Z(mb_size, Z_dim)&#125;) 最后得到结果： GAN training 参考资料： Generative Adversarial Nets in TensorFlow","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"GAN","slug":"GAN","permalink":"http://luojiaji.github.io/tags/GAN/"}]},{"title":"科比职业生涯投篮数据分析","date":"2017-09-24T11:44:34.000Z","path":"2017/09/24/科比职业生涯投篮数据分析/","text":"今天这篇文章主要是通过Python对科比职业生涯的投篮数据进行分析。原文数据 本文将探索科比职业生涯的出手数据，并观察是否有热手效应。 首先导入需要用到的库 123456789101112import pandas as pdimport numpy as npimport matplotlib.pyplot as pltfrom matplotlib.patches import Circle, Rectangle, Arc, Ellipsefrom sklearn import mixturefrom sklearn import ensemblefrom sklearn import model_selectionfrom sklearn.metrics import accuracy_score as accuracyfrom sklearn.metrics import log_lossimport timeimport itertoolsimport operator 然后导入数据并创建一些有效的字段。 1234567891011121314allData = pd.read_csv('data.csv')data = allData[allData['shot_made_flag'].notnull()].reset_index()#%% add some temporal columns to the datadata['game_date_DT'] = pd.to_datetime(data['game_date'])data['dayOfWeek'] = data['game_date_DT'].dt.dayofweekdata['dayOfYear'] = data['game_date_DT'].dt.dayofyeardata['secondsFromPeriodEnd'] = 60*data['minutes_remaining']+data['seconds_remaining']data['secondsFromPeriodStart'] = 60*(11-data['minutes_remaining'])+(60-data['seconds_remaining'])data['secondsFromGameStart'] = (data['period'] &lt;= 4).astype(int)*(data['period']-1)*12*60 + (data['period'] &gt; 4).astype(int)*((data['period']-4)*5*60 + 3*12*60) + data['secondsFromPeriodStart']# look at first couple of rows and verify that everything is goodprint(data.loc[:10,['period','minutes_remaining','seconds_remaining','secondsFromGameStart']]) 上面的代码主要计算了一下剩余比赛的时间以及开始时间。allData[&#39;shot_made_flag&#39;].notnull()去除shot_made_flag这一列数据的非空数据。 下面绘制根据比赛时间的出手次数的图。时间间隔分别是24秒，12秒，6秒。 123456789101112131415161718192021plt.rcParams['figure.figsize'] = (16, 16)plt.rcParams['font.size'] = 8binsSizes = [24, 12, 6]plt.figure()for k, binSizeInSeconds in enumerate(binsSizes): timeBins = np.arange(0, 60 * (4 * 12 + 3 * 5), binSizeInSeconds) + 0.01 attemptsAsFunctionOfTime, b = np.histogram(data['secondsFromGameStart'], bins=timeBins) maxHeight = max(attemptsAsFunctionOfTime) + 30 barWidth = 0.999 * (timeBins[1] - timeBins[0]) plt.subplot(len(binsSizes), 1, k + 1); plt.bar(timeBins[:-1], attemptsAsFunctionOfTime, align='edge', width=barWidth) plt.title(str(binSizeInSeconds) + ' second time bins') plt.vlines(x=[0, 12 * 60, 2 * 12 * 60, 3 * 12 * 60, 4 * 12 * 60, 4 * 12 * 60 + 5 * 60, 4 * 12 * 60 + 2 * 5 * 60,4 * 12 * 60 + 3 * 5 * 60], ymin=0, ymax=maxHeight, colors='r') plt.xlim((-20, 3200)) plt.ylim((0, maxHeight)) plt.ylabel('attempts')plt.xlabel('time [seconds from start of game]')plt.show() 其中np.histogram(data[&#39;secondsFromGameStart&#39;], bins=timeBins)以timeBins为间隔统计secondsFromGameStart这一列的直方图。 得到结果如下： 然后根据比赛时间计算并绘制投篮命中率的图，时间间隔为20s：123456789101112131415161718192021222324#%% plot the accuracy as a function of timeplt.rcParams['figure.figsize'] = (15, 10)plt.rcParams['font.size'] = 16binSizeInSeconds = 20timeBins = np.arange(0,60*(4*12+3*5),binSizeInSeconds)+0.01attemptsAsFunctionOfTime, b = np.histogram(data['secondsFromGameStart'], bins=timeBins)madeAttemptsAsFunctionOfTime, b = np.histogram(data.loc[data['shot_made_flag']==1,'secondsFromGameStart'], bins=timeBins)attemptsAsFunctionOfTime[attemptsAsFunctionOfTime &lt; 1] = 1accuracyAsFunctionOfTime = madeAttemptsAsFunctionOfTime.astype(float)/attemptsAsFunctionOfTimeaccuracyAsFunctionOfTime[attemptsAsFunctionOfTime &lt;= 50] = 0 # zero accuracy in bins that don't have enough samplesmaxHeight = max(attemptsAsFunctionOfTime) + 30barWidth = 0.999*(timeBins[1]-timeBins[0])plt.figure()plt.subplot(2,1,1); plt.bar(timeBins[:-1],attemptsAsFunctionOfTime, align='edge', width=barWidth)plt.xlim((-20,3200)); plt.ylim((0,maxHeight)); plt.ylabel('attempts'); plt.title(str(binSizeInSeconds) + ' second time bins')plt.vlines(x=[0,12*60,2*12*60,3*12*60,4*12*60,4*12*60+5*60,4*12*60+2*5*60,4*12*60+3*5*60], ymin=0,ymax=maxHeight, colors='r')plt.subplot(2,1,2); plt.bar(timeBins[:-1],accuracyAsFunctionOfTime, align='edge', width=barWidth)plt.xlim((-20,3200)); plt.ylabel('accuracy'); plt.xlabel('time [seconds from start of game]')plt.vlines(x=[0,12*60,2*12*60,3*12*60,4*12*60,4*12*60+5*60,4*12*60+2*5*60,4*12*60+3*5*60], ymin=0.0,ymax=0.7, colors='r')plt.show() 代码的第7,8行分别计算根据比赛时间的投篮次数和命中次数的直方图。并根据这两个数据计算命中率并绘图。 然后探索位置对科比投篮的影响。首先建立一个高斯混合模型（GMM）来总结科比的投篮区域分布。将投篮区域分为13个区域。 12345678#%% cluster the shot attempts of kobe using GMM on their locationnumGaussians = 13gaussianMixtureModel = mixture.GaussianMixture(n_components=numGaussians,covariance_type='full', init_params='kmeans', n_init=50,verbose=0, random_state=5)gaussianMixtureModel.fit(data.loc[:,['loc_x','loc_y']])# add the GMM cluster as a field in the datasetdata['shotLocationCluster'] = gaussianMixtureModel.predict(data.loc[:,['loc_x','loc_y']]) 然后定义两个函数，一个用来绘制篮球场，一个用来绘制高斯数据。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#%% cluster the shot attempts of kobe using GMM on their locationnumGaussians = 13gaussianMixtureModel = mixture.GaussianMixture(n_components=numGaussians, covariance_type='full', init_params='kmeans', n_init=50, verbose=0, random_state=5)gaussianMixtureModel.fit(data.loc[:,['loc_x','loc_y']])# add the GMM cluster as a field in the datasetdata['shotLocationCluster'] = gaussianMixtureModel.predict(data.loc[:,['loc_x','loc_y']])# %% define draw functions (stealing shamelessly the draw_court() function from MichaelKrueger's excelent script)def draw_court(ax=None, color='black', lw=2, outer_lines=False): # If an axes object isn't provided to plot onto, just get current one if ax is None: ax = plt.gca() # Create the various parts of an NBA basketball court # Create the basketball hoop # Diameter of a hoop is 18\" so it has a radius of 9\", which is a value # 7.5 in our coordinate system hoop = Circle((0, 0), radius=7.5, linewidth=lw, color=color, fill=False) # Create backboard backboard = Rectangle((-30, -7.5), 60, -1, linewidth=lw, color=color) # The paint # Create the outer box 0f the paint, width=16ft, height=19ft outer_box = Rectangle((-80, -47.5), 160, 190, linewidth=lw, color=color, fill=False) # Create the inner box of the paint, widt=12ft, height=19ft inner_box = Rectangle((-60, -47.5), 120, 190, linewidth=lw, color=color, fill=False) # Create free throw top arc top_free_throw = Arc((0, 142.5), 120, 120, theta1=0, theta2=180, linewidth=lw, color=color, fill=False) # Create free throw bottom arc bottom_free_throw = Arc((0, 142.5), 120, 120, theta1=180, theta2=0, linewidth=lw, color=color, linestyle='dashed') # Restricted Zone, it is an arc with 4ft radius from center of the hoop restricted = Arc((0, 0), 80, 80, theta1=0, theta2=180, linewidth=lw, color=color) # Three point line # Create the side 3pt lines, they are 14ft long before they begin to arc corner_three_a = Rectangle((-220, -47.5), 0, 140, linewidth=lw, color=color) corner_three_b = Rectangle((220, -47.5), 0, 140, linewidth=lw, color=color) # 3pt arc - center of arc will be the hoop, arc is 23'9\" away from hoop # I just played around with the theta values until they lined up with the # threes three_arc = Arc((0, 0), 475, 475, theta1=22, theta2=158, linewidth=lw, color=color) # Center Court center_outer_arc = Arc((0, 422.5), 120, 120, theta1=180, theta2=0, linewidth=lw, color=color) center_inner_arc = Arc((0, 422.5), 40, 40, theta1=180, theta2=0, linewidth=lw, color=color) # List of the court elements to be plotted onto the axes court_elements = [hoop, backboard, outer_box, inner_box, top_free_throw, bottom_free_throw, restricted, corner_three_a, corner_three_b, three_arc, center_outer_arc, center_inner_arc] if outer_lines: # Draw the half court line, baseline and side out bound lines outer_lines = Rectangle((-250, -47.5), 500, 470, linewidth=lw, color=color, fill=False) court_elements.append(outer_lines) # Add the court elements onto the axes for element in court_elements: ax.add_patch(element) return axdef Draw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages): fig, h = plt.subplots() # fig = plt.figure(0) # h = fig.add_subplot(111, aspect='equal') # 这两句跟上面那个等效 for i, (mean, covarianceMatrix) in enumerate(zip(gaussianMixtureModel.means_, gaussianMixtureModel.covariances_)): # get the eigen vectors and eigen values of the covariance matrix v, w = np.linalg.eigh(covarianceMatrix) v = 2.5 * np.sqrt(v) # go to units of standard deviation instead of variance # calculate the ellipse angle and two axis length and draw it u = w[0] / np.linalg.norm(w[0]) angle = np.arctan(u[1] / u[0]) angle = 180 * angle / np.pi # convert to degrees currEllipse = Ellipse(mean, v[0], v[1], 180 + angle, color=ellipseColors[i]) currEllipse.set_alpha(0.5) h.add_artist(currEllipse) h.text(mean[0] + 7, mean[1] - 1, ellipseTextMessages[i], fontsize=13, color='blue') 代码中np.linalg.norm()用来计算矩阵或向量的范数，默认为计算2范数。np.linalg.eigh()用来计算埃尔米特矩阵或对称矩阵的特征值和特征向量。 然后绘制2D高斯投篮图，图中的数字代表该区域投篮数的比重。 12345678910111213#%% show gaussian mixture elipses of shot attemptsplt.rcParams['figure.figsize'] = (13, 10)plt.rcParams['font.size'] = 15ellipseTextMessages = [str(100*gaussianMixtureModel.weights_[x])[:5]+'%' for x in range(numGaussians)]ellipseColors = ['red','green','purple','cyan','magenta','yellow','blue','orange','silver','maroon','lime','olive','brown','darkblue']Draw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages)draw_court(outer_lines=True)plt.ylim(-60,440)plt.xlim(270,-270)plt.title('shot attempts')plt.show() 从图中可以看出，科比的投篮出手更多地在球场的左侧（从他的视角则为右侧），可能是因为他是一名右手球员。并且比例最大为16.8%，直接来自篮下，并且还有5.05%来自靠近篮筐的区域。 下面画出投篮的散点图来验证上面的高斯混合模型的正确性。12345678910#%% just to make sure the gaussian model actually captures something, show the scatter and cluster assignmentplt.rcParams['figure.figsize'] = (13, 10)plt.rcParams['font.size'] = 15plt.figure(); draw_court(outer_lines=True)plt.ylim(-60,440)plt.xlim(270,-270)plt.title('cluser assignment')plt.scatter(x=data['loc_x'],y=data['loc_y'],c=data['shotLocationCluster'],s=40,cmap='hsv',alpha=0.1)plt.show() 然后计算每个区域的命中率。图中的数字代表该区域的命中率。 123456789101112131415161718plt.rcParams['figure.figsize'] = (13, 10)plt.rcParams['font.size'] = 15variableCategories = data['shotLocationCluster'].value_counts().index.tolist()clusterAccuracy = &#123;&#125;for category in variableCategories: shotsAttempted = np.array(data['shotLocationCluster'] == category).sum() shotsMade = np.array(data.loc[data['shotLocationCluster'] == category,'shot_made_flag'] == 1).sum() clusterAccuracy[category] = float(shotsMade)/shotsAttemptedellipseTextMessages = [str(100*clusterAccuracy[x])[:4]+'%' for x in range(numGaussians)]Draw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages)draw_court(outer_lines=True)plt.ylim(-60,440)plt.xlim(270,-270)plt.title('shot accuracy')plt.show() 从图中可以发现，科比不仅在右侧（他的视角）出手次数比较多，而且命中率也相对比较高。 接下来，将会根据投篮的性质来评估投篮难度（比如投篮方式或者投篮距离）。 首先构造一个投篮难度模型的列表12345678910111213141516171819202122232425262728293031323334def FactorizeCategoricalVariable(inputDB, categoricalVarName): opponentCategories = inputDB[categoricalVarName].value_counts().index.tolist() outputDB = pd.DataFrame() for category in opponentCategories: featureName = categoricalVarName + ': ' + str(category) outputDB[featureName] = (inputDB[categoricalVarName] == category).astype(int) return outputDBfeaturesDB = pd.DataFrame()featuresDB['homeGame'] = data['matchup'].apply(lambda x: 1 if (x.find('@') &lt; 0) else 0)featuresDB = pd.concat([featuresDB, FactorizeCategoricalVariable(data, 'opponent')], axis=1)featuresDB = pd.concat([featuresDB, FactorizeCategoricalVariable(data, 'action_type')], axis=1)featuresDB = pd.concat([featuresDB, FactorizeCategoricalVariable(data, 'shot_type')], axis=1)featuresDB = pd.concat([featuresDB, FactorizeCategoricalVariable(data, 'combined_shot_type')], axis=1)featuresDB = pd.concat([featuresDB, FactorizeCategoricalVariable(data, 'shot_zone_basic')], axis=1)featuresDB = pd.concat([featuresDB, FactorizeCategoricalVariable(data, 'shot_zone_area')], axis=1)featuresDB = pd.concat([featuresDB, FactorizeCategoricalVariable(data, 'shot_zone_range')], axis=1)featuresDB = pd.concat([featuresDB, FactorizeCategoricalVariable(data, 'shotLocationCluster')], axis=1)featuresDB['playoffGame'] = data['playoffs']featuresDB['locX'] = data['loc_x']featuresDB['locY'] = data['loc_y']featuresDB['distanceFromBasket'] = data['shot_distance']featuresDB['secondsFromPeriodEnd'] = data['secondsFromPeriodEnd']featuresDB['dayOfWeek_cycX'] = np.sin(2 * np.pi * (data['dayOfWeek'] / 7))featuresDB['dayOfWeek_cycY'] = np.cos(2 * np.pi * (data['dayOfWeek'] / 7))featuresDB['timeOfYear_cycX'] = np.sin(2 * np.pi * (data['dayOfYear'] / 365))featuresDB['timeOfYear_cycY'] = np.cos(2 * np.pi * (data['dayOfYear'] / 365))labelsDB = data['shot_made_flag'] 代码中.tolist()方法可以将数组转化为列表。value_counts()用来计算列表中某一数据的数量。 建立一个基于featuresDB的模型，并确保模型没有过拟合（测试误差和训练误差一致）。用ExtraTreesClassifier模型来检验。123456789101112131415161718192021222324252627282930313233343536373839404142# %% build a simple model and make sure it doesnt overfitrandomSeed = 1numFolds = 4stratifiedCV = model_selection.StratifiedKFold(n_splits=numFolds, shuffle=True, random_state=randomSeed)mainLearner = ensemble.ExtraTreesClassifier(n_estimators=500, max_depth=5, min_samples_leaf=120, max_features=120, criterion='entropy', bootstrap=False, n_jobs=-1, random_state=randomSeed)startTime = time.time()trainAccuracy = []validAccuracy = []trainLogLosses = []validLogLosses = []for trainInds, validInds in stratifiedCV.split(featuresDB, labelsDB): # split to train and valid sets X_train_CV = featuresDB.iloc[trainInds, :] y_train_CV = labelsDB.iloc[trainInds] X_valid_CV = featuresDB.iloc[validInds, :] y_valid_CV = labelsDB.iloc[validInds] # train learner mainLearner.fit(X_train_CV, y_train_CV) # make predictions y_train_hat_mainLearner = mainLearner.predict_proba(X_train_CV)[:, 1] y_valid_hat_mainLearner = mainLearner.predict_proba(X_valid_CV)[:, 1] # store results trainAccuracy.append(accuracy(y_train_CV, y_train_hat_mainLearner &gt; 0.5)) validAccuracy.append(accuracy(y_valid_CV, y_valid_hat_mainLearner &gt; 0.5)) trainLogLosses.append(log_loss(y_train_CV, y_train_hat_mainLearner)) validLogLosses.append(log_loss(y_valid_CV, y_valid_hat_mainLearner))print(\"-----------------------------------------------------\")print(\"total (train,valid) Accuracy = (%.5f,%.5f). took %.2f minutes\" % (np.mean(trainAccuracy), np.mean(validAccuracy), (time.time() - startTime) / 60))print(\"total (train,valid) Log Loss = (%.5f,%.5f). took %.2f minutes\" % (np.mean(trainLogLosses), np.mean(validLogLosses), (time.time() - startTime) / 60))print(\"-----------------------------------------------------\") 得到结果如下： 给模型的原始条目添加’shotDifficulty’12mainLearner.fit(featuresDB, labelsDB)data['shotDifficulty'] = mainLearner.predict_proba(featuresDB)[:,1] 根据ET分类器观察特征的重要程度： 123456# just to get a feel for what determins shot difficulty, look at feature importancesfeatureInds = mainLearner.feature_importances_.argsort()[::-1]featureImportance = pd.DataFrame(np.concatenate((featuresDB.columns[featureInds,None], mainLearner.feature_importances_[featureInds,None]), axis=1), columns=['featureName', 'importanceET'])featureImportance.iloc[:30,:] 对此，我们将分析两组不同的投篮并分析他们之间的不同。 在投篮命中之后的投篮 在投篮失败之后的投篮 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# %% collect data given that kobe made or missed last shottimeBetweenShotsDict = &#123;&#125;timeBetweenShotsDict['madeLast'] = []timeBetweenShotsDict['missedLast'] = []changeInDistFromBasketDict = &#123;&#125;changeInDistFromBasketDict['madeLast'] = []changeInDistFromBasketDict['missedLast'] = []changeInShotDifficultyDict = &#123;&#125;changeInShotDifficultyDict['madeLast'] = []changeInShotDifficultyDict['missedLast'] = []afterMadeShotsList = []afterMissedShotsList = []for shot in range(1, data.shape[0]): # make sure the current shot and last shot were all in the same period of the same game sameGame = data.loc[shot, 'game_date'] == data.loc[shot - 1, 'game_date'] samePeriod = data.loc[shot, 'period'] == data.loc[shot - 1, 'period'] if samePeriod and sameGame: madeLastShot = data.loc[shot - 1, 'shot_made_flag'] == 1 missedLastShot = data.loc[shot - 1, 'shot_made_flag'] == 0 timeDifferenceFromLastShot = data.loc[shot, 'secondsFromGameStart'] - data.loc[shot - 1, 'secondsFromGameStart'] distDifferenceFromLastShot = data.loc[shot, 'shot_distance'] - data.loc[shot - 1, 'shot_distance'] shotDifficultyDifferenceFromLastShot = data.loc[shot, 'shotDifficulty'] - data.loc[shot - 1, 'shotDifficulty'] # check for currupt data points (assuming all samples should have been chronologically ordered) if timeDifferenceFromLastShot &lt; 0: continue if madeLastShot: timeBetweenShotsDict['madeLast'].append(timeDifferenceFromLastShot) changeInDistFromBasketDict['madeLast'].append(distDifferenceFromLastShot) changeInShotDifficultyDict['madeLast'].append(shotDifficultyDifferenceFromLastShot) afterMadeShotsList.append(shot) if missedLastShot: timeBetweenShotsDict['missedLast'].append(timeDifferenceFromLastShot) changeInDistFromBasketDict['missedLast'].append(distDifferenceFromLastShot) changeInShotDifficultyDict['missedLast'].append(shotDifficultyDifferenceFromLastShot) afterMissedShotsList.append(shot)afterMissedData = data.iloc[afterMissedShotsList, :]afterMadeData = data.iloc[afterMadeShotsList, :]shotChancesListAfterMade = afterMadeData['shotDifficulty'].tolist()totalAttemptsAfterMade = afterMadeData.shape[0]totalMadeAfterMade = np.array(afterMadeData['shot_made_flag'] == 1).sum()shotChancesListAfterMissed = afterMissedData['shotDifficulty'].tolist()totalAttemptsAfterMissed = afterMissedData.shape[0]totalMadeAfterMissed = np.array(afterMissedData['shot_made_flag'] == 1).sum() 对上面两组数据绘制柱形图123456789101112131415#%% after making a shot, kobe wants moreplt.rcParams['figure.figsize'] = (13, 10)jointHist, timeBins = np.histogram(timeBetweenShotsDict['madeLast']+timeBetweenShotsDict['missedLast'],bins=200)barWidth = 0.999*(timeBins[1]-timeBins[0])timeDiffHist_GivenMadeLastShot, b = np.histogram(timeBetweenShotsDict['madeLast'],bins=timeBins)timeDiffHist_GivenMissedLastShot, b = np.histogram(timeBetweenShotsDict['missedLast'],bins=timeBins)maxHeight = max(max(timeDiffHist_GivenMadeLastShot),max(timeDiffHist_GivenMissedLastShot)) + 30plt.figure();plt.subplot(2,1,1); plt.bar(timeBins[:-1], timeDiffHist_GivenMadeLastShot, width=barWidth); plt.xlim((0,500)); plt.ylim((0,maxHeight))plt.title('made last shot'); plt.ylabel('counts')plt.subplot(2,1,2); plt.bar(timeBins[:-1], timeDiffHist_GivenMissedLastShot, width=barWidth); plt.xlim((0,500)); plt.ylim((0,maxHeight))plt.title('missed last shot'); plt.xlabel('time since last shot'); plt.ylabel('counts') 可以发现，当科比投篮命中之后，更加渴望下一次投篮。 图像前面有一段沉默的区域是因为当投篮命中之后，球在对方手上，并且一段时间之后才会再一次 得到球。 绘制累计直方图，来更好地可视化两个直方图之间的差异。1234567891011121314#%% to make the difference clearer, show the cumulative histogramplt.rcParams['figure.figsize'] = (13, 6)timeDiffCumHist_GivenMadeLastShot = np.cumsum(timeDiffHist_GivenMadeLastShot).astype(float)timeDiffCumHist_GivenMadeLastShot = timeDiffCumHist_GivenMadeLastShot/max(timeDiffCumHist_GivenMadeLastShot)timeDiffCumHist_GivenMissedLastShot = np.cumsum(timeDiffHist_GivenMissedLastShot).astype(float)timeDiffCumHist_GivenMissedLastShot = timeDiffCumHist_GivenMissedLastShot/max(timeDiffCumHist_GivenMissedLastShot)maxHeight = max(timeDiffCumHist_GivenMadeLastShot[-1],timeDiffCumHist_GivenMissedLastShot[-1])plt.figure()madePrev = plt.plot(timeBins[:-1], timeDiffCumHist_GivenMadeLastShot, label='made Prev'); plt.xlim((0,500))missedPrev = plt.plot(timeBins[:-1], timeDiffCumHist_GivenMissedLastShot, label='missed Prev'); plt.xlim((0,500)); plt.ylim((0,1))plt.title('cumulative density function - CDF'); plt.xlabel('time since last shot'); plt.legend(loc='lower right') 代码中np.cumsum()用来计算数据中的累计值。 绘制两组数据的’当前投篮距离-前一次投篮距离’的直方图。如果科比先近距离投篮然后远距离投篮，那么计算结果为正值，反之亦然，如果科比先远距离投篮，然后在近距离投篮，计算结果为负值。1234567891011121314plt.rcParams['figure.figsize'] = (13, 10)jointHist, distDiffBins = np.histogram(changeInDistFromBasketDict['madeLast']+changeInDistFromBasketDict['missedLast'],bins=100,density=False)barWidth = 0.999*(distDiffBins[1]-distDiffBins[0])distDiffHist_GivenMadeLastShot, b = np.histogram(changeInDistFromBasketDict['madeLast'],bins=distDiffBins)distDiffHist_GivenMissedLastShot, b = np.histogram(changeInDistFromBasketDict['missedLast'],bins=distDiffBins)maxHeight = max(max(distDiffHist_GivenMadeLastShot),max(distDiffHist_GivenMissedLastShot)) + 30plt.figure()plt.subplot(2,1,1); plt.bar(distDiffBins[:-1], distDiffHist_GivenMadeLastShot, width=barWidth); plt.xlim((-40,40)); plt.ylim((0,maxHeight))plt.title('made last shot'); plt.ylabel('counts')plt.subplot(2,1,2); plt.bar(distDiffBins[:-1], distDiffHist_GivenMissedLastShot, width=barWidth); plt.xlim((-40,40)); plt.ylim((0,maxHeight))plt.title('missed last shot'); plt.xlabel('curr shot distance - prev shot distance'); plt.ylabel('counts') 图中可以清楚地看到投篮命中的图更加倾向于右侧。因此，可以发现，科比投篮命中之后会更加自信，并因此会冒更大的风险在更远的地方投篮。 这比之前的图更加明显，但绘制累计直方图会更加明显。1234567891011121314#%% to make the difference clearer, show the cumulative histogramplt.rcParams['figure.figsize'] = (13, 6)distDiffCumHist_GivenMadeLastShot = np.cumsum(distDiffHist_GivenMadeLastShot).astype(float)distDiffCumHist_GivenMadeLastShot = distDiffCumHist_GivenMadeLastShot/max(distDiffCumHist_GivenMadeLastShot)distDiffCumHist_GivenMissedLastShot = np.cumsum(distDiffHist_GivenMissedLastShot).astype(float)distDiffCumHist_GivenMissedLastShot = distDiffCumHist_GivenMissedLastShot/max(distDiffCumHist_GivenMissedLastShot)maxHeight = max(distDiffCumHist_GivenMadeLastShot[-1],distDiffCumHist_GivenMissedLastShot[-1])plt.figure()madePrev = plt.plot(distDiffBins[:-1], distDiffCumHist_GivenMadeLastShot, label='made Prev'); plt.xlim((-40,40))missedPrev = plt.plot(distDiffBins[:-1], distDiffCumHist_GivenMissedLastShot, label='missed Prev'); plt.xlim((-40,40)); plt.ylim((0,1))plt.title('cumulative density function - CDF'); plt.xlabel('curr shot distance - prev shot distance'); plt.legend(loc='lower right') 最后，绘制两组数据投篮难度变化。这里负值代表科比冒更大的风险，正值表示科比采取比较保险的投篮。123456789101112131415#%% after making a shot, kobe is a more confident and makes much more difficult shots generallyplt.rcParams['figure.figsize'] = (13, 10)jointHist, difficultyDiffBins = np.histogram(changeInShotDifficultyDict['madeLast']+changeInShotDifficultyDict['missedLast'],bins=100)barWidth = 0.999*(difficultyDiffBins[1]-difficultyDiffBins[0])shotDifficultyDiffHist_GivenMadeLastShot, b = np.histogram(changeInShotDifficultyDict['madeLast'],bins=difficultyDiffBins)shotDifficultyDiffHist_GivenMissedLastShot, b = np.histogram(changeInShotDifficultyDict['missedLast'],bins=difficultyDiffBins)maxHeight = max(max(shotDifficultyDiffHist_GivenMadeLastShot),max(shotDifficultyDiffHist_GivenMissedLastShot)) + 30plt.figure()plt.subplot(2,1,1); plt.bar(difficultyDiffBins[:-1], shotDifficultyDiffHist_GivenMadeLastShot, width=barWidth); plt.xlim((-1,1)); plt.ylim((0,maxHeight))plt.title('made last shot'); plt.ylabel('counts')plt.subplot(2,1,2); plt.bar(difficultyDiffBins[:-1], shotDifficultyDiffHist_GivenMissedLastShot, width=barWidth); plt.xlim((-1,1)); plt.ylim((0,maxHeight))plt.title('missed last shot'); plt.xlabel('chance to make curr shot - chance to make prev shot'); plt.ylabel('counts') 从图中可以发现，命中的投篮更加倾向于左侧。说明科比命中之后会就更加自信，并允许自己尝试更加困难的投篮。 或许你会好奇是否仅仅是简单地对均值的回归。 这种想法是合理的，因为所有命中的投篮都明显地偏向于比较容易的投篮，如果使用相对测量，比如“投篮难度”，肯定会得到这个回归均值的效果，所以需要确保是否是这样。 1234567891011121314151617181920#%% is this regression to the mean?plt.rcParams['figure.figsize'] = (12, 10)accuracyAllShots = data['shot_made_flag'].mean()accuracyAfterMade = afterMadeData['shot_made_flag'].mean()accuracyAfterMissed = afterMissedData['shot_made_flag'].mean()standardErrorAllShots = np.sqrt(accuracyAllShots*(1-accuracyAllShots)/data.shape[0])standardErrorAfterMade = np.sqrt(accuracyAfterMade*(1-accuracyAfterMade)/afterMadeData.shape[0])standardErrorAfterMissed = np.sqrt(accuracyAfterMissed*(1-accuracyAfterMissed)/afterMissedData.shape[0])accuracyVec = np.array([accuracyAfterMade,accuracyAllShots,accuracyAfterMissed])errorVec = np.array([standardErrorAfterMade,standardErrorAllShots,standardErrorAfterMissed])barWidth = 0.7xLocs = np.arange(len(accuracyVec)) + 0.5fig, h = plt.subplots(); h.bar(xLocs, accuracyVec, barWidth, color='b', yerr=errorVec)h.set_xticks(xLocs); h.set_xticklabels(('after made', 'all shots', 'after missed'))plt.ylim([0.41,0.47]); plt.xlim([-0.3,3.3]); plt.title('not regression to the mean') 现在可以确定不是简单地均值回归，实际上两种不同的投篮数据组有非常不同的命中率。那么有一个问题出现了 科比手热的感觉是否正确？获取科比真的感觉到自己的投篮区，并更多地尝试更加困难的投篮。 可以通过创建的投篮困难的模型看出，命中率几乎一致，并没有包含手热的特性。 这个结果表明科比并没有手热的效应。 下面尝试可视化。1234567891011121314#%% let's try and visualize this - show scatter plot of after made and after missed shotsplt.rcParams['figure.figsize'] = (16, 8)afterMissedData = data.iloc[afterMissedShotsList,:]afterMadeData = data.iloc[afterMadeShotsList,:]plt.figure();plt.subplot(1,2,1); plt.title('shots after made')plt.scatter(x=afterMadeData['loc_x'],y=afterMadeData['loc_y'],c=afterMadeData['shotLocationCluster'],s=50,cmap='hsv',alpha=0.06)draw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270);plt.subplot(1,2,2); plt.title('shots after missed');plt.scatter(x=afterMissedData['loc_x'],y=afterMissedData['loc_y'],c=afterMissedData['shotLocationCluster'],s=50,cmap='hsv',alpha=0.06)draw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270); 明锐的眼睛或许可以发现这里密度的不同，但是不太明显，因此用高斯格式来显示这些数据。12345678910111213141516171819202122#%% show shot attempts of after made and after missed shotsplt.rcParams['figure.figsize'] = (13, 10)variableCategories = afterMadeData['shotLocationCluster'].value_counts().index.tolist()clusterFrequency = &#123;&#125;for category in variableCategories: shotsAttempted = np.array(afterMadeData['shotLocationCluster'] == category).sum() clusterFrequency[category] = float(shotsAttempted)/afterMadeData.shape[0]ellipseTextMessages = [str(100*clusterFrequency[x])[:4]+'%' for x in range(numGaussians)]Draw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages)draw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270); plt.title('after made shots')variableCategories = afterMissedData['shotLocationCluster'].value_counts().index.tolist()clusterFrequency = &#123;&#125;for category in variableCategories: shotsAttempted = np.array(afterMissedData['shotLocationCluster'] == category).sum() clusterFrequency[category] = float(shotsAttempted)/afterMissedData.shape[0]ellipseTextMessages = [str(100*clusterFrequency[x])[:4]+'%' for x in range(numGaussians)]Draw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages)draw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270); plt.title('after missed shots') 现在可以清晰地发现，当科比投丢一个球的时候，会更加倾向于直接从篮下来得分（投丢上一个球之后后27%的概率，命中前一个球后有18%的概率） 同样可以明显地看到，当科比命中一个球后接下来更加倾向于投三分。","tags":[{"name":"Data Analysis","slug":"Data-Analysis","permalink":"http://luojiaji.github.io/tags/Data-Analysis/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"}]},{"title":"TensorBoard Embeddings 可视化","date":"2017-09-17T03:13:13.000Z","path":"2017/09/17/TensorBoard-Embeddings-可视化/","text":"今天的文章主要介绍TensorFlow中TensorBoard Embeddings的使用 导入数据123456789101112131415161718import matplotlib.pyplot as pltimport tensorflow as tfimport numpy as npimport osfrom tensorflow.contrib.tensorboard.plugins import projectorfrom tensorflow.examples.tutorials.mnist import input_dataLOG_DIR = 'minimalsample'NAME_TO_VISUALISE_VARIABLE = \"mnistembedding\"TO_EMBED_COUNT = 500path_for_mnist_sprites = os.path.join(LOG_DIR,'mnistdigits.png')path_for_mnist_metadata = os.path.join(LOG_DIR,'metadata.tsv')mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)batch_xs, batch_ys = mnist.train.next_batch(TO_EMBED_COUNT) 得到如下结果：1234Extracting MNIST_data/train-images-idx3-ubyte.gzExtracting MNIST_data/train-labels-idx1-ubyte.gzExtracting MNIST_data/t10k-images-idx3-ubyte.gzExtracting MNIST_data/t10k-labels-idx1-ubyte.gz 创建embeddings在这个例子中，就是训练数据的值。但是要知道想要可视化的变量的名称。12embedding_var = tf.Variable(batch_xs, name=NAME_TO_VISUALISE_VARIABLE)summary_writer = tf.summary.FileWriter(LOG_DIR) 创建embeddings projector这是嵌入可视化比较重要的一步，需要指定映射的变量，metadata文件的路径，以及sprits文件的路径。12345678910111213config = projector.ProjectorConfig()embedding = config.embeddings.add()embedding.tensor_name = embedding_var.name# Specify where you find the metadataembedding.metadata_path = path_for_mnist_metadata #'metadata.tsv'# Specify where you find the sprite (we will create this later)embedding.sprite.image_path = path_for_mnist_sprites #'mnistdigits.png'embedding.sprite.single_image_dim.extend([28,28])# Say that you want to visualise the embeddingsprojector.visualize_embeddings(summary_writer, config) 保存数据TensorBoard从保存的图形中导入保存的变量。初始化会话和变量，并保存在日志路径中。1234sess = tf.InteractiveSession()sess.run(tf.global_variables_initializer())saver = tf.train.Saver()saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), 1) 保存sprite图像有三个比较重要的可视化的函数： create_sprite_imagecreate_sprite_image：将sprit整齐的排列在方形的图片上。 vector_to_matrix_mnist：MNIST特征导入的是向量而不是图像，这个函数可以将他们转化为图像。 invert_grayscale：matplotlib中将0视为黑色，1视为白色。但是在TensorBoard中白色的背景看上去效果会更好，所以将他们进行翻转处理处理之后将sprite图像保存，将向量转化为图像，翻转灰度值，创建并保存图像： 123456789101112131415161718192021222324252627282930313233343536def create_sprite_image(images): \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\" if isinstance(images, list): images = np.array(images) img_h = images.shape[1] img_w = images.shape[2] n_plots = int(np.ceil(np.sqrt(images.shape[0]))) spriteimage = np.ones((img_h * n_plots ,img_w * n_plots )) for i in range(n_plots): for j in range(n_plots): this_filter = i * n_plots + j if this_filter &lt; images.shape[0]: this_img = images[this_filter] spriteimage[i * img_h:(i + 1) * img_h, j * img_w:(j + 1) * img_w] = this_img return spriteimagedef vector_to_matrix_mnist(mnist_digits): \"\"\"Reshapes normal mnist digit (batch,28*28) to matrix (batch,28,28)\"\"\" return np.reshape(mnist_digits,(-1,28,28))def invert_grayscale(mnist_digits): \"\"\" Makes black white, and white black \"\"\" return 1-mnist_digitsto_visualise = batch_xsto_visualise = vector_to_matrix_mnist(to_visualise)to_visualise = invert_grayscale(to_visualise)sprite_image = create_sprite_image(to_visualise)plt.imsave(path_for_mnist_sprites,sprite_image,cmap='gray')plt.imshow(sprite_image,cmap='gray') 保存metadata文件为了给mnist数据添加颜色，潜入可视化工具需要知道每一张图片的标签。这些信息保存在.tsv文件中。文件中每一行包含：1&quot;Index&quot; , &quot;Label&quot; Index是嵌入矩阵的索引，Label是MNIST特征的标签。 将数据写入metadata文件的代码如下： 1234with open(path_for_mnist_metadata,'w') as f: f.write(\"Index\\tLabel\\n\") for index,label in enumerate(batch_ys): f.write(\"%d\\t%d\\n\" % (index,label)) 运行已经获得了MNIST的特征，现在就进行可视化。如果没有改变上面的任何变量，可以执行线面的命令进行可视化： 1tensorboard –logdir=minimalsample 用浏览器打开http://127.0.0.1:6006（注意：可能会根据自己的电脑设施修改），将会在Embeddings标签中看到下图（老版本的TensorFlow没有Embeddings标签，需要对TensorFlow升级）： 可以在Embeddings标签中看到MNIST数据集的PCA，点击左侧的“color by”选择器并选择Label，将会看到更加漂亮的分组。（0互相靠近，6互相靠近，等等） 也可以尝试T-SNE来观察当数据样本试图形成群体时，数字会移动。 如果TensorBoard有问题无法显示，可以尝试改变LOG_DIR。可以将metadata和sprite文件的相对路径改为绝对路径。LOG_DIR = os.getcwd()+&#39;/minimalsample&#39; 参考资料 Simple Introduction to Tensorboard Embedding Visualisation Visualizing MNIST: An Exploration of Dimensionality Reduction Embeddings http://projector.tensorflow.org/","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"}]},{"title":"通过DQN来玩FlappyBird","date":"2017-09-09T08:23:45.000Z","path":"2017/09/09/通过DQN来玩FlappyBird/","text":"本文主要介绍通过CNN+DQN模型来实现玩AI玩FlappyBird。 介绍今天主要介绍如何通过强化学习来让程序玩FlappyBird。最终的效果如下： 上面的效果实在进行了2000000次迭代训练之后得到的结果。几乎已经可以碾压人类玩家了。 算法整体的算法是CNN+DQN，并通过奖励值对网络进行训练。模型的整体结构如下图。 具体CNN和DQN算法的原理可以参考之前写过的文章，这里重点介绍模型的代码实现。 实现游戏环境的实现就不具体解释了，没什么太难得地方，了解Pygame模块之后，程序没有太难的地方。重点来看一下神经网络的搭建以及训练的过程。 代码用到的主要模块及版本：Python：3.5.3TensorFlow：1.0.1cv2：3.3.0pygame：1.9.3 首先是一些超参数的设置：123456789ACTIONS = 2 # 动作的数量GAMMA = 0.99 # 衰减系数OBSERVE = 100000. # 训练之前的观察步骤EXPLORE = 2000000. # 迭代数量FINAL_EPSILON = 0.0001 # final value of epsilonINITIAL_EPSILON = 0.0001 # starting value of epsilonREPLAY_MEMORY = 50000 # 状态存储大小BATCH = 32 # minibatch的大小FRAME_PER_ACTION = 1 然后是神将网络的搭建：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253def weight_variable(shape): initial = tf.truncated_normal(shape, stddev = 0.01) return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.01, shape = shape) return tf.Variable(initial)def conv2d(x, W, stride): return tf.nn.conv2d(x, W, strides = [1, stride, stride, 1], padding = \"SAME\")def max_pool_2x2(x): return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"SAME\")def createNetwork(): # network weights W_conv1 = weight_variable([8, 8, 4, 32]) b_conv1 = bias_variable([32]) W_conv2 = weight_variable([4, 4, 32, 64]) b_conv2 = bias_variable([64]) W_conv3 = weight_variable([3, 3, 64, 64]) b_conv3 = bias_variable([64]) W_fc1 = weight_variable([1600, 512]) b_fc1 = bias_variable([512]) W_fc2 = weight_variable([512, ACTIONS]) b_fc2 = bias_variable([ACTIONS]) # input layer s = tf.placeholder(\"float\", [None, 80, 80, 4]) # hidden layers h_conv1 = tf.nn.relu(conv2d(s, W_conv1, 4) + b_conv1) h_pool1 = max_pool_2x2(h_conv1) h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, 2) + b_conv2) #h_pool2 = max_pool_2x2(h_conv2) h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 1) + b_conv3) #h_pool3 = max_pool_2x2(h_conv3) #h_pool3_flat = tf.reshape(h_pool3, [-1, 256]) h_conv3_flat = tf.reshape(h_conv3, [-1, 1600]) h_fc1 = tf.nn.relu(tf.matmul(h_conv3_flat, W_fc1) + b_fc1) # readout layer readout = tf.matmul(h_fc1, W_fc2) + b_fc2 return s, readout, h_fc1 神经网络一共3个卷基层和2个全连接层。最终代码里的实现结构和上面图中的结构有一些差别，输入图片大小为80x80x4。第一个卷基层得到图片的尺寸为20x20x32，然后加一个maxpooling层，得到10x10x32的图片。第二个卷基层得到的图片尺寸为10x10x64。第三个卷基层得到图片的尺寸为5x5x64。然后将得到的数据产开，得到1600x1的数据，然后经过第一个全连接层得到512x1的数据，然后经过第二个全连接层最终得到对应的动作值。 然后计算损失函数和优化规则：123readout_action = tf.reduce_sum(tf.multiply(readout, a), reduction_indices=1)cost = tf.reduce_mean(tf.square(y - readout_action))train_step = tf.train.AdamOptimizer(1e-6).minimize(cost) 然后根据动作得到当前的图片，并对图片进行裁剪：12345do_nothing = np.zeros(ACTIONS)do_nothing[0] = 1x_t, r_0, terminal = game_state.frame_step(do_nothing)x_t = cv2.cvtColor(cv2.resize(x_t, (80, 80)), cv2.COLOR_BGR2GRAY)ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY) 代码中cv2.resize()将图片尺寸转化成80x80，cv2.cvtColor()对图像进行灰度化，cv2.threshold()将图像二值化。 然后导入保存好的网络参数：12345678saver = tf.train.Saver() sess.run(tf.initialize_all_variables()) checkpoint = tf.train.get_checkpoint_state(\"saved_networks\") if checkpoint and checkpoint.model_checkpoint_path: saver.restore(sess, checkpoint.model_checkpoint_path) print(\"Successfully loaded:\", checkpoint.model_checkpoint_path) else: print(\"Could not find old network weights\") 然后根据当前的状态图片得到对应的动作，并通过概率判断是否选择最优动作或进行探索。12345678910111213readout_t = readout.eval(feed_dict=&#123;s : [s_t]&#125;)[0] a_t = np.zeros([ACTIONS]) action_index = 0 if t % FRAME_PER_ACTION == 0: if random.random() &lt;= epsilon: print(\"----------Random Action----------\") action_index = random.randrange(ACTIONS) a_t[random.randrange(ACTIONS)] = 1 else: action_index = np.argmax(readout_t) a_t[action_index] = 1 else: a_t[0] = 1 # do nothing 将动作值输入游戏环境总得到奖励值，和下一步的状态值图片，并对下一步的状态图片进行裁剪。并保存当前状态，动作值，奖励值和下一步状态。如果存储空间的大小大于存储的大小，则删除之前的数据。1234567891011x_t1_colored, r_t, terminal = game_state.frame_step(a_t) x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (80, 80)), cv2.COLOR_BGR2GRAY) ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY) x_t1 = np.reshape(x_t1, (80, 80, 1)) #s_t1 = np.append(x_t1, s_t[:,:,1:], axis = 2) s_t1 = np.append(x_t1, s_t[:, :, :3], axis=2) # store the transition in D D.append((s_t, a_t, r_t, s_t1, terminal)) if len(D) &gt; REPLAY_MEMORY: D.popleft() 从存储的数据中采样mimibatch大小的数据对网络进行训练，123456789101112131415161718192021222324minibatch = random.sample(D, BATCH) # get the batch variables s_j_batch = [d[0] for d in minibatch] a_batch = [d[1] for d in minibatch] r_batch = [d[2] for d in minibatch] s_j1_batch = [d[3] for d in minibatch] y_batch = [] readout_j1_batch = readout.eval(feed_dict = &#123;s : s_j1_batch&#125;) for i in range(0, len(minibatch)): terminal = minibatch[i][4] # if terminal, only equals reward if terminal: y_batch.append(r_batch[i]) else: y_batch.append(r_batch[i] + GAMMA * np.max(readout_j1_batch[i])) # perform gradient step train_step.run(feed_dict = &#123; y : y_batch, a : a_batch, s : s_j_batch&#125; ) 以上就是主要的代码片段。运行程序，导入现有的网络参数就可以看到上面的游戏效果。 参考资料： Using Keras and Deep Q-Network to Play FlappyBird https://github.com/yenchenlin/DeepLearningFlappyBird","tags":[{"name":"RL","slug":"RL","permalink":"http://luojiaji.github.io/tags/RL/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"}]},{"title":"Actor Critic算法设计与实现","date":"2017-08-25T12:14:53.000Z","path":"2017/08/25/Actor-Critic算法设计与实现/","text":"今天介绍强化学习中的一种新的算法，叫做Actor Critic。 介绍Actor Critic将Policy Gradient（Actor部分）和Function Approximation（Critic部分）相结合，Actor根据当前状态对应行为的概率选择行为，Critic通过当前状态，奖励值以及下一个状态进行学习同时返回Actor当前行为评分，Actor根据Critic给出的评分对行为概率进行修正。 Actor Critic的优缺点： 优点：Actor Critic不用想DQN或者Policy Gradient那样需要对探索的状态，动作和奖励信息进行存储。而是可以进行单步学习和更新，这样学习效率要比DQN和Policy Gradient快。 缺点：由于单步更新参照的信息有限，而且Actor和Critic要同时学习，因此学习比较难以收敛。 代码实现下面介绍Actor Critic的具体实现过程。用到的Python库：Python：3.5.3TensorFlow：1.0.1gym：0.8.1 试验环境依然使用gym中的CartPole-v0。 首先介绍Actor部分的代码。1234567891011121314151617181920212223242526272829303132333435363738394041424344class Actor(object): def __init__(self, sess, n_features, n_actions, lr=0.001): self.sess = sess self.s = tf.placeholder(tf.float32, [1, n_features], \"state\") self.a = tf.placeholder(tf.int32, None, \"act\") self.td_error = tf.placeholder(tf.float32, None, \"td_error\") # TD_error with tf.variable_scope('Actor'): l1 = tf.layers.dense( inputs=self.s, units=20, # number of hidden units activation=tf.nn.relu, kernel_initializer=tf.random_normal_initializer(0., .1), # weights bias_initializer=tf.constant_initializer(0.1), # biases name='l1' ) self.acts_prob = tf.layers.dense( inputs=l1, units=n_actions, # output units activation=tf.nn.softmax, # get action probabilities kernel_initializer=tf.random_normal_initializer(0., .1), # weights bias_initializer=tf.constant_initializer(0.1), # biases name='acts_prob' ) with tf.variable_scope('exp_v'): log_prob = tf.log(self.acts_prob[0, self.a]) self.exp_v = tf.reduce_mean(log_prob * self.td_error) # advantage (TD_error) guided loss with tf.variable_scope('train'): self.train_op = tf.train.AdamOptimizer(lr).minimize(-self.exp_v) # minimize(-exp_v) = maximize(exp_v) def learn(self, s, a, td): s = s[np.newaxis, :] feed_dict = &#123;self.s: s, self.a: a, self.td_error: td&#125; _, exp_v = self.sess.run([self.train_op, self.exp_v], feed_dict) return exp_v def choose_action(self, s): s = s[np.newaxis, :] probs = self.sess.run(self.acts_prob, &#123;self.s: s&#125;) # get probabilities for all actions return np.random.choice(np.arange(probs.shape[1]), p=probs.ravel()) # return a int 代码中首先传递环境的状态数量n_features，动作数量n_actions和学习效率lr。然后构建用于Actor学习的神经网络，网络包含一个含有20个节点的隐藏层。Actor.learn()通过当前状态s，动作a和Critic给出的时间差分误差td进行学习。Actor.Choose_action()通过当前状态s计算出每个动作的概率，然后根据相应的概率来选择动作。 下面是Critic部分的代码：123456789101112131415161718192021222324252627282930313233343536373839404142class Critic(object): def __init__(self, sess, n_features, lr=0.01): self.sess = sess self.s = tf.placeholder(tf.float32, [1, n_features], \"state\") self.v_ = tf.placeholder(tf.float32, [1, 1], \"v_next\") self.r = tf.placeholder(tf.float32, None, 'r') with tf.variable_scope('Critic'): l1 = tf.layers.dense( inputs=self.s, units=20, # number of hidden units activation=tf.nn.relu, # None # have to be linear to make sure the convergence of actor. # But linear approximator seems hardly learns the correct Q. kernel_initializer=tf.random_normal_initializer(0., .1), # weights bias_initializer=tf.constant_initializer(0.1), # biases name='l1' ) self.v = tf.layers.dense( inputs=l1, units=1, # output units activation=None, kernel_initializer=tf.random_normal_initializer(0., .1), # weights bias_initializer=tf.constant_initializer(0.1), # biases name='V' ) with tf.variable_scope('squared_TD_error'): self.td_error = self.r + GAMMA * self.v_ - self.v self.loss = tf.square(self.td_error) # TD_error = (r+gamma*V_next) - V_eval with tf.variable_scope('train'): self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss) def learn(self, s, r, s_): s, s_ = s[np.newaxis, :], s_[np.newaxis, :] v_ = self.sess.run(self.v, &#123;self.s: s_&#125;) td_error, _ = self.sess.run([self.td_error, self.train_op], &#123;self.s: s, self.v_: v_, self.r: r&#125;) return td_error 代码中建立一个输入层节点为s,隐藏层节点为20，输出层节点为1的神经网络。Critic.learn()根据当前状态s,奖励值r和下一步的状态s_进行学习，并返回时间差分误差td给actor.learn() 然后是完整的训练过程：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import gymfrom ActorCritic import *np.random.seed(2)tf.set_random_seed(2) # reproducible# SuperparametersOUTPUT_GRAPH = FalseMAX_EPISODE = 3000DISPLAY_REWARD_THRESHOLD = 100 # renders environment if total episode reward is greater then this thresholdMAX_EP_STEPS = 1000 # maximum time step in one episodeRENDER = False # rendering wastes timeGAMMA = 0.9 # reward discount in TD errorLR_A = 0.001 # learning rate for actorLR_C = 0.01 # learning rate for criticenv = gym.make('CartPole-v0')env.seed(1) # reproducibleN_F = env.observation_space.shape[0]N_A = env.action_space.nsess = tf.Session()actor = Actor(sess, n_features=N_F, n_actions=N_A, lr=LR_A)critic = Critic(sess, n_features=N_F, lr=LR_C) # we need a good teacher, so the teacher should learn faster than the actorsess.run(tf.global_variables_initializer())if OUTPUT_GRAPH: tf.summary.FileWriter(\"logs/\", sess.graph)for i_episode in range(MAX_EPISODE): s = env.reset() t = 0 track_r = [] while True: if RENDER: env.render() a = actor.choose_action(s) s_, r, done, info = env.step(a) if done: r = -20 track_r.append(r) td_error = critic.learn(s, r, s_) # gradient = grad[r + gamma * V(s_) - V(s)] actor.learn(s, a, td_error) # true_gradient = grad[logPi(s,a) * td_error] s = s_ t += 1 if done or t &gt;= MAX_EP_STEPS: ep_rs_sum = sum(track_r) if 'running_reward' not in globals(): running_reward = ep_rs_sum else: running_reward = running_reward * 0.95 + ep_rs_sum * 0.05 if running_reward &gt; DISPLAY_REWARD_THRESHOLD: RENDER = True # rendering print(\"episode:\", i_episode, \" reward:\", int(running_reward)) break 通过训练发下，通过3000次迭代，Actor Critic算法的收敛性确实不是太理想，没有DQN和Policy Gradient的效果好。 通过TensorBoard可以查看网络的结构如下：1Tensorboard --logdir logs 参考资料： Actor Critic (Tensorflow)","tags":[{"name":"RL","slug":"RL","permalink":"http://luojiaji.github.io/tags/RL/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"}]},{"title":"MathJax的基本用法","date":"2017-08-13T11:57:57.000Z","path":"2017/08/13/MathJax的基本用法/","text":"本文主要介绍MathJax的符号表示以及常用语法表示。 插入公式 如果是文本中插入公式，则用 $ ... $ 如果是单独的公式行，则使用 $$ ... $$ 多行公式如果需要些多行公式，就用123\\begin&#123;equation&#125;\\begin&#123;split&#125;...end&#123;split&#125;\\end&#123;equation&#125; \\\\表示换行，&amp;表示要对其的位置，例如：12345\\begin&#123;equation&#125;\\begin&#123;split&#125;H(Y|X) &amp;=\\sum_&#123;x\\in X&#125; p(x)H(Y|X)\\\\&amp;=-\\sum_&#123;x\\in X&#125; p(x)\\sum_&#123;y\\in Y&#125;p(y|x)\\log p(y|x)\\\\&amp;=-\\sum_&#123;x\\in X&#125; \\sum_&#123;y\\in Y&#125;p(y,x)\\log p(y|x)\\end&#123;split&#125;\\end&#123;equation&#125; $$\\begin{equation}\\begin{split}H(Y|X) &amp;=\\sum{x\\in X} p(x)H(Y|X) \\\\&amp;=-\\sum{x\\in X} p(x)\\sum{y\\in Y}p(y|x)\\log p(y|x) \\\\&amp;=-\\sum{x\\in X} \\sum_{y\\in Y}p(y,x)\\log p(y|x)\\end{split}\\end{equation}$$ 分式有两种方法可以实现分式： 使用\\frac a b。例如\\frac {1+a} {4+b}，效果为：$\\frac {1+a} {4+b}$ 使用 a \\over b。例如{1+a} \\over {4+b}，效果为：${1+a} \\over {4+b}$ 不要在指数或者积分中使用\\frac。在指数或者积分中使用\\frac会使表达式看起来不清晰，因此在专业的数学排版中很少被使用。应该使用/来代替。1234567891011$$\\begin&#123;array&#125;&#123;c | c&#125; \\\\\\mathrm&#123;Bad&#125; &amp; \\mathrm&#123;Better&#125; \\\\\\hline \\\\e^&#123;i \\frac &#123;\\pi&#125; 2&#125; \\quad e^&#123;\\frac&#123;i \\pi&#125; 2&#125; &amp;e^&#123;i \\pi / 2&#125; \\\\\\int _ &#123;- \\frac \\pi 2&#125;^ \\frac \\pi 2 \\sin x \\, dx &amp;\\int _ &#123;- \\pi / 2&#125;^&#123;\\pi / 2&#125;\\sin x \\, dx \\\\\\end&#123;array&#125;$$ 效果如下： $$\\begin{array}{c | c} \\\\\\mathrm{Bad} &amp; \\mathrm{Better} \\\\\\hline \\\\e^{i \\frac {\\pi} 2} \\quad e^{\\frac{i \\pi} 2} &amp;e^{i \\pi / 2} \\\\\\int _ {- \\frac \\pi 2}^ \\frac \\pi 2 \\sin x \\, dx &amp;\\int _ {- \\pi / 2}^{\\pi / 2}\\sin x \\, dx \\\\\\end{array}$$ 书写连分数表达式的时候，使用\\cfrac来代替\\frac或\\over。12345678910$$\\begin&#123;array&#125;&#123;c | c&#125;\\mathrm&#123;Bad(over)&#125; &amp; \\mathrm&#123;Bad(frac)&#125; &amp; \\mathrm&#123;Better(cfrac)&#125; \\\\\\hline \\\\x = a_0 + &#123; &#123;1^2&#125; \\over &#123;a_1 + &#123; &#123;2^2&#125; \\over &#123;a_2 + &#123; &#123;3^2&#125; \\over &#123;a_3 + &#123; &#123;4^4&#125; \\over &#123;a_4 + \\cdots&#125;&#125;&#125;&#125;&#125;&#125;&#125;&#125; &amp;x = a_0 + \\frac &#123;1^2&#125;&#123;a_1 + \\frac &#123;2^2&#125; &#123;a_2 + \\frac &#123;3^2&#125; &#123;a_3 + \\frac&#123;4^4&#125; &#123;a_4 + \\cdots&#125;&#125;&#125;&#125; &amp;x = a_0 + \\cfrac &#123;1^2&#125;&#123;a_1 + \\cfrac &#123;2^2&#125; &#123;a_2 + \\cfrac &#123;3^2&#125; &#123;a_3 + \\cfrac&#123;4^4&#125; &#123;a_4 + \\cdots&#125;&#125;&#125;&#125;\\end&#123;array&#125;$$ 效果 $$\\begin{array}{c | c}\\mathrm{Bad(over)} &amp; \\mathrm{Bad(frac)} &amp; \\mathrm{Better(cfrac)} \\\\\\hline \\\\x = a_0 + { {1^2} \\over {a_1 + { {2^2} \\over {a_2 + { {3^2} \\over {a_3 + { {4^4} \\over {a_4 + \\cdots}}}}}}}} &amp;x = a_0 + \\frac {1^2}{a_1 + \\frac {2^2} {a_2 + \\frac {3^2} {a_3 + \\frac{4^4} {a_4 + \\cdots}}}} &amp;x = a_0 + \\cfrac {1^2}{a_1 + \\cfrac {2^2} {a_2 + \\cfrac {3^2} {a_3 + \\cfrac{4^4} {a_4 + \\cdots}}}}\\end{array}$$ 根式 平方根。\\sqrt {x^3}：效果为$\\sqrt {x^3}$。 其他根式。\\sqrt[4] {\\frac x y}：效果为$\\sqrt[4] {\\frac x y}$。 公式的对齐有时候可能需要一系列的公式中等号对齐。需要用到$ \\begin{align} ... \\end{align}$的格式，其中需要使用&amp;来指示要对齐的位置。12345678910$$\\begin&#123;align&#125;\\sqrt&#123;37&#125;&amp;= \\sqrt&#123;\\frac &#123;73^2-1&#125; &#123;12^2&#125;&#125; \\\\&amp;= \\sqrt&#123;\\frac &#123;73^2&#125; &#123;12^2&#125; \\cdot \\frac &#123;73^2-1&#125; &#123;73^2&#125;&#125; \\\\&amp;= \\sqrt&#123;\\frac &#123;73^2&#125; &#123;12^2&#125;&#125; \\sqrt &#123;\\frac &#123;73^2-1&#125; &#123;73^2&#125;&#125; \\\\&amp;= \\frac &#123;73&#125; &#123;12&#125; \\sqrt&#123;1 - \\frac &#123;1&#125; &#123;73^2&#125;&#125; \\\\&amp;\\approx \\frac &#123;73&#125; &#123;12&#125; \\left( 1 - \\frac &#123;1&#125; &#123;2 \\cdot 73^2&#125; \\right)\\end&#123;align&#125;$$ 效果如下：$$\\begin{aligned}\\sqrt{37}&amp;= \\sqrt{\\frac {73^2-1} {12^2}} \\\\&amp;= \\sqrt{\\frac {73^2} {12^2} \\cdot \\frac {73^2-1} {73^2}} \\\\&amp;= \\sqrt{\\frac {73^2} {12^2}} \\sqrt {\\frac {73^2-1} {73^2}} \\\\&amp;= \\frac {73} {12} \\sqrt{1 - \\frac {1} {73^2}} \\\\&amp;\\approx \\frac {73} {12} \\left( 1 - \\frac {1} {2 \\cdot 73^2} \\right)\\end{aligned}$$ 公式的标记与引用使用\\tag{yourtag}来标记公式，如果后文想要引用该公式，则还需要在\\tag{yourtag}之后加上\\label{yourlabel}，例如：123$$a = x^2 - y^3 \\tag&#123;公式1&#125;\\label&#123;label1&#125;$$ 效果为：$$a = x^2 - y^3 \\tag{公式1}\\label{label1}$$如果需要引用该公式，需要使用\\eqref{label}，例如：123$$a+ y^3 \\stackrel &#123;\\eqref &#123;label1&#125;&#125; = x^2$$ 效果如下：$$a+ y^3 \\stackrel {\\eqref {label1}} = x^2$$可以看到，通过超链接可以跳转到${\\eqref {label1}} $的位置。 字体 使用\\mathbb来显示黑板粗体字: $ \\mathbb {ABCDEFGHIGKLMNOPQRSTUVWXYZ} $$ \\mathbb {abcdefghijklmnopqrstuvwxyz} $ 使用\\mathbf来显示粗体字: $ \\mathbf {ABCDEFGHIGKLMNOPQRSTUVWXYZ} $$ \\mathbf {abcdefghijklmnopqrstuvwxyz} $ 使用\\mathtt来显示打印字体 $ \\mathtt {ABCDEFGHIGKLMNOPQRSTUVWXYZ} $$ \\mathtt {abcdefghijklmnopqrstuvwxyz} $ 使用\\mathrm来显示罗马字体: $ \\mathrm {ABCDEFGHIGKLMNOPQRSTUVWXYZ} $$ \\mathrm {abcdefghijklmnopqrstuvwxyz} $ 使用\\mathcal来显示手写字体: $ \\mathcal {ABCDEFGHIGKLMNOPQRSTUVWXYZ} $$ \\mathcal {abcdefghijklmnopqrstuvwxyz} $ 使用\\mathbf来显示剧本字体: $ \\mathbf {ABCDEFGHIGKLMNOPQRSTUVWXYZ} $$ \\mathbf {abcdefghijklmnopqrstuvwxyz} $ 使用\\mathfrak来显示Fraktur字母（一种旧的德国字体）: $ \\mathfrak {ABCDEFGHIGKLMNOPQRSTUVWXYZ} $$ \\mathfrak {abcdefghijklmnopqrstuvwxyz} $ 分组通过大括号{}将操作数与符号分隔开，消除二义性。 例如：x^10的效果为$x^10$，如果在两个数字上加上大括号，x^{10}，最终效果为$x^{10}$ 空间MathJax通常有一套复杂的策略来决定公式的空间距离，直接在两届元素之间加入空格是毫无用处的。因此为了增加空间距离，使用\\,可以增加少许的空间；使用\\;可以增加更多地空间；\\quad和\\qquad分别对应更多地空间。1$ a \\, b \\; c \\quad d \\qquad e f g $ 效果如下：$ a \\, b \\; c \\quad d \\qquad e f g $ 希腊字母 大写字母 代码 小写字母 代码 $A$ A $\\alpha$ \\alpha $B$ B $\\beta$ \\beta $\\Gamma$ \\Gamma $\\gamma$ \\gamma $\\Delta$ \\Delta $\\delta$ \\delta $E$ E $\\epsilon$ \\epsilon $Z$ Z $\\zeta$ \\zeta $H$ H $\\eta$ \\eta $\\Theta$ \\Theta $\\theta$ \\theta $ \\Lambda $ \\Lambda $\\lambda$ \\lambda $M$ M $\\mu$ \\mu $N$ N $\\nu$ \\nu $ \\Xi$ \\Xi $ \\xi $ \\xi $ O$ O $\\omicron$ \\omicron $ \\Pi$ \\Pi $\\pi$ \\pi $ P$ P $\\rho$ \\rho $ \\Sigma$ \\Sigma $\\sigma$ \\sigma $ T$ T $\\tau$ \\tau $ \\Upsilon$ \\Upsilon $\\upsilon$ \\upsilon $ \\Phi$ \\Phi $\\phi$ \\phi $ X $ X $ \\chi $ \\chi $ \\Psi$ \\Psi $\\psi$ \\psi $ \\Omega$ \\Omega $\\omega$ \\omega 数学符号上标与下标上标和下标只需要在后面加上^或_，需要注意的是，如果上表或者下表不止有一个字符的话需要用大括号{}括起来。 运算符 说明 示例代码 效果 ^ 上标 $x^y$ $x^y$ _ 下标 $x_y$ $x_y$ \\mid 上下限 $\\mid _a^b$ $\\mid _a^b$ \\sideset 四周标记 $\\sideset {^1_2} {^3_4} \\bigotimes$ $\\sideset {^1_2} {^3_4} \\bigotimes$ choose 选择排列 $n+1 \\choose 2k$ $n+1 \\choose 2k$ \\binom 二项式排列 $\\binom {n+1} {2k}$ $\\binom {n+1} {2k}$ 关系比较符号 符号 代码 $ \\lt $ \\lt $ \\gt $ \\gt $ \\le $ \\le $\\ge $ \\ge $ \\neq $ \\neq $ \\not\\lt $ \\not\\lt $ \\nleq $ \\nleq $ \\not\\gt $ \\not\\gt $ \\ngeq $ \\ngeq $\\approx$ \\approx $\\equiv$ \\equiv $\\sim$ \\sim $\\cong$ \\cong $\\prec$ \\prec 运算符号 运算符 代码 $ + $ + $ -$ - $ \\times$ \\times $ \\div $ \\div $ \\pm $ pm $ \\mp $ mp $ \\cdot $ \\cdot $ \\ast $ \\ast $ \\pmod n$ \\pmod n $ \\mid $ \\mid $ \\nmid $ \\nmid $ \\sum $ \\sum $ \\prod $ \\prod $ \\coprod $ \\coprod $ \\oplus $ \\oplus $ \\odot $ \\odot $ \\otimes $ \\otimes $ \\bigoplus $ \\bigoplus $ \\bigodot $ \\bigodot $ \\bigotimes $ \\bigotimes 集合符号 运算符 代码 $ \\cup $ \\cup $ \\not\\cup $ \\not\\cup $ \\cap $ \\cap $ \\not\\cap $ \\not\\cap $ \\setminus $ \\setminus $ \\subset $ \\subset $ \\not\\subset $ not\\subset $ \\subseteq $ \\subseteq $ \\not\\subseteq $ not\\subseteq $ \\subsetneq $ \\subsetneq $ \\supset $ \\supset $ \\not\\supset $ \\not\\supset $ \\supseteq $ \\supseteq $ \\not\\supseteq $ \\not\\supseteq $ \\in $ \\in $ \\notin $ \\notin $ \\emptyset $ \\emptyset $ \\varnothing $ \\varnothing $ \\vee $ 和取 \\vee $ \\not\\vee $ 非和取 \\not\\vee $ \\wedge $ 析取 \\wedge $ \\not\\wedge $非析取 \\not\\wedge $ \\uplus $ \\uplus $ \\not\\uplus $ \\not\\uplus $ \\sqcup $ \\sqcup $ \\not\\sqcup $ \\not\\sqcup $ \\bigcup $ \\bigcup $ \\not\\bigcup $ \\not\\bigcup $ \\bigvee $ \\bigvee $ \\not\\bigvee $ \\not\\bigvee $ \\bigwedge $ \\bigwedge $ \\not\\bigwedge $ \\not\\bigwedge $ \\biguplus $ \\biguplus $ \\not\\biguplus $ \\not\\biguplus $ \\bigsqcup $ \\bigsqcup $ \\not\\bigsqcup $ \\not\\bigsqcup 箭头符号 运算符 代码 $ \\to $ \\to $ \\mapsto $ \\mapsto $ \\Rightarrow $ \\Rightarrow $ \\rightarrow $ \\rightarrow $ \\Longrightarrow $ \\Longrightarrow $ \\longrightarrow $ \\longrightarrow $ \\Leftarrow $ \\Leftarrow $ \\leftarrow $ \\leftarrow $ \\Uparrow $ \\Uparrow $ \\uparrow $ \\uparrow $ \\Downarrow $ \\Downarrow $ \\downarrow $ \\downarrow $ \\dagger $（剑标） \\dagger $ \\ddagger $（双剑标） \\ddagger 特殊符号 运算符 代码 $ \\infty $ \\infity $ \\nabla $ \\nabla $ \\partial $ \\partial $ \\approx $ \\approx $ \\sim $ \\sim $ \\simeq $ \\simeq $ \\cong $ \\cong $ \\equiv $ \\equiv $ \\prec $ \\prec $ {n+1 \\choose 2k } $ {n+1 \\choose 2k } 或 \\binom {n+1} {2k} $ \\land $ \\land $ \\lor $ \\lor $ \\lnot $ \\lnot $ \\forall $ \\forall $ \\exists $ \\exists $ \\top $ \\top $ \\bot $ \\bot $ \\vdash $ \\vdash $ \\vDash $ \\vDash $ \\star $ \\star $ \\ast $ \\ast $ \\oplus $ \\oplus $ \\circ $ \\circ $ \\bullet $ \\bullet 括号需要注意的是，原始的符号不会随着公式的大小自动缩放，可以使用\\left、\\right来自适应调整括号$()$、$[]$、$ {}$以及分隔符$|$的大小。如果需要省略部分括号内容，可以用\\left.或\\right.来代替。12345678910$$\\begin&#123;aligned&#125;( \\frac 1 2 ) &amp;= [\\frac 1 2] \\\\\\left( \\frac 1 2 \\right) &amp;= \\left[ \\frac 1 2 \\right] \\\\\\lbrace \\sum _&#123;i=0&#125;^n i^2 \\rbrace &amp;= \\langle \\frac &#123;( \\frac &#123;n&#125;&#123;2&#125; + n)(2n+1)&#125;&#123;6&#125; \\rangle \\\\\\left \\lbrace \\sum _&#123;i=0&#125;^n i^2 \\right\\rbrace &amp;= \\left\\langle \\frac &#123;\\left( \\frac &#123;n&#125;&#123;2&#125; + n \\right)(2n+1)&#125;&#123;6&#125; \\right \\rangle \\\\\\left. \\sum _&#123;i=0&#125;^n i^2 \\right\\rbrace &amp;= \\left\\langle \\frac &#123;\\left( \\frac &#123;n&#125;&#123;2&#125; + n \\right)(2n+1)&#125;&#123;6&#125; \\right. \\\\\\left. \\frac &#123;d u&#125; &#123;d x&#125; \\right| _&#123;x=0&#125; &amp;= 1\\end&#123;aligned&#125;$$ 效果如下： $$\\begin{aligned}( \\frac 1 2 ) &amp;= [\\frac 1 2] \\\\\\left( \\frac 1 2 \\right) &amp;= \\left[ \\frac 1 2 \\right] \\\\\\lbrace \\sum _{i=0}^n i^2 \\rbrace &amp;= \\langle \\frac {( \\frac {n}{2} + n)(2n+1)}{6} \\rangle \\\\\\left \\lbrace \\sum _{i=0}^n i^2 \\right\\rbrace &amp;= \\left\\langle \\frac {\\left( \\frac {n}{2} + n \\right)(2n+1)}{6} \\right \\rangle \\\\\\left . \\sum _{i=0}^n i^2 \\right\\rbrace &amp;= \\left\\langle \\frac {\\left( \\frac {n}{2} + n \\right)(2n+1)}{6} \\right . \\\\\\left. \\frac {d u} {d x} \\right| _{x=0} &amp;= 1\\end{aligned}$$ 运算符 说明 代码 $ () $ 小括号 () $ [] $ 中括号 [] $\\{ \\} $ 大括号 \\{ \\} 或\\lbrace \\rbrace $ \\langle \\rangle $ 尖括号 \\langle \\rangle $ \\lceil x \\rceil $ 上取整 \\lceil x \\rceil $ \\lfloor x \\rfloor $ 下取整 \\lfloor x \\rfloor 对数运算 运算符 示例代码 效果 \\log $\\log(x)$ $\\log(x)$ \\lg $\\lg(x)$ $\\lg(x)$ \\ln $\\ln(x)$ $\\ln(x)$ 顶部符号与连线符号 运算符 代码 $\\hat x $ \\hat x $\\widehat {xy} $ \\widehat {xy} $\\overline {xyz} $ \\overline {xyz} $\\vec {ab} $ \\vec {ab} $\\overrightarrow {abcd} $ \\overrightarrow {abcd} $ \\dot d $ \\dot d $ \\ddot d $ \\ddot d $ \\tilde a $ \\tilde a 三角运算符 运算符 说明 示例代码 效果 \\bot 垂直 $A \\bot B$ $A \\bot B$ \\angle 角 $\\angle 45$ $\\angle 45$ circ 度 $45^\\circ$ $45^\\circ$ \\sin 正弦 $\\sin 30^\\circ = 0.5$ $\\sin 30^\\circ = 0.5$ \\cos 余弦 $\\cos 90^\\circ = 0$ $\\cos 90^\\circ = 0$ \\tan 正切 $\\tan 45^\\circ = 1$ $\\tan 45^\\circ = 1$ \\arcsin 反正弦 $\\arcsin 0.5 = 30^\\circ$ $\\arcsin 0.5 = 30^\\circ$ \\arccos 反余弦 $\\arcsin 0.5 = 60^\\circ$ $\\arcsin 0.5 = 60^\\circ$ \\arctan 反正切 $\\arcsin 0.5 = 45^\\circ$ $\\arcsin 0.5 = 45^\\circ$ \\cot 余切 $\\cot$ $\\cot$ \\sec 正割 $\\sec$ $\\sec$ \\csc 余割 $\\csc$ $\\csc$ 微积分运算符 运算符 效果 \\prime $\\prime$ \\int $\\int$ \\iint $\\iint$ \\iiint $\\iiint$ \\iiiint $\\iiiint$ \\oint $\\oint$ \\lim $\\lim$ \\infty $\\infty$ \\nabla $\\nabla$ \\partial $\\partial$ 块公式显示$\\displaystyle \\lim_{x\\to\\infty}$:$\\displaystyle \\lim_{x\\to\\infty}$ 逻辑运算符 运算符 效果 \\because $\\because$ \\therefore $\\therefore$ \\land $\\land$ \\lor $\\lor$ \\lnot $\\lnot$ \\forall $\\forall$ \\exists $\\exists$ \\top $\\top$ \\bot $\\bot$ \\vdash $\\vdash$ \\vDash $\\vDash$ 其他符号 运算符 效果 \\ldots底端对齐的省略号 $\\ldots$ \\cdots中线对齐的省略号 $\\cdots$ \\vdots竖直对齐的省略号 $\\vdots$ \\ddots矩阵对齐的省略号 $\\ddots$ \\star $\\star$ \\ast $\\ast$ \\cirs $\\circ$ \\bullet $\\bullet$ \\bigstar $\\bigstar$ \\bigcirc $\\bigcirc$ \\aleph $\\aleph$ \\Im $\\Im$ \\Re $\\Re$ 表格在MathJax中插入表格需要 $$ \\begin{array} {列格式} ... \\end{array} $$，在\\begin{array}后面需要表明每一列的格式：c表示居中；l表示左对齐，r表示右对齐；|表示列分割线；\\\\表示每一行的结束；&amp;用来分割矩阵元素；\\hline表示行分割线；使用\\text{文字内容}在表格中插入文本。%来添加注释。123456789$$\\begin&#123;array&#125;&#123;c | lcr&#125;n &amp; \\text&#123;Left&#125; &amp; \\text&#123;Center&#125; &amp; \\text&#123;Right&#125; \\\\ \\hline1 &amp; 0.24 &amp; 1 &amp; 125 \\\\2 &amp; -1 &amp; 189 &amp; -8 \\\\3 &amp; -20 &amp; 2000 &amp; 1+10i\\end&#123;array&#125;$$ 效果如下：$$\\begin{array}{c | lcr}n &amp; \\text{Left} &amp; \\text{Center} &amp; \\text{Right} \\\\\\hline1 &amp; 0.24 &amp; 1 &amp; 125 \\\\2 &amp; -1 &amp; 189 &amp; -8 \\\\3 &amp; -20 &amp; 2000 &amp; 1+10i\\end{array}$$ 矩阵使用$$ \\begin{matrix} ... \\end{matrix} $$，\\\\表示每一行的结尾，&amp;用来分割元素1234567$$\\begin&#123;matrix&#125;1 &amp; 0 &amp; 0 \\\\0 &amp; 1 &amp; 0 \\\\0 &amp; 0 &amp; 1 \\\\\\end&#123;matrix&#125;$$ 效果如下：$$\\begin{matrix}1 &amp; 0 &amp; 0 \\\\0 &amp; 1 &amp; 0 \\\\0 &amp; 0 &amp; 1 \\\\\\end{matrix}$$ 如果需要加括号，可以使用上面提到的符号，除此之外还可以通过将matrix替换来实现： 替换为\\pmatrix得到：$ \\begin{pmatrix}1 &amp; 0 &amp; 0 \\\\0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{pmatrix} $ 替换为\\bmatrix得到：$ \\begin{bmatrix}1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} $ 替换为\\Bmatrix得到：$ \\begin{Bmatrix}1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{Bmatrix} $ 替换为\\vmatrix得到：$ \\begin{vmatrix}1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{vmatrix} $ 替换为\\Vmatrix得到：$ \\begin{Vmatrix}1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{Vmatrix} $ 如果想省略一些像，可以使用\\cdots，\\ddots，vdots，来省略行元素，对角元素和列元素：12345678$$\\begin&#123;pmatrix&#125;1 &amp; a_1 &amp; a_1^2 &amp; \\cdots &amp; a_1^n \\\\1 &amp; a_2 &amp; a_2^2 &amp; \\cdots &amp; a_2^n \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\1 &amp; a_n &amp; a_n^2 &amp; \\cdots &amp; a_n^n \\\\\\end&#123;pmatrix&#125;$$ 效果如下：$$\\begin{pmatrix}1 &amp; a_1 &amp; a_1^2 &amp; \\cdots &amp; a_1^n \\\\1 &amp; a_2 &amp; a_2^2 &amp; \\cdots &amp; a_2^n \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\1 &amp; a_n &amp; a_n^2 &amp; \\cdots &amp; a_n^n \\\\\\end{pmatrix}$$如果是增光矩阵，可以使用前面介绍的创建表格是方式来实现：12345678$$\\left[\\begin&#123;array&#125;&#123;cc|c&#125;1 &amp; 2 &amp; 3 \\\\4 &amp; 5 &amp; 6\\end&#123;array&#125;\\right]$$ $$\\left[\\begin{array}{cc|c}1 &amp; 2 &amp; 3 \\\\4 &amp; 5 &amp; 6\\end{array}\\right]$$文本段内使用矩阵，则需要使用\\big(\\begin{smallmatrix} ... \\end{smallmatrix}\\bigr)123$$\\bigl(\\begin&#123;smallmatrix&#125; a &amp; b \\\\ c &amp; d \\end&#123;smallmatrix&#125; \\bigr)$$ $$\\bigl(\\begin{smallmatrix} a &amp; b \\\\ c &amp; d \\end{smallmatrix} \\bigr)$$ 方程组使用\\begin{aray} ... \\end{array}与\\left{ ... \\rigth.配合可以表示方程组：12345678910$$\\left \\&#123;\\begin&#123;array&#125;&#123;c&#125;a_1 x + b_1 y + c_1 z = d_1 + e_1 \\\\a_2 x + b_2 y = d_2 \\\\a_3 x + b_3 y + c_3 z = d_3\\end&#123;array&#125;\\right.$$ 效果如下： $$\\left \\lbrace\\begin{array}{c}a_1 x + b_1 y + c_1 z = d_1 + e_1 \\\\a_2 x + b_2 y = d_2 \\\\a_3 x + b_3 y + c_3 z = d_3\\end{array}\\right.$$ 此外，还可以使用\\begin{cases} ... \\end{cases}来表示同样的方程组：1234567$$\\begin&#123;cases&#125;a_1 x + b_1 y + c_1 z = d_1 + e_1 \\\\a_2 x + b_2 y = d_2 \\\\a_3 x + b_3 y + c_3 z = d_3\\end&#123;cases&#125;$$ 效果如下：$$\\begin{cases}a_1 x + b_1 y + c_1 z = d_1 + e_1 \\\\a_2 x + b_2 y = d_2 \\\\a_3 x + b_3 y + c_3 z = d_3\\end{cases}$$如果需要对齐方程组中的$=$号，可以使用\\begin{aligned} ... \\end{aligned}：123456789$$\\left\\&#123;\\begin&#123;aligned&#125;a_1 x + b_1 y + c_1 z &amp;= d_1 + e_1 \\\\a_2 x + b_2 y &amp;= d_2 \\\\a_3 x + b_3 y + c_3 z &amp;= d_3\\end&#123;aligned&#125;\\right.$$ 效果如下：$$\\left\\lbrace\\begin{aligned}a_1 x + b_1 y + c_1 z &amp;= d_1 + e_1 \\\\a_2 x + b_2 y &amp;= d_2 \\\\a_3 x + b_3 y + c_3 z &amp;= d_3\\end{aligned}\\right.$$如果需要对齐等号和项，可以使用\\begin{array} {列样式} ... \\end{array}：12345678910$$\\left\\&#123;\\begin&#123;array&#125;&#123;l l&#125;a_1 x + b_1 y + c_1 z &amp;= d_1 + e_1 \\\\a_2 x + b_2 y &amp;= d_2 \\\\a_3 x + b_3 y + c_3 z &amp;= d_3\\end&#123;array&#125;\\right.$$ 效果如下：$$\\left\\lbrace\\begin{array}{l l}a_1 x + b_1 y + c_1 z &amp;= d_1 + e_1 \\\\a_2 x + b_2 y &amp;= d_2 \\\\a_3 x + b_3 y + c_3 z &amp;= d_3\\end{array}\\right.$$ 分类表达式有些时候，定义函数需要分情况给出表达式，可以使用$\\begin{cases} ... \\end{cases}$。其中，\\\\用来分类，&amp;用来表示要对齐的位置。1234567$$f(n) =\\begin&#123;cases&#125;n/2 , &amp; \\text&#123;if $n$ is over&#125; \\\\3n + 1 &amp; , \\text&#123;if $n$ is odd &#125;\\end&#123;cases&#125;$$ $$f(n) =\\begin{cases}n/2 , &amp; \\text{if $n$ is over} \\\\3n + 1 &amp; , \\text{if $n$ is odd }\\end{cases}$$如果想要更多的竖直空间，可以用\\\\[2ex] （3ex，4ex也可以，1ex相当于原始距离）代替 \\\\：1234567$$f(n) =\\begin&#123;cases&#125;n/2 , &amp; \\text&#123;if $n$ is over&#125; \\\\[2ex]3n + 1 &amp; , \\text&#123;if $n$ is odd &#125;\\end&#123;cases&#125;$$ $$f(n) =\\begin{cases}\\frac {n} {2} , &amp; \\text{if $n$ is over} \\\\[2ex]3n + 1 &amp; , \\text{if $n$ is odd }\\end{cases}$$上述公式的括号也可以移动到右侧，不过需要使用$\\begin{arry} ... \\end{arry}$来实现：12345678910$$\\left.\\begin&#123;array&#125;&#123;l&#125;\\text&#123;if $n$ is even:&#125; &amp; n/2 \\\\[5ex]\\text&#123;if $n$ is odd:&#125; &amp; 3n+1\\end&#123;array&#125;\\right \\rbrace=f(n)$$ 效果如下：$$\\left.\\begin{array}{l}\\text{if $n$ is even:} &amp; n/2 \\\\[5ex]\\text{if $n$ is odd:} &amp; 3n+1\\end{array}\\right \\rbrace=f(n)$$ 绝对值和模 \\lvert，\\rvert用来表示绝对值。例如$\\lvert x \\rvert$ 表示：$\\lvert x \\rvert$ \\lVert，\\rVert用来表示绝对值。例如$\\lVert x \\rVert$ 表示：$\\lVert x \\rVert$ 高亮为了显著表示某公式，可以使用\\bbox来高亮表达式：1234567$$\\bbox[yellow]&#123;e^x = \\lim_&#123;n \\to \\infty&#125; \\left( 1 + \\frac &#123;x&#125; &#123;n&#125; \\right) ^n\\qquad (1)&#125;$$ 效果如下：$$\\bbox[yellow]{e^x = \\lim_{n \\to \\infty} \\left( 1 + \\frac {x} {n} \\right) ^n\\qquad (1)}$$ 1234567$$\\bbox[border:2px solid red]&#123;e^x = \\lim_&#123;n \\to \\infty&#125; \\left( 1 + \\frac &#123;x&#125; &#123;n&#125; \\right) ^n\\qquad (1)&#125;$$ 效果如下：$$\\bbox[border:2px solid red]{e^x = \\lim_{n \\to \\infty} \\left( 1 + \\frac {x} {n} \\right) ^n\\qquad (1)}$$ 颜色 代码 效果 $\\color{black}{Hello World!}$ $\\color{black}{Hello World!}$ $\\color{gray}{Hello World!}$ $\\color{gray}{Hello World!}$ $\\color{silver}{Hello World!}$ $\\color{silver}{Hello World!}$ $\\color{white}{Hello World!}$ $\\color{white}{Hello World!}$ $\\color{maroom}{Hello World!}$ $\\color{maroom}{Hello World!}$ $\\color{red}{Hello World!}$ $\\color{red}{Hello World!}$ $\\color{yellow}{Hello World!}$ $\\color{yellow}{Hello World!}$ $\\color{lime}{Hello World!}$ $\\color{lime}{Hello World!}$ $\\color{olive}{Hello World!}$ $\\color{olive}{Hello World!}$ $\\color{green}{Hello World!}$ $\\color{green}{Hello World!}$ $\\color{teal}{Hello World!}$ $\\color{teal}{Hello World!}$ $\\color{aqua}{Hello World!}$ $\\color{aqua}{Hello World!}$ $\\color{blue}{Hello World!}$ $\\color{blue}{Hello World!}$ $\\color{navy}{Hello World!}$ $\\color{navy}{Hello World!}$ $\\color{purple}{Hello World!}$ $\\color{purple}{Hello World!}$ $\\color{fuchsia}{Hello World!}$ $\\color{fuchsia}{Hello World!}$","tags":[{"name":"MathJax","slug":"MathJax","permalink":"http://luojiaji.github.io/tags/MathJax/"}]},{"title":"Dueling DQN设计与实现","date":"2017-08-06T02:34:09.000Z","path":"2017/08/06/Dueling-DQN设计与实现/","text":"本文介绍Deep Q Network的一种改进形式dueling DQN的设计与实现过程：Dueling DQN将DQN中神经网络的中间层拆分成两个网络，一个为Value，一个为Advantage，然后将两个网络的值相加得到最终的网络的输出。网络结构如下图所示： 在Dueling DQN中，神经网络的输出由下面的公式确定：$$Q(s,a;\\theta,\\alpha,\\beta) = V(s;\\theta,\\beta)+A(s,a;\\theta,\\alpha)$$ 下面介绍Dueling DQN的具体实现过程： 用到的库如下：Python：3.5.3TensorFlow：1.0.1gym：0.8.1 本文依旧用到gym中的CartPole-v0来完成算法。 代码大部分与DQN的代码相似，只是建立网络模型的部分不同，神将网络结构设计的代码部分如下：1234567891011121314151617181920212223def _build_net(self): def build_layers(s, c_names, n_l1, w_initializer, b_initializer): with tf.variable_scope('l1'): w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names) b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names) l1 = tf.nn.relu(tf.matmul(s, w1) + b1) # Dueling DQN with tf.variable_scope('Value'): w2 = tf.get_variable('w2', [n_l1, 1], initializer=w_initializer, collections=c_names) b2 = tf.get_variable('b2', [1, 1], initializer=b_initializer, collections=c_names) self.V = tf.matmul(l1, w2) + b2 with tf.variable_scope('Advantage'): w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names) b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names) self.A = tf.matmul(l1, w2) + b2 with tf.variable_scope('Q'): out = self.V + (self.A - tf.reduce_mean(self.A, axis=1, keep_dims=True)) # Q = V(s) + A(s,a) return out 其他部分的代码与DQN中的代码基本相似。 最终运行程序可以得到如下的损失函数： Dueling DQN的网络结构如下图： Dueling DQN网络结构 DQN网络结构 从结构图中可以看到，Dueling DQN中将DQN中的l2节点改变成了Advantage,Value和Q三个结构。 参考资料： Dueling DQN (Tensorflow)","tags":[{"name":"RL","slug":"RL","permalink":"http://luojiaji.github.io/tags/RL/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"}]},{"title":"Double DQN设计与实现","date":"2017-07-22T01:20:36.000Z","path":"2017/07/22/Double-DQN设计与实现/","text":"今天介绍Deep Q Network的一个改进版本 DoubleDQN算法的原理和实现过程。DQN算法中在计算需要通过在目标网络中得到下一个动作的状态值，但是由于目标网络的更新有一定的滞后性，所以导致算法中存在一定的误差。而Double DQN则是在估计网络中计算下一个动作，并用目标网络得到相应的状态值，这样可以提高算法的实时性。 在DQN中状态值的更新公式为：$$Y_t ^{DQN} = R_{t+1} + \\gamma \\max_a Q(S_{t+1},a;\\theta_t^-)$$在Double DQN中，状态值的跟新公式为：$$Y_t ^{DoubleDQN} = R_{t+1} + \\gamma Q(S_{t+1},arg\\max_a Q(S_{t+1},a;\\theta_t);\\theta_t^-)$$ 下面通过编程来实现Double DQN算法。 用到的库如下：Python：3.5.3TensorFlow：1.0.1gym：0.8.1 本次依然使用gym中的CartPole-v0的环境来实现算法。代码大部分跟DQN的代码相同，只是在神经网络学习的时候状态值的更新方法不同，算法的学习部分如下：1234567891011121314151617181920212223242526272829303132333435363738def learn(self): if self.learn_step_counter % self.replace_target_iter == 0: self._replace_target_params() # print('\\ntarget_params_replaced\\n') if self.memory_counter &gt; self.memory_size: sample_index = np.random.choice(self.memory_size, size=self.batch_size) else: sample_index = np.random.choice(self.memory_counter, size=self.batch_size) batch_memory = self.memory[sample_index, :] q_next, q_eval4next = self.sess.run( [self.q_next, self.q_eval], feed_dict=&#123;self.s_: batch_memory[:, -self.n_features:], # next observation self.s: batch_memory[:, -self.n_features:]&#125;) # next observation q_eval = self.sess.run(self.q_eval, &#123;self.s: batch_memory[:, :self.n_features]&#125;) q_target = q_eval.copy() batch_index = np.arange(self.batch_size, dtype=np.int32) eval_act_index = batch_memory[:, self.n_features].astype(int) reward = batch_memory[:, self.n_features + 1] if self.double_q: max_act4next = np.argmax(q_eval4next, axis=1) # the action that brings the highest value is evaluated by q_eval selected_q_next = q_next[batch_index, max_act4next] # Double DQN, select q_next depending on above actions else: selected_q_next = np.max(q_next, axis=1) # the natural DQN q_target[batch_index, eval_act_index] = reward + self.gamma * selected_q_next _, self.cost = self.sess.run([self._train_op, self.loss], feed_dict=&#123;self.s: batch_memory[:, :self.n_features], self.q_target: q_target&#125;) self.cost_his.append(self.cost) self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon &lt; self.epsilon_max else self.epsilon_max self.learn_step_counter += 1 其他的代码部分与DQN中的代码基本一致。 最终程序可疑达到预期的效果，损失函数图如下： Double DQN的网络结构如下： 可以发现Double DQN的网络结构和Deep Q Network的网络结构相同。不同的是图中Q_target的更新方式。 参考资料： Double DQN (Tensorflow)","tags":[{"name":"RL","slug":"RL","permalink":"http://luojiaji.github.io/tags/RL/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"}]},{"title":"Policy Gradients设计与实现","date":"2017-06-29T12:12:11.000Z","path":"2017/06/29/Policy-Gradients设计与实现/","text":"本文主要介绍强化学习中Policy Gradients算法的设计与实现过程。跟上一篇介绍DQN的文章类似，本文也是基于gym环境和TensorFlow来实现来实现Policy Gradients算法，用到的环境也是CartPole-v0的立杆子的环境。具体Policy Gradients的算法过程可以参考之前的文章，今天主要介绍算法的实现过程。 代码同样分为两部分，首先是建立Policy Gradients更新过程，然后建立CartPole-v0环境并对模型进行训练。 涉及的主要模块版本号：Python：3.5.3TensorFlow：1.0.1gym：0.8.1 首先建立Policy Gradients模型。导入模块和一些初始设置：123456import numpy as npimport tensorflow as tf# reproduciblenp.random.seed(1)tf.set_random_seed(1) 然后定义PolicyGradient类：123456789101112131415161718192021222324252627class PolicyGradient: def __init__( self, n_actions, n_features, learning_rate=0.01, reward_decay=0.95, output_graph=False, ): self.n_actions = n_actions self.n_features = n_features self.lr = learning_rate self.gamma = reward_decay self.ep_obs, self.ep_as, self.ep_rs = [], [], [] self._build_net() self.sess = tf.Session() if output_graph: # $ tensorboard --logdir=logs # http://0.0.0.0:6006/ # tf.train.SummaryWriter soon be deprecated, use following tf.summary.FileWriter(\"logs/\", self.sess.graph) self.sess.run(tf.global_variables_initializer()) 然后建立网络模型，与DQN的模型类似，在输入和输出之间添加了一个10个隐藏节点的隐藏层。1234567891011121314151617181920212223242526272829303132333435def _build_net(self): with tf.name_scope('inputs'): self.tf_obs = tf.placeholder(tf.float32, [None, self.n_features], name=\"observations\") self.tf_acts = tf.placeholder(tf.int32, [None, ], name=\"actions_num\") self.tf_vt = tf.placeholder(tf.float32, [None, ], name=\"actions_value\") # fc1 layer = tf.layers.dense( inputs=self.tf_obs, units=10, activation=tf.nn.tanh, # tanh activation kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.3), bias_initializer=tf.constant_initializer(0.1), name='fc1' ) # fc2 all_act = tf.layers.dense( inputs=layer, units=self.n_actions, activation=None, kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.3), bias_initializer=tf.constant_initializer(0.1), name='fc2' ) self.all_act_prob = tf.nn.softmax(all_act, name='act_prob') # use softmax to convert to probability with tf.name_scope('loss'): # to maximize total reward (log_p * R) is to minimize -(log_p * R), and the tf only have minimize(loss) neg_log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=all_act, labels=self.tf_acts) # this is negative log of chosen action # or in this way: # neg_log_prob = tf.reduce_sum(-tf.log(self.all_act_prob)*tf.one_hot(self.tf_acts, self.n_actions), axis=1) loss = tf.reduce_mean(neg_log_prob * self.tf_vt) # reward guided loss with tf.name_scope('train'): self.train_op = tf.train.AdamOptimizer(self.lr).minimize(loss) 然后建立动作选择函数：1234def choose_action(self, observation): prob_weights = self.sess.run(self.all_act_prob, feed_dict=&#123;self.tf_obs: observation[np.newaxis, :]&#125;) action = np.random.choice(range(prob_weights.shape[1]), p=prob_weights.ravel()) # select action w.r.t the actions prob return action 代码中，在运行网络模型得到动作的权重之前，需要注意一点，就是要将状态值observation添加一个维度再传递给TensorFlow的网络模型中。np.random.choice可以根据p参数给出的概率来选择动作。 然后建立状态存储函数，用来存储状态值，动作值，和奖励值：1234def store_transition(self, s, a, r): self.ep_obs.append(s) self.ep_as.append(a) self.ep_rs.append(r) Policy Gradients不需要存储动作的下一个状态值是因为算法在更新的时候直接使用一组完整的状态动作值对，每次学习时前后的状态本身就是有联系的，并不像DQN中采用随机采样的方法来实现。 然后建立学习函数：12345678910111213def learn(self): # discount and normalize episode reward discounted_ep_rs_norm = self._discount_and_norm_rewards() # train on episode self.sess.run(self.train_op, feed_dict=&#123; self.tf_obs: np.vstack(self.ep_obs), # shape=[None, n_obs] self.tf_acts: np.array(self.ep_as), # shape=[None, ] self.tf_vt: discounted_ep_rs_norm, # shape=[None, ] &#125;) self.ep_obs, self.ep_as, self.ep_rs = [], [], [] # empty episode data return discounted_ep_rs_norm 每次学习完成之后需要清空存储空间一边下一次训练时从新保存新的状态动作值。在学习之前需要将奖励值正则化，因此还需要建立奖励值正则化的函数：123456789101112def _discount_and_norm_rewards(self): # discount episode rewards discounted_ep_rs = np.zeros_like(self.ep_rs) running_add = 0 for t in reversed(range(0, len(self.ep_rs))): running_add = running_add * self.gamma + self.ep_rs[t] discounted_ep_rs[t] = running_add # normalize episode rewards discounted_ep_rs -= np.mean(discounted_ep_rs) discounted_ep_rs /= np.std(discounted_ep_rs) return discounted_ep_rs 到此，Policy Gradients的模型已经建立完成。下面就需要导入gym环境对模型进行训练。 同样也需要导入涉及的模块123import gymfrom PolicyGradients import PolicyGradientimport matplotlib.pyplot as plt 然后设置一些基本的参数并导入CartPole-v0环境123456DISPLAY_REWARD_THRESHOLD = 400 # renders environment if total episode reward is greater then this thresholdRENDER = False # rendering wastes timeenv = gym.make('CartPole-v0')env.seed(1) # reproducible, general Policy gradient has high varianceenv = env.unwrapped DISPLAY_REWARD_THRESHOLD设置了一个奖励门限，当奖励值大于门限的时候开始显示图形界面，因为奖励值小的时候说明训练效果还不是太好，所以为了节省时间就忽略的界面显示。 然后实例化PolicyGradient：1234567RL = PolicyGradient( n_actions=env.action_space.n, n_features=env.observation_space.shape[0], learning_rate=0.02, reward_decay=0.99, # output_graph=True,) 最后就是对模型进行训练：123456789101112131415161718192021222324252627282930313233for i_episode in range(3000): observation = env.reset() while True: if RENDER: env.render() action = RL.choose_action(observation) observation_, reward, done, info = env.step(action) RL.store_transition(observation, action, reward) if done: ep_rs_sum = sum(RL.ep_rs) if 'running_reward' not in globals(): running_reward = ep_rs_sum else: running_reward = running_reward * 0.99 + ep_rs_sum * 0.01 if running_reward &gt; DISPLAY_REWARD_THRESHOLD: RENDER = True # rendering print(\"episode:\", i_episode, \" reward:\", int(running_reward)) vt = RL.learn() if i_episode == 0: plt.plot(vt) # plot the episode vt plt.xlabel('episode steps') plt.ylabel('normalized state-action value') plt.show() break observation = observation_ 运行程序可疑看到，当训练迭代到87步左后的时候模型已经达到比较好的效果。 设置PolicyGradient类中的参数output_graph=True，可疑在TensorBoard中看到PolicyGradient网络模型的结构： 参考资料： Policy Gradients 算法更新 Policy Gradients 思维决策","tags":[{"name":"RL","slug":"RL","permalink":"http://luojiaji.github.io/tags/RL/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"}]},{"title":"Deep Q Network设计与实现","date":"2017-06-28T02:06:51.000Z","path":"2017/06/28/Deep-Q-Network设计与实现/","text":"之前写了关于DQN（Deep Q Network）的算法分析，今天用Python以及相关的库来设计并实现一个DQN。 本文主要基于OpenAI的开源库gym中的环境再结合TensorFlow来设计与实现DQN。用到了gym中CartPole-v0的立杆子的环境。将每一步得到的状态和奖励值传递给TensorFlow中建立好的QDN网络，并对收集到的状态奖励值进行训练。算法的具体流程参考之前介绍DQN的那篇文章。今天主要介绍代码的实现。 代码主要分为两个部分，首先是建立DQN网络模型，然后导入CartPole-v0环境通过其中返回的状态值和奖励值训练DQN网络。最终实现杆子尽可能长时间地保持不倒。 涉及的主要模块版本号：Python：3.5.3TensorFlow：1.0.1gym：0.8.1 新建DQN.py来建立网络模型以及相关的操作。首先导入模块以及一些初始设置：123456import numpy as npimport pandas as pdimport tensorflow as tfnp.random.seed(1)tf.set_random_seed(1) 然后建立建立DQN模型的类以及一些全局变量：123456789101112131415161718192021222324252627282930313233343536373839404142434445# Deep Q Network off-policyclass DeepQNetwork: def __init__( self, n_actions, n_features, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9, replace_target_iter=300, memory_size=500, batch_size=32, e_greedy_increment=None, output_graph=False, ): self.n_actions = n_actions self.n_features = n_features self.lr = learning_rate self.gamma = reward_decay self.epsilon_max = e_greedy self.replace_target_iter = replace_target_iter self.memory_size = memory_size self.batch_size = batch_size self.epsilon_increment = e_greedy_increment self.epsilon = 0 if e_greedy_increment is not None else self.epsilon_max # total learning step self.learn_step_counter = 0 self.cost = 0 # initialize zero memory [s, a, r, s_] self.memory = np.zeros((self.memory_size, n_features * 2 + 2)) # consist of [target_net, evaluate_net] self._build_net() self.sess = tf.Session() if output_graph: # $ tensorboard --logdir=logs # tf.train.SummaryWriter soon be deprecated, use following tf.summary.FileWriter(\"logs/\", self.sess.graph) self.sess.run(tf.global_variables_initializer()) self.cost_his = [] self.memory建立一个全0的矩阵用来存储状态和奖励值。大小为500x10（self.memory = 500 ; n_feature*2+2 = 10）。每一行保存当前状态，奖励值，动作，和采取动作之后的下一个状态。self.epsilon表示动作选择时的贪婪值。 然后建立DQN网络，一共需要建立两个网络，一个是目标网络，一个是估计网络，网络的输入为模型中的状态值，输出为动作值，其中包含一个隐藏节点为10的隐藏层。1234567891011121314151617181920212223242526272829303132333435363738394041424344def _build_net(self): # ------------------ build evaluate_net ------------------ self.s = tf.placeholder(tf.float32, [None, self.n_features], name='s') # input self.q_target = tf.placeholder(tf.float32, [None, self.n_actions], name='Q_target') # for calculating loss with tf.variable_scope('eval_net'): # c_names(collections_names) are the collections to store variables c_names, n_l1, w_initializer, b_initializer = \\ ['eval_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 10, \\ tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1) # config of layers # first layer. collections is used later when assign to target net with tf.variable_scope('l1'): w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names) b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names) l1 = tf.nn.relu(tf.matmul(self.s, w1) + b1) # second layer. collections is used later when assign to target net with tf.variable_scope('l2'): w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names) b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names) self.q_eval = tf.matmul(l1, w2) + b2 with tf.variable_scope('loss'): self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval)) with tf.variable_scope('train'): self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss) # ------------------ build target_net ------------------ self.s_ = tf.placeholder(tf.float32, [None, self.n_features], name='s_') # input with tf.variable_scope('target_net'): # c_names(collections_names) are the collections to store variables c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES] # first layer. collections is used later when assign to target net with tf.variable_scope('l1'): w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names) b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names) l1 = tf.nn.relu(tf.matmul(self.s_, w1) + b1) # second layer. collections is used later when assign to target net with tf.variable_scope('l2'): w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names) b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names) self.q_next = tf.matmul(l1, w2) + b2 然后创建函数用来保存转移信息（当前状态，动作，奖励，下一个状态）：12345678910def store_transition(self, s, a, r, s_): if not hasattr(self, 'memory_counter'): self.memory_counter = 0 transition = np.hstack((s, [a, r], s_)) # replace the old memory with new memory index = self.memory_counter % self.memory_size self.memory[index, :] = transition self.memory_counter += 1 下面建立状态选择函数，函数需要传入当前的状态值用来作为网络的输入，并调用评估网络得到对应的动作：1234567891011def choose_action(self, observation): # to have batch dimension when feed into tf placeholder observation = observation[np.newaxis, :] if np.random.uniform() &lt; self.epsilon: # forward feed the observation and get q value for every actions actions_value = self.sess.run(self.q_eval, feed_dict=&#123;self.s: observation&#125;) action = np.argmax(actions_value) else: action = np.random.randint(0, self.n_actions) return action DQN的动作选择采用贪婪策略，$\\epsilon$的概率选择动作值函数的最大值，$1-\\epsilon$的概率随机选择动作值，这样可以使模型对未知的状态进行探索。 然后建立网络替换函数，当达到一定步数的时候（replace_target_iter =300）需要将估计网络的参数赋给目标网络：1234def _replace_target_params(self): t_params = tf.get_collection('target_net_params') e_params = tf.get_collection('eval_net_params') self.sess.run([tf.assign(t, e) for t, e in zip(t_params, e_params)]) 然后建立学习函数，用来对模型参数进行学习：1234567891011121314151617181920212223242526272829303132333435363738def learn(self): # check to replace target parameters if self.learn_step_counter % self.replace_target_iter == 0: self._replace_target_params() # print('\\ntarget_params_replaced\\n') # sample batch memory from all memory if self.memory_counter &gt; self.memory_size: sample_index = np.random.choice(self.memory_size, size=self.batch_size) else: sample_index = np.random.choice(self.memory_counter, size=self.batch_size) batch_memory = self.memory[sample_index, :] q_next, q_eval = self.sess.run( [self.q_next, self.q_eval], feed_dict=&#123; self.s_: batch_memory[:, -self.n_features:], # fixed params self.s: batch_memory[:, :self.n_features], # newest params &#125;) # change q_target w.r.t q_eval's action q_target = q_eval.copy() batch_index = np.arange(self.batch_size, dtype=np.int32) eval_act_index = batch_memory[:, self.n_features].astype(int) reward = batch_memory[:, self.n_features + 1] q_target[batch_index, eval_act_index] = reward + self.gamma * np.max(q_next, axis=1) # train eval network _, self.cost = self.sess.run([self._train_op, self.loss], feed_dict=&#123;self.s: batch_memory[:, :self.n_features], self.q_target: q_target&#125;) self.cost_his.append(self.cost) # increasing epsilon self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon &lt; self.epsilon_max else self.epsilon_max self.learn_step_counter += 1 代码中，当达到参数替换的迭代数之后（replace_target_iter）需要替换目标网络的参数。然后在状态的存储空间中随机选择训练数据（self.batch_size = 32）。然后调用目标网络和估计网络分别计算当前状态的Q值和下一状态的Q值。在下一状态的Q值中选择最大值并乘以衰减系数$\\gamma$加上奖励值就得到新的的当前状态的Q值，两个=当前状态的Q值的差作为误差函数来对DQN网络进行训练。 为了将每一步训练的损失值话出来，需要建立一个损失函数：123456def plot_cost(self): import matplotlib.pyplot as plt plt.plot(np.arange(len(self.cost_his)), self.cost_his) plt.ylabel('Cost') plt.xlabel('training steps') plt.show() 到这里未知，DQN的模型以及需要的函数就建立完成了。下面进入第二步，导入CartPole-v0的立杆子的环境并对DQN网络模型进行训练。 首先在新建的Python文件中导入gym模块以及建立好的DQN模型，并且导入CartPole-v0：12345678import gymfrom DQN import DeepQNetworkenv = gym.make('CartPole-v0')env = env.unwrappedprint(env.action_space)print(env.observation_space) 代码中env = env.unwrapped用来解除环境的一些默认限制。打印函数可以看到该环境有两个离散的动作值和四个状态值。 然后实例化建立好的DQN模型：123456RL = DeepQNetwork(n_actions=env.action_space.n, n_features=env.observation_space.shape[0], learning_rate=0.01, e_greedy=0.9, replace_target_iter=100, memory_size=2000, e_greedy_increment=0.001, output_graph=False) 最后就是迭代过程：1234567891011121314151617181920212223242526272829303132333435total_steps = 0for i_episode in range(100): observation = env.reset() while True: env.render() action = RL.choose_action(observation) observation_, reward, done, info = env.step(action) x, x_dot, theta, theta_dot = observation_ # the smaller theta and closer to center the better r1 = (env.x_threshold - abs(x))/env.x_threshold - 0.8 r2 = (env.theta_threshold_radians - abs(theta))/env.theta_threshold_radians - 0.5 reward = r1 + r2 RL.store_transition(observation, action, reward, observation_) if total_steps &gt; 1000: RL.learn() if done: print('episode: ', i_episode, 'cost: ', round(RL.cost, 4), ' epsilon: ', round(RL.epsilon, 2)) break observation = observation_ total_steps += 1RL.plot_cost() 代码中将状态值作为奖励值，（默认的将离职返回为-1，不适合作为DQN的奖励值。），每一步都要保存状态信息，当总步数大于1000步的时候开始对DQN模型进行训练，前面的步用来收集用于学习的状态信息。每一次迭代结束之后打印迭代数，损失值，和贪婪值。最后完成100次迭代之后，画出损失值的图。 将DeepQNetwork类中的参数output_graph=True，可以在TensorBoard中看到DQN网络的结构图： 参考资料： OpenAI DQN 神经网络 (Tensorflow) OpenAI gym 环境库 (Tensorflow)","tags":[{"name":"RL","slug":"RL","permalink":"http://luojiaji.github.io/tags/RL/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"}]},{"title":"Python数据处理教程","date":"2017-06-12T07:22:58.000Z","path":"2017/06/12/Python数据处理教程/","text":"本文主要介绍Python在数据处理中用到的库和方法。这篇文章本质上是一篇翻译文，原文是Python Numpy Tutorial。 Python是一门优秀的通用编程语言，再结合一些流行的库（numpy，scipy，matplotlib）它会成为强大的科学计算环境。 Pythonpython是一门高级的动态类型的多模式编程语言。Python代码经常被说成是伪代码，因为它可以让你用可读性很强的几行代码来实现一些有力的想法。下面是一个用Python实现的经典的快速排序算法。1234567891011def quicksort(arr): if len(arr) &lt;= 1: return arr pivot = arr[len(arr) // 2] left = [x for x in arr if x &lt; pivot] middle = [x for x in arr if x == pivot] right = [x for x in arr if x &gt; pivot] return quicksort(left) + middle + quicksort(right)print(quicksort([3,6,8,10,1,2,1]))# Prints \"[1, 1, 2, 3, 6, 8, 10]\" Python版本目前，Python有两个不同的受支持版本2.7和3.5。令人困惑的是Python3.0引入了许多向后不兼容的改变，因此2.7版本下的代码在3.5中不一定有效，反之亦然。本教程的代码使用的是Python3.5。可以通过命令行运行Python --version来检查你的Python版本。 基本数据类型像大多数编程语言一样，Python有许多基本的数据类型，包括整型、浮点型、布尔型和字符串。这些数据类型的操作方式和其他编程语言类似。数字：整型和浮点型的工作方式和其他编程语言类似：1234567891011121314x = 3print(type(x)) # Prints \"&lt;class 'int'&gt;\"print(x) # Prints \"3\"print(x + 1) # Addition; prints \"4\"print(x - 1) # Subtraction; prints \"2\"print(x * 2) # Multiplication; prints \"6\"print(x ** 2) # Exponentiation; prints \"9\"x += 1print(x) # Prints \"4\"x *= 2print(x) # Prints \"8\"y = 2.5print(type(y)) # Prints \"&lt;class 'float'&gt;\"print(y, y + 1, y * 2, y ** 2) # Prints \"2.5 3.5 5.0 6.25\" 注意：与其他编程语言不同，Python没有自加(x++)和自减(x--)操作。Python也有内建的复数类型，具体内容可以参考官方文档布尔值：Python可以通过英文单词来实现常用的布尔逻辑操作，而不是使用符号(&amp;&amp;,||,等):1234567t = Truef = Falseprint(type(t)) # Prints \"&lt;class 'bool'&gt;\"print(t and f) # Logical AND; prints \"False\"print(t or f) # Logical OR; prints \"True\"print(not t) # Logical NOT; prints \"False\"print(t != f) # Logical XOR; prints \"True\" 字符串：Python可以很好地支持字符串操作：12345678hello = 'hello' # String literals can use single quotesworld = \"world\" # or double quotes; it does not matter.print(hello) # Prints \"hello\"print(len(hello)) # String length; prints \"5\"hw = hello + ' ' + world # String concatenationprint(hw) # prints \"hello world\"hw12 = '%s %s %d' % (hello, world, 12) # sprintf style string formattingprint(hw12) # prints \"hello world 12\" 字符串对象有许多非常有用的方法，比如：12345678s = \"hello\"print(s.capitalize()) # Capitalize a string; prints \"Hello\"print(s.upper()) # Convert a string to uppercase; prints \"HELLO\"print(s.rjust(7)) # Right-justify a string, padding with spaces; prints \" hello\"print(s.center(7)) # Center a string, padding with spaces; prints \" hello \"print(s.replace('l', '(ell)')) # Replace all instances of one substring with another; # prints \"he(ell)(ell)o\"print(' world '.strip()) # Strip leading and trailing whitespace; prints \"world\" 你可以通过官方文档来查找所有的字符串方法。 容器Python包含几个内建的容器类型：列表、字典、集合和元组。 列表Python中列表等效于数组，并且可以调整大小以及包含其他类型的元素：123456789xs = [3, 1, 2] # Create a listprint(xs, xs[2]) # Prints \"[3, 1, 2] 2\"print(xs[-1]) # Negative indices count from the end of the list; prints \"2\"xs[2] = 'foo' # Lists can contain elements of different typesprint(xs) # Prints \"[3, 1, 'foo']\"xs.append('bar') # Add a new element to the end of the listprint(xs) # Prints \"[3, 1, 'foo', 'bar']\"x = xs.pop() # Remove and return the last element of the listprint(x, xs) # Prints \"bar [3, 1, 'foo']\" 你也可以在官方文档中查找列表的详细资料。切片：除了每次可以获取列表中的元素之外，Python还提供了简明的语法来获取子列表。这就是所谓的切片：123456789nums = list(range(5)) # range is a built-in function that creates a list of integersprint(nums) # Prints \"[0, 1, 2, 3, 4]\"print(nums[2:4]) # Get a slice from index 2 to 4 (exclusive); prints \"[2, 3]\"print(nums[2:]) # Get a slice from index 2 to the end; prints \"[2, 3, 4]\"print(nums[:2]) # Get a slice from the start to index 2 (exclusive); prints \"[0, 1]\"print(nums[:]) # Get a slice of the whole list; prints \"[0, 1, 2, 3, 4]\"print(nums[:-1]) # Slice indices can be negative; prints \"[0, 1, 2, 3]\"nums[2:4] = [8, 9] # Assign a new sublist to a sliceprint(nums) # Prints \"[0, 1, 8, 9, 4]\" 我们还将会在numpy的数部分作中遇到切片操作。循环：你可以像下面的例子一样通过列表中的元素来实现循环：1234animals = ['cat', 'dog', 'monkey']for animal in animals: print(animal)# Prints \"cat\", \"dog\", \"monkey\", each on its own line. 如果想要得到每一个元素在循环体中的索引，可以使用内建函数enumerate():1234animals = ['cat', 'dog', 'monkey']for idx, animal in enumerate(animals): print('#%d: %s' % (idx + 1, animal))# Prints \"#1: cat\", \"#2: dog\", \"#3: monkey\", each on its own line 列表解析：在编程过程中，通常我们会将一种类型的数据转换为其他类型，考虑下面计算平方数的例子：12345nums = [0, 1, 2, 3, 4]squares = []for x in nums: squares.append(x ** 2)print(squares) # Prints [0, 1, 4, 9, 16] 你可以利用简单地利用列表解析来实现：123nums = [0, 1, 2, 3, 4]squares = [x ** 2 for x in nums]print(squares) # Prints [0, 1, 4, 9, 16] 列表解析可以包含条件：123nums = [0, 1, 2, 3, 4]even_squares = [x ** 2 for x in nums if x % 2 == 0]print(even_squares) # Prints \"[0, 4, 16]\" 字典字典存储键值对(关键词，数值)，类似于Java中的Map和JavaScript中的对象。可以通过下面的例子来使用字典：12345678910d = &#123;'cat': 'cute', 'dog': 'furry'&#125; # Create a new dictionary with some dataprint(d['cat']) # Get an entry from a dictionary; prints \"cute\"print('cat' in d) # Check if a dictionary has a given key; prints \"True\"d['fish'] = 'wet' # Set an entry in a dictionaryprint(d['fish']) # Prints \"wet\"# print(d['monkey']) # KeyError: 'monkey' not a key of dprint(d.get('monkey', 'N/A')) # Get an element with a default; prints \"N/A\"print(d.get('fish', 'N/A')) # Get an element with a default; prints \"wet\"del d['fish'] # Remove an element from a dictionaryprint(d.get('fish', 'N/A')) # \"fish\" is no longer a key; prints \"N/A\" 可以在官方文档中查找需要的有关字典的信息。循环：可以简单地通过字典中的关键字来进行迭代：12345d = &#123;'person': 2, 'cat': 4, 'spider': 8&#125;for animal in d: legs = d[animal] print('A %s has %d legs' % (animal, legs))# Prints \"A person has 2 legs\", \"A cat has 4 legs\", \"A spider has 8 legs\" 如果想要得到字典中的关键字和相对应的数值，可以使用items方法来实现：1234d = &#123;'person': 2, 'cat': 4, 'spider': 8&#125;for animal, legs in d.items(): print('A %s has %d legs' % (animal, legs))# Prints \"A person has 2 legs\", \"A cat has 4 legs\", \"A spider has 8 legs\" 字典解析：与列表解析类似，可以方便地构造字典。例如：123nums = [0, 1, 2, 3, 4]even_num_to_square = &#123;x: x ** 2 for x in nums if x % 2 == 0&#125;print(even_num_to_square) # Prints \"&#123;0: 0, 2: 4, 4: 16&#125;\" 集合集合是不同元素的无序集合。思考下面的例子：12345678910animals = &#123;'cat', 'dog'&#125;print('cat' in animals) # Check if an element is in a set; prints \"True\"print('fish' in animals) # prints \"False\"animals.add('fish') # Add an element to a setprint('fish' in animals) # Prints \"True\"print(len(animals)) # Number of elements in a set; prints \"3\"animals.add('cat') # Adding an element that is already in the set does nothingprint(len(animals)) # Prints \"3\"animals.remove('cat') # Remove an element from a setprint(len(animals)) # Prints \"2\" 同样可以在官方文档中查找更详细的信息。循环：通过集合迭代和通过列表迭代有相同的语法。但是由于集合是无序的，因此不能假设所访问的集合中元素的顺序：1234animals = &#123;'cat', 'dog', 'fish'&#125;for idx, animal in enumerate(animals): print('#%d: %s' % (idx + 1, animal))# Prints \"#1: fish\", \"#2: dog\", \"#3: cat\" 集合解析：与列表解析和字典解析类似，我们可以使用集合解析快速地构造集合：123from math import sqrtnums = &#123;int(sqrt(x)) for x in range(30)&#125;print(nums) # Prints \"&#123;0, 1, 2, 3, 4, 5&#125;\" 元组元组是(不可改变的)有序的值列表，元组在许多方面和列表类似，最重要的一点不同是元组可以作为字典中的关键字和集合中的元素，而列表不行。下面是一些小例子：12345d = &#123;(x, x + 1): x for x in range(10)&#125; # Create a dictionary with tuple keyst = (5, 6) # Create a tupleprint(type(t)) # Prints \"&lt;class 'tuple'&gt;\"print(d[t]) # Prints \"5\"print(d[(1, 2)]) # Prints \"1\" 关于元组的官方文档 函数Python中的函数通过关键字def来定义。例如：1234567891011def sign(x): if x &gt; 0: return 'positive' elif x &lt; 0: return 'negative' else: return 'zero'for x in [-1, 0, 1]: print(sign(x))# Prints \"negative\", \"zero\", \"positive\" 通常会采用可选关键字参数来定义函数，例如：12345678def hello(name, loud=False): if loud: print('HELLO, %s!' % name.upper()) else: print('Hello, %s' % name)hello('Bob') # Prints \"Hello, Bob\"hello('Fred', loud=True) # Prints \"HELLO, FRED!\" 有关Python函数的更多信息可以参考官方文档 类Python中定义类的语法非常简洁：12345678910111213141516class Greeter(object): # Constructor def __init__(self, name): self.name = name # Create an instance variable # Instance method def greet(self, loud=False): if loud: print('HELLO, %s!' % self.name.upper()) else: print('Hello, %s' % self.name)g = Greeter('Fred') # Construct an instance of the Greeter classg.greet() # Call an instance method; prints \"Hello, Fred\"g.greet(loud=True) # Call an instance method; prints \"HELLO, FRED!\" Python中类的官方文档 NumpyNumpy是Python科学计算的核心库。它提供可高性能的多维数组对象以及处理多维数组的工具。如果你已经熟悉MATLAB，你会发现教程对你入门Numpy非常有用。 数组Numpy中的数组是类型相同，由非负整数构成的元组索引的值的网格。维数是数组的秩(rank)，矩阵的形状(shape)是一个整数元组，表示每一个维度的大小。可以通过嵌套Python列表的方式来初始化numpy数组，可以通过方括号来获取数组中的元素：123456789101112import numpy as npa = np.array([1, 2, 3]) # Create a rank 1 arrayprint(type(a)) # Prints \"&lt;class 'numpy.ndarray'&gt;\"print(a.shape) # Prints \"(3,)\"print(a[0], a[1], a[2]) # Prints \"1 2 3\"a[0] = 5 # Change an element of the arrayprint(a) # Prints \"[5, 2, 3]\"b = np.array([[1,2,3],[4,5,6]]) # Create a rank 2 arrayprint(b.shape) # Prints \"(2, 3)\"print(b[0, 0], b[0, 1], b[1, 0]) # Prints \"1 2 4\" Numpy也提供了很多函数用来创建数组：1234567891011121314151617181920import numpy as npa = np.zeros((2,2)) # Create an array of all zerosprint(a) # Prints \"[[ 0. 0.] # [ 0. 0.]]\"b = np.ones((1,2)) # Create an array of all onesprint(b) # Prints \"[[ 1. 1.]]\"c = np.full((2,2), 7) # Create a constant arrayprint(c) # Prints \"[[ 7. 7.] # [ 7. 7.]]\"d = np.eye(2) # Create a 2x2 identity matrixprint(d) # Prints \"[[ 1. 0.] # [ 0. 1.]]\"e = np.random.random((2,2)) # Create an array filled with random valuesprint(e) # Might print \"[[ 0.91940167 0.08143941] # [ 0.68744134 0.87236687]]\" 可以通过官方文档来查找更多数组创建的方法。 数组索引Numpy提供了几种数组索引的方法。切片：类似于Python中的列表，numpy中的数组也可以切片。由于数组有时候是多维的，所以一定要明确数组中每一维度上的切片：12345678910111213141516171819import numpy as np# Create the following rank 2 array with shape (3, 4)# [[ 1 2 3 4]# [ 5 6 7 8]# [ 9 10 11 12]]a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])# Use slicing to pull out the subarray consisting of the first 2 rows# and columns 1 and 2; b is the following array of shape (2, 2):# [[2 3]# [6 7]]b = a[:2, 1:3]# A slice of an array is a view into the same data, so modifying it# will modify the original array.print(a[0, 1]) # Prints \"2\"b[0, 0] = 77 # b[0, 0] is the same piece of data as a[0, 1]print(a[0, 1]) # Prints \"77\" 可以混合使用整数索引和切片索引。然而，这样做需要数组的秩要低于原始数组。注意，这和MATLAB中数组切片的操作不同：123456789101112131415161718192021222324import numpy as np# Create the following rank 2 array with shape (3, 4)# [[ 1 2 3 4]# [ 5 6 7 8]# [ 9 10 11 12]]a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])# Two ways of accessing the data in the middle row of the array.# Mixing integer indexing with slices yields an array of lower rank,# while using only slices yields an array of the same rank as the# original array:row_r1 = a[1, :] # Rank 1 view of the second row of arow_r2 = a[1:2, :] # Rank 2 view of the second row of aprint(row_r1, row_r1.shape) # Prints \"[5 6 7 8] (4,)\"print(row_r2, row_r2.shape) # Prints \"[[5 6 7 8]] (1, 4)\"# We can make the same distinction when accessing columns of an array:col_r1 = a[:, 1]col_r2 = a[:, 1:2]print(col_r1, col_r1.shape) # Prints \"[ 2 6 10] (3,)\"print(col_r2, col_r2.shape) # Prints \"[[ 2] # [ 6] # [10]] (3, 1)\" 整数数组索引：当使用切片来索引numpy的数组时，结果被视为是原始阵列的一个子阵列。相反，整数数组索引可以利用其它数组中的数据来构造任意的数组。例如：1234567891011121314151617import numpy as npa = np.array([[1,2], [3, 4], [5, 6]])# An example of integer array indexing.# The returned array will have shape (3,) andprint(a[[0, 1, 2], [0, 1, 0]]) # Prints \"[1 4 5]\"# The above example of integer array indexing is equivalent to this:print(np.array([a[0, 0], a[1, 1], a[2, 0]])) # Prints \"[1 4 5]\"# When using integer array indexing, you can reuse the same# element from the source array:print(a[[0, 0], [1, 1]]) # Prints \"[2 2]\"# Equivalent to the previous integer array indexing exampleprint(np.array([a[0, 1], a[0, 1]])) # Prints \"[2 2]\" 整数数组索引的一个有用的技巧是用用来选择或改变矩阵中每一列的元素1234567891011121314151617181920212223import numpy as np# Create a new array from which we will select elementsa = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])print(a) # prints \"array([[ 1, 2, 3], # [ 4, 5, 6], # [ 7, 8, 9], # [10, 11, 12]])\"# Create an array of indicesb = np.array([0, 2, 0, 1])# Select one element from each row of a using the indices in bprint(a[np.arange(4), b]) # Prints \"[ 1 6 7 11]\"# Mutate one element from each row of a using the indices in ba[np.arange(4), b] += 10print(a) # prints \"array([[11, 2, 3], # [ 4, 5, 16], # [17, 8, 9], # [10, 21, 12]]) 布尔数组索引：布尔数组索引可以挑出数组中的任意元素。通常这用索引用来选择数组中满足一定条件的数组。例如：1234567891011121314151617181920import numpy as npa = np.array([[1,2], [3, 4], [5, 6]])bool_idx = (a &gt; 2) # Find the elements of a that are bigger than 2; # this returns a numpy array of Booleans of the same # shape as a, where each slot of bool_idx tells # whether that element of a is &gt; 2.print(bool_idx) # Prints \"[[False False] # [ True True] # [ True True]]\"# We use boolean array indexing to construct a rank 1 array# consisting of the elements of a corresponding to the True values# of bool_idxprint(a[bool_idx]) # Prints \"[3 4 5 6]\"# We can do all of the above in a single concise statement:print(a[a &gt; 2]) # Prints \"[3 4 5 6]\" 想要了解更多关于numpy数组索引的信息，可以阅读官方文档 数据类型每一个numpy数组是一个有相同类型元素的网格。Numpy提供了许多用来构造数组的数据类型。当你在创建数组的时候Numpy会尝试猜测数组的类型，但是构造数组通常包括一个可选参数来明确数组的数据类型。例如：12345678910import numpy as npx = np.array([1, 2]) # Let numpy choose the datatypeprint(x.dtype) # Prints \"int64\"x = np.array([1.0, 2.0]) # Let numpy choose the datatypeprint(x.dtype) # Prints \"float64\"x = np.array([1, 2], dtype=np.int64) # Force a particular datatypeprint(x.dtype) # Prints \"int64\" 更多关于numpy的数据类型请参考官方文档 数据计算在Numpy模块中基本的针对数组元素的数学公式操作可以通过运算符重载或函数来实现：123456789101112131415161718192021222324252627282930313233import numpy as npx = np.array([[1,2],[3,4]], dtype=np.float64)y = np.array([[5,6],[7,8]], dtype=np.float64)# Elementwise sum; both produce the array# [[ 6.0 8.0]# [10.0 12.0]]print(x + y)print(np.add(x, y))# Elementwise difference; both produce the array# [[-4.0 -4.0]# [-4.0 -4.0]]print(x - y)print(np.subtract(x, y))# Elementwise product; both produce the array# [[ 5.0 12.0]# [21.0 32.0]]print(x * y)print(np.multiply(x, y))# Elementwise division; both produce the array# [[ 0.2 0.33333333]# [ 0.42857143 0.5 ]]print(x / y)print(np.divide(x, y))# Elementwise square root; produces the array# [[ 1. 1.41421356]# [ 1.73205081 2. ]]print(np.sqrt(x)) 注意，不像在MATLAB中，*是元素间相乘，而不是矩阵相乘。我们使用dot函数来计算向量的内积，来实现矩阵乘法。dot可以通过模块函数或者数组对象的方法来实现：123456789101112131415161718192021import numpy as npx = np.array([[1,2],[3,4]])y = np.array([[5,6],[7,8]])v = np.array([9,10])w = np.array([11, 12])# Inner product of vectors; both produce 219print(v.dot(w))print(np.dot(v, w))# Matrix / vector product; both produce the rank 1 array [29 67]print(x.dot(v))print(np.dot(x, v))# Matrix / matrix product; both produce the rank 2 array# [[19 22]# [43 50]]print(x.dot(y))print(np.dot(x, y)) Numpy在矩阵运算中提供了许多有用的函数，最常用的函数之一是sum:1234567import numpy as npx = np.array([[1,2],[3,4]])print(np.sum(x)) # Compute sum of all elements; prints \"10\"print(np.sum(x, axis=0)) # Compute sum of each column; prints \"[4 6]\"print(np.sum(x, axis=1)) # Compute sum of each row; prints \"[3 7]\" 可以在官方文档中查看完整的数学函数列表。除了使用数组来计算数学函数之外，通常需要改变数组形状或者其他队数组中数据的操作，最简单的例子是矩阵的转置操作；通过数组对象的T转置可以简单地实现矩阵的转置。123456789101112import numpy as npx = np.array([[1,2], [3,4]])print(x) # Prints \"[[1 2] # [3 4]]\"print(x.T) # Prints \"[[1 3] # [2 4]]\"# Note that taking the transpose of a rank 1 array does nothing:v = np.array([1,2,3])print(v) # Prints \"[1 2 3]\"print(v.T) # Prints \"[1 2 3]\" Numpy提供了许多函数来对数组进行操作，完整的函数列表请参考官方文档 广播广播是一种非常强大的机制，可以允许numpy中不同形状的数组执行算术运算。通常情况下当有一个小数组和一个大数组时，想要用小数组在大数组上多次执行某些操作。比如，想给矩阵的每一行加上常数向量。方法如下：123456789101112131415161718import numpy as np# We will add the vector v to each row of the matrix x,# storing the result in the matrix yx = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])v = np.array([1, 0, 1])y = np.empty_like(x) # Create an empty matrix with the same shape as x# Add the vector v to each row of the matrix x with an explicit loopfor i in range(4): y[i, :] = x[i, :] + v# Now y is the following# [[ 2 2 4]# [ 5 5 7]# [ 8 8 10]# [11 11 13]]print(y) 然而当矩阵x非常大的时候，Python中计算循环会变得很慢。注意到在矩阵x的每一行加上向量v等效于通过垂直复制v来构造矩阵vv，然后对x和vv执行元素间求和。实现方法如下：12345678910111213141516import numpy as np# We will add the vector v to each row of the matrix x,# storing the result in the matrix yx = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])v = np.array([1, 0, 1])vv = np.tile(v, (4, 1)) # Stack 4 copies of v on top of each otherprint(vv) # Prints \"[[1 0 1] # [1 0 1] # [1 0 1] # [1 0 1]]\"y = x + vv # Add x and vv elementwiseprint(y) # Prints \"[[ 2 2 4 # [ 5 5 7] # [ 8 8 10] # [11 11 13]]\" Numpy广播允许执行这样的操作而不必创造多重复制的v，使用广播来实现：1234567891011import numpy as np# We will add the vector v to each row of the matrix x,# storing the result in the matrix yx = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])v = np.array([1,0,1])y = x + v # Add v to each row of x using broadcastingprint(y) # Prints \"[[ 2 2 4] # [ 5 5 7] # [ 8 8 10] # [11 11 13]]\" 即使x的形状是(4,3)而且v的形状是(3,)，但现行方程y = x + v由于广播机制同样有效。这个线性方程仿佛v的形状实际上是(4,3)，其中每一行都是v的复制，然后在执行元素间求和。两个矩阵执行广播需要遵循以下规则： 如果数组具有不同的秩，用1来填充秩较低的数组的形状，直到数组具有相同的长度。 数组在这一维度中被称为兼容的，如果两个数组在某一维度中的大小的是相同的，或者其中一个数组的在某一维度中的大小是1。 如果数组在所有维度上都是兼容的，则数组可以执行广播操作合并在一起。 广播操作之后，数组的形状等于两个输入数组形状元素的最大值。 在任何维度中，如果一个数组的形状为1并且另一个数组的形状大于1，第一个数组沿这个维度进行复制操作。 如果以上解释不明白的话，请参考官方文档的解释或者其他解释支持广播功能被称作通用功能，可以在官方文档中查看所有通用功能。下面是一些广播功能的应用：123456789101112131415161718192021222324252627282930313233343536373839404142import numpy as np# Compute outer product of vectorsv = np.array([1,2,3]) # v has shape (3,)w = np.array([4,5]) # w has shape (2,)# To compute an outer product, we first reshape v to be a column# vector of shape (3, 1); we can then broadcast it against w to yield# an output of shape (3, 2), which is the outer product of v and w:# [[ 4 5]# [ 8 10]# [12 15]]print(np.reshape(v, (3, 1)) * w)# Add a vector to each row of a matrixx = np.array([[1,2,3], [4,5,6]])# x has shape (2, 3) and v has shape (3,) so they broadcast to (2, 3),# giving the following matrix:# [[2 4 6]# [5 7 9]]print(x + v)# Add a vector to each column of a matrix# x has shape (2, 3) and w has shape (2,).# If we transpose x then it has shape (3, 2) and can be broadcast# against w to yield a result of shape (3, 2); transposing this result# yields the final result of shape (2, 3) which is the matrix x with# the vector w added to each column. Gives the following matrix:# [[ 5 6 7]# [ 9 10 11]]print((x.T + w).T)# Another solution is to reshape w to be a column vector of shape (2, 1);# we can then broadcast it directly against x to produce the same# output.print(x + np.reshape(w, (2, 1)))# Multiply a matrix by a constant:# x has shape (2, 3). Numpy treats scalars as arrays of shape ();# these can be broadcast together to shape (2, 3), producing the# following array:# [[ 2 4 6]# [ 8 10 12]]print(x * 2) 广播功能可以使代码更加简洁和高效，因此可以尽可能地使用这用方法。 以上是Numpy中重要内容的简明概述，但实际远不止如此。可以在numpy参考中查看更多关于numpy的资料。 SciPyNumpy提供了高性能的多维数组的基本计算和操作工具，Scipy在这基础上，提供了大量用来操作numpy数组的函数，在不同的科学和工程领域都十分有用。最有效的了解SciPy的方法是阅读官方文档，这里会重点介绍SciPy中常用的部分。 图像操作SciPy提供可一些图像操作的基本功能。例如，将磁盘中的图片读取到numpy数组中，将数组中的图像写入到磁盘中，以及改变图片的大小。下面是一些用来展示以上功能的小例子：12345678910111213141516171819from scipy.misc import imread, imsave, imresize# Read an JPEG image into a numpy arrayimg = imread('assets/cat.jpg')print(img.dtype, img.shape) # Prints \"uint8 (400, 248, 3)\"# We can tint the image by scaling each of the color channels# by a different scalar constant. The image has shape (400, 248, 3);# we multiply it by the array [1, 0.95, 0.9] of shape (3,);# numpy broadcasting means that this leaves the red channel unchanged,# and multiplies the green and blue channels by 0.95 and 0.9# respectively.img_tinted = img * [1, 0.95, 0.9]# Resize the tinted image to be 300 by 300 pixels.img_tinted = imresize(img_tinted, (300, 300))# Write the tinted image back to diskimsave('assets/cat_tinted.jpg', img_tinted) 原始图片 修改颜色和大小之后的图片 Matlab文件函数scipy.io.loadmat和scipy.io.savemat可以对MATLAB文件进行读写，详细说明请参考官方文档 两点间距离Scipy定义了许多函数用来计算集合中坐标点之间的距离函数scipy.spatial.distance.pdist可以计算集合中所有点之间的距离：123456789101112131415161718import numpy as npfrom scipy.spatial.distance import pdist, squareform# Create the following array where each row is a point in 2D space:# [[0 1]# [1 0]# [2 0]]x = np.array([[0, 1], [1, 0], [2, 0]])print(x)# Compute the Euclidean distance between all rows of x.# d[i, j] is the Euclidean distance between x[i, :] and x[j, :],# and d is the following array:# [[ 0. 1.41421356 2.23606798]# [ 1.41421356 0. 1. ]# [ 2.23606798 1. 0. ]]d = squareform(pdist(x, 'euclidean'))print(d) 关于这个函数的详细资料可以阅读官方文档 MatplotlibMatplotlib是一个绘图库，本节内容将简明介绍matplotlib.pyplot模块，该模块提供了与MATLAB类似的绘图系统。类似的函数(scipy.spatial.distance.cdist)计算两个集合之间点的距离。官方文档 绘图matplotlib中最重要的函数是plot，该函数可以绘制2D数据，例如“12345678910import numpy as npimport matplotlib.pyplot as plt# Compute the x and y coordinates for points on a sine curvex = np.arange(0, 3 * np.pi, 0.1)y = np.sin(x)# Plot the points using matplotlibplt.plot(x, y)plt.show() # You must call plt.show() to make graphics appear. 运行上面的代码可以得到下面的图： 仅仅需要少量的额外工作就可以简单地绘制多条曲线，并且添加标题，图例和坐标轴12345678910111213141516import numpy as npimport matplotlib.pyplot as plt# Compute the x and y coordinates for points on sine and cosine curvesx = np.arange(0, 3 * np.pi, 0.1)y_sin = np.sin(x)y_cos = np.cos(x)# Plot the points using matplotlibplt.plot(x, y_sin)plt.plot(x, y_cos)plt.xlabel('x axis label')plt.ylabel('y axis label')plt.title('Sine and Cosine')plt.legend(['Sine', 'Cosine'])plt.show() 可以在官方文档中阅读关于plot的更多资料。 子图使用subplot函数可以在一张图片上显示不同事物。例子如下：1234567891011121314151617181920212223import numpy as npimport matplotlib.pyplot as plt# Compute the x and y coordinates for points on sine and cosine curvesx = np.arange(0, 3 * np.pi, 0.1)y_sin = np.sin(x)y_cos = np.cos(x)# Set up a subplot grid that has height 2 and width 1,# and set the first such subplot as active.plt.subplot(2, 1, 1)# Make the first plotplt.plot(x, y_sin)plt.title('Sine')# Set the second subplot as active, and make the second plot.plt.subplot(2, 1, 2)plt.plot(x, y_cos)plt.title('Cosine')# Show the figure.plt.show() 有关subplot的更多信息请参考官方文档 图像可以使用imshow函数来显示图像，例如：12345678910111213141516171819import numpy as npfrom scipy.misc import imread, imresizeimport matplotlib.pyplot as pltimg = imread('assets/cat.jpg')img_tinted = img * [1, 0.95, 0.9]# Show the original imageplt.subplot(1, 2, 1)plt.imshow(img)# Show the tinted imageplt.subplot(1, 2, 2)# A slight gotcha with imshow is that it might give strange results# if presented with data that is not uint8. To work around this, we# explicitly cast the image to uint8 before displaying it.plt.imshow(np.uint8(img_tinted))plt.show()","tags":[{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"}]},{"title":"基于TensorFlow的循环神经网络设计","date":"2017-06-08T09:38:54.000Z","path":"2017/06/08/基于TensorFlow的循环神经网络设计/","text":"循环神经网络(RNN)是区别于卷积神经网络的一种网络结构。适用于自然语言处理，文本分析，机器翻译等领域。循环神经网络出现于20世纪80年代，但是早期应用有限，随着神经网络结构的进步和硬件的支持，RNN变得越来越流行。循环神经网络对时间序列数据比较有效，今天用TensorFlow实现一个循环神经网络，数据依旧使用手写体数据。 今天用到的模块和版本号：Python版本：3.5.3Tensorflow版本：1.0.1 第一步，导入数据12from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets('MNIST_data', one_hot=True) 然后定义一些参数123456789# 超参数lr = 0.001 # 学习率training_iters = 1000 # 迭代次数batch_size = 128 # 批大小n_inputs = 28 # 输入数据大小n_steps = 28 # 步长n_hidden_units = 128 # 隐藏层节点数n_classes = 10 # 分类数量 然后定义神经网络中的权重和偏置123456789101112weights = &#123; # (28, 128) 'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])), # (128, 10) 'out': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))&#125;biases = &#123; # (128, ) 'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])), # (10, ) 'out': tf.Variable(tf.constant(0.1, shape=[n_classes, ]))&#125; 代码中权重初始化为服从正态分布的随机数，偏置初始化为常数0.1 然后定义神经网络的输入和输出12x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])y = tf.placeholder(tf.float32, [None, n_classes]) 用占位符定义循环神经网络的输入和标签输出，这个输出并不是神经网络的输出值，而是数据的标签值，计算结果直接由神经网络输出。 然后就到了关键部分，定义循环神经网络：1234567891011121314151617181920212223def RNN(X, weights, biases): # hidden layer for input to cell # transpose the inputs shape from # X ==&gt; (128 batch * 28 steps, 28 inputs) X = tf.reshape(X, [-1, n_inputs]) # into hidden # X_in = (128 batch * 28 steps, 128 hidden) X_in = tf.matmul(X, weights['in']) + biases['in'] # X_in ==&gt; (128 batch, 28 steps, 128 hidden) X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units]) # basic LSTM Cell. lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units) init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32) outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, X_in, initial_state=init_state, time_major=False) outputs = tf.unstack(tf.transpose(outputs, [1, 0, 2])) results = tf.matmul(outputs[-1], weights['out']) + biases['out'] # shape = (128, 10) return results 代码中tf.reshape()用来改变数据的维度，将(128,28,28)的三维向量改为(128*28,28)的二维向量。然后经过输入层之后再将数据转换三维的。tf.contrib.rnn.BasicLSTMCell()调用LSTM循环神经网络单元。然后用tf.nn.dynamic_rnn()创建一个由循环神经网络单元组成的循环神经网络。tf.transpose()用来对矩阵进行转换。tf.unstack()用来将张量数据解开。最后用tf.matmul()计算输出层的结果。 然后调用设计好的神经网络并计算损失函数和优化方法，然后计算预测输出和准确率：123456pred = RNN(x, weights, biases)cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))train_op = tf.train.AdamOptimizer(lr).minimize(cost)correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) 最后对模型进行训练，每隔20步计算并打印模型的识别效率。1234567891011121314151617181920with tf.Session() as sess: # tf.initialize_all_variables() no long valid from # 2017-03-02 if using tensorflow &gt;= 0.12 init = tf.global_variables_initializer() sess.run(init) step = 0 while step &lt; training_iters: batch_xs, batch_ys = mnist.train.next_batch(batch_size) batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs]) sess.run([train_op], feed_dict=&#123; x: batch_xs, y: batch_ys, &#125;) if step % 20 == 0: print(step,sess.run(accuracy, feed_dict=&#123; x: batch_xs, y: batch_ys, &#125;)) step += 1 最终模型的识别率可以达到97%左右。 参考资料： 《TensorFlow实战》 循环神经网络(RNN, Recurrent Neural Networks)介绍 RNN LSTM 循环神经网络 (分类例子)","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"ML","slug":"ML","permalink":"http://luojiaji.github.io/tags/ML/"}]},{"title":"基于TensorFlow的AutoEncoder网络设计","date":"2017-05-27T02:23:41.000Z","path":"2017/05/27/基于TensorFlow的AutoEncoder网络设计/","text":"Autoencoder是一种无监督的学习方法，通过编码过程自动提取数据的高阶特征，并用于分析与识别。 AutoEncoder(自编码)可以对数据进行非监督学习，首先通过encoder对数据进行压缩，然后再通过decoder对压缩数据进行恢复，并通过恢复数据与原始数据之间的误差来训练神经网络，从而可以实现网络对数据的特征提取。网络提取的中间压缩数据有点类似于PCA(主成分分析)的方法，都是从数据中提取有效信息。然后训练完成之后利用encoder部分便可以对数据进行特征提取，得到的特征数据可以用于后续的数据分析与识别。 AutoEncoder的过程如下图，前半部分是Encoder结构，后半部分是Decoder部分。 AutoEncoder结构图 下面用TensorFlow来实现一个AutoEncoder网络。 今天用到的模块和版本号：Python版本：3.5.3Tensorflow版本：1.0.1 首先导入模块和数据 1234567import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt# 导入 MNIST data手写体数据库from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(\"MNIST_data\", one_hot=False) 然后设置一些用到的参数的值12345678910111213learning_rate = 0.01 # 学习效率training_epochs = 20 # 训练的迭代次数batch_size = 256 # 每一批训练的数据大小display_step = 1 # 显示步进examples_to_show = 10 # 测试数据显示数量n_input = 784 # 输入数据的大小 手写体数据为28*28 = 784# 隐藏层节点数量n_hidden_1 = 128n_hidden_2 = 64n_hidden_3 = 10n_hidden_4 = 2 AutoEncoder中设计了4个编码层和4个解码层，编码层和解码层一一对应。 然后设置AutoEncoder网络的权重和偏置12345678910111213141516171819202122weights = &#123; 'encoder_h1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1],)), 'encoder_h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],)), 'encoder_h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3],)), 'encoder_h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4],)), 'decoder_h1': tf.Variable(tf.truncated_normal([n_hidden_4, n_hidden_3],)), 'decoder_h2': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_2],)), 'decoder_h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_1],)), 'decoder_h4': tf.Variable(tf.truncated_normal([n_hidden_1, n_input],)),&#125;biases = &#123; 'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])), 'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])), 'encoder_b3': tf.Variable(tf.random_normal([n_hidden_3])), 'encoder_b4': tf.Variable(tf.random_normal([n_hidden_4])), 'decoder_b1': tf.Variable(tf.random_normal([n_hidden_3])), 'decoder_b2': tf.Variable(tf.random_normal([n_hidden_2])), 'decoder_b3': tf.Variable(tf.random_normal([n_hidden_1])), 'decoder_b4': tf.Variable(tf.random_normal([n_input])),&#125; 代码中，用tf.Variable()来创建变量，并用tf.truncated_normal()截尾正态分布随机值来初始化权重，并用tf.random_normal()正态分布来初始化偏置。 然后设计AutoEncoder的网络结构,记忆误差函数和训练函数12345678910111213141516171819202122232425262728293031323334# 创建 encoder 结构def encoder(x): layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1'])) layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2'])) layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['encoder_h3']), biases['encoder_b3'])) layer_4 = tf.add(tf.matmul(layer_3, weights['encoder_h4']), biases['encoder_b4']) return layer_4# 创建 decoder 结构def decoder(x): layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1'])) layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2'])) layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['decoder_h3']), biases['decoder_b3'])) layer_4 = tf.nn.sigmoid(tf.add(tf.matmul(layer_3, weights['decoder_h4']), biases['decoder_b4'])) return layer_4# 把Encoder部分和Decoder部分组合在一起encoder_op = encoder(X)decoder_op = decoder(encoder_op)y_pred = decoder_op # 输出预测值y_true = X # 原始数据# Define loss and optimizer, minimize the squared errorcost = tf.reduce_mean(tf.pow(y_true - y_pred, 2)) # 定义代价函数optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost) # 定义优化方法 代码中tf.matmul()用来计算数据与权值相乘的结果，tf.add()用来计算tf.matmul()得到结果加上偏置。在每个隐藏层之间加上tf.nn.sigmoid()作为激活函数(Activation function) 网络结构定义好之后就可以对网络进行训练了。123456789101112sess = tf.Session() init = tf.global_variables_initializer() # 定义初始化sess.run(init) # 运行初始化total_batch = int(mnist.train.num_examples/batch_size) # 计算批数量for epoch in range(training_epochs): # 迭代循环 for i in range(total_batch): # 批循环 batch_xs, batch_ys = mnist.train.next_batch(batch_size) # 得到每一批训练的数据 _, c = sess.run([optimizer, cost], feed_dict=&#123;X: batch_xs&#125;) # 运行优化器并且计算代价值 print(\"Epoch:\", '%02d' % (epoch+1),\"cost=\", \"&#123;:.9f&#125;\".format(c)) # 打印迭代次数和损失值print(\"Optimization Finished!\") 代码中，根据前面定义的参数，需要运行20次迭代来进行训练，在每次迭代过程中在将数据分批对网络参数进行优化，total_batch计算得到每次迭代中需要多少批数据(数据总量除以每一批需要的数据量),然后通过mnist.train.next_batch() 得到每一批的数据，并对网络参数进行优化。 然后用10组数据来测试一下网络解码之后的数据和原始数据之间的差别，并显出出来。123456789encode_decode = sess.run(y_pred, feed_dict=&#123;X: mnist.test.images[:examples_to_show]&#125;) # 运行编码和解码的程序 得到恢复的数据f, a = plt.subplots(2, 10, figsize=(10, 2)) # 将原始数据和解压之后的数据显示出来，for i in range(examples_to_show): a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28))) # 第一行显示原始数据 a[1][i].imshow(np.reshape(encode_decode[i], (28, 28))) # 第二行显示AutoEcodoer压缩并解压之后的数据 a[0][i].axis('off') # 关闭坐标轴显示 a[1][i].axis('off')plt.show() # 显示图像 结果如下图，第一行是原始数据，第二行是Decoder解压缩之后的数据。 Decoder部分得到数据与原始数据对比 可以看出AutoEncoder解码得到的数据和原始数据的差别并不大。 然后只用AutoEncoder中的encoder部分来对测试数据进行计算，得到输出的二维数据并用散点图的方式显示在二维平面上。 1234encoder_result = sess.run(encoder_op, feed_dict=&#123;X: mnist.test.images&#125;) # 运行encoder部分，得到压缩数据plt.scatter(encoder_result[:, 0], encoder_result[:, 1], c=mnist.test.labels) # 绘制散点图plt.colorbar() # 显示颜色指示条plt.show() # 显示图像 代码中plt.scatter()用来显示散点图，其中前两个参数表示数据的横坐标和纵坐标，第三个参数用来设置散点图的颜色。 结果如下图： 压缩之后的数据分布 可以看出把数据压缩成二维之后可以提取数据中的部分有效信息。 后续也可以在得到的二位数据后使用普通神经网络或者其他分类方法对手写体数据进行分类。 参考资料： 《TensorFlow实战》 自编码 Autoencoder (非监督学习)","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"ML","slug":"ML","permalink":"http://luojiaji.github.io/tags/ML/"}]},{"title":"Policy Gradients","date":"2017-05-26T06:27:46.000Z","path":"2017/05/26/Policy-Gradients/","text":"Policy Gradients是强化学(Reinforcement Learning)中的一种算法，Policy Gradients 不需要用贪婪策略来选择行为，而是算法直接给出不同行为的概率并通过这个概率来选择行为。 下面是Policy Gradients算法的伪代码： Policy Gradients算法更新过程 算法中$v_t$是累计回报率(通常需要归一化处理)，累计回报越大的状态跟新幅度也越大，这样也可以提高算法的收敛速度。$\\pi_\\theta(s_t,a_t)$是神经网络根据状态输出的策略。神经网络在输出之前加了一层softmax层，这样可以得到不同行为的概率，行为选择的时候便根据得到的不同行为的概率来选择行为。 Policy Gradients算法在每次迭代之后进行学习，每一次迭代相对独立，因此每一次训练所用的数据也是相对独立的，每一次训练都能利用行为序列中的所有信息。而DQN中需要在运行若干步之后随机采样来进行学习，而跟算法的迭代的次数(算法中的episode)无关，而且DQN中每隔若干步进行学习是样本序列是在存储空间随机采样得到的，这样算法的效率略低，但是DQN所需要的存储空间也会相对较小(可以人为设置)。 Policy Gradients中的$v_t$是累计回报率，跟整个行为序列有关，所以需要在整个行为序列结束之后再进行学习。而DQN中用到的是时间差分的方法，更新时只跟下一次的状态和行为值有关，所以DQN中测存储的状态行为值可以随机采样来进行学习。 Policy Gradients算法中的神将网络直接输出某一状态下不同行为的概率，可以利用得到的概率直接进行行为的选择，这样可以有效地避免算法陷入局部最优。而DQN输出的是不同行为对应的值，因此还需要过$\\epsilon$贪婪策略来对行为进行选择。 Policy Gradients需要完整的一组行为序列，得到行为序列之后再反向计算每一个状态的累计回报值，然后才能对神经网络进行训练。DQN则不必等到每一次迭代完成之后才进行训练，而是在给定的若干步之后便可以在存储空间中随机采样并对神经网络进行训练。 Policy的训练依据是累计回报值，回报值跟当前迭代的整个行为序列有关，回报值越高则说明行为越正确。DQN的修正依据是每一步的奖励值，只跟当前状态和下一状态有关，奖励值越高则说明行为越正确。 因此，虽然Policy Gradients 和 DQN 都是在强化学习算法中采用了神将网络的方法对行为值进行近似计算，但本质的思想是不一样的。 Policy Gradients 采用的蒙特卡洛方法来计算行为值(累计回报)。在DQN中则是用到时间差分的方法(TD方法)来计算行为值。 参考资料: Policy Gradients 算法更新 (Tensorflow) 强化学习入门 第四讲 时间差分法(TD方法) 强化学习进阶 第六讲 策略梯度方法","tags":[{"name":"RL","slug":"RL","permalink":"http://luojiaji.github.io/tags/RL/"}]},{"title":"DQN(Deep Q Network)","date":"2017-05-25T11:03:43.000Z","path":"2017/05/25/DQN(Deep Q Network)/","text":"DQN是Deep Q Network的简称，是一种将强化学习的方法(Q-Learning)和神经网络(Neural Networks)相结合的一种新的算法。Q-learning算法是1989年Watkins提出来的一种强化学习的算法，在次基础上2015年nature的论文上提出了在Q-Learning基础上改进的算法DQN。Q-Learning中需要一个Q表来存储每个状态中不同动作对应的值函数。这种算法在有限状态中会比较有效，但当状态空间变得非常大或者连续的情况下，Q-Learning的算法就需要一个非常大的Q表来存储不同的状态，这样使得算法变得难以实现。因此结合神经网络的方法出现了DQN算法。DQN可以通过神经网络来拟合状态值，这样就避免了Q-Learning中需要存储大量状态空间的问题。 下面就是DQN的算法更新过程 DQN算法的更新过程 第1行，初始化状态存储空间$D$，存储空间容量为$N$ 第2行，用随机权值 $\\theta$ 初始化动作值函数的神经网络$Q$ 第3行，初始化目标动作值函数$\\hat Q$，并且网络权值$\\theta^-=\\theta$ 第4行，循环每一次事件 第5行，初始化第一个状态$s_1$ ，通过预处理得到对应的状态特征 $\\phi_1=\\phi(s)$ (用来作为神经网络的输入) 第6行，循环每一步动作 第7行，利用$\\epsilon$随机选择一个动作$a_t$ 第8行，如果$\\epsilon$概率没有发生，则选择对应状态中所有动作的最大值$a_t=\\arg \\max_a Q(\\phi(s_t),a;\\theta)$ 第9行，执行动作$a_t$，得到奖励值$r_t$和推测的下一步$x_{t+1}$ 第10行，令$s_{t+1} = s_t,a_t,x_{t+1}$，并且对状态$s_{t+1}$做预处理，$\\phi_{t+1}=\\phi(s_{t+1})$ 第11行，将转移过程$(\\phi_t,a_t,r_t,\\phi_{t+1})$保存在存储空间$D$中 第12行，从存储空间$D$中，随机采样一组训练数据$(\\phi_j,a_j,r_j,\\phi_{j+1})$ 第13行，判断事件是否在$j+1$步终止，如果终止，则$y_j = r_j$；否则$ y_j = r_j + \\gamma max_{a^`} \\hat Q (\\phi_{j+1}+a^`;\\theta^-)$ 第14~15行，通过梯度下降$(y_t - Q(\\phi_j,a_j;\\theta) )^2$来优化参数$\\theta$ 第17行，每经过$C$步，将动作值函数的预测网络赋值给目标动作值网络网络 $\\hat Q = Q $ 从上面的算法过程可以看出DQN算法在原有Q-Learning的基础上做了一些改进 首先，DQN利用神将网络来通过状态计算相应的动作值，这样就可以避免在状态空间较大或者状态空间为连续的情况下Q-Learning算法难以实现的问题。 其次，算法通过存储一定数量的过往经历，并在这些经历中随机选择一些进行重复学习(算法第12行)，来对神经网络进行训练。这样通过经验进行回放学习的思想来自于人类大脑中的海马体，海马体是人类大脑中负责记忆和学习的部分，当人在睡觉的时候，海马体会把一天的记忆重放给大脑皮层。 最后，通过独立设置目标网络来进行计算目标动作值，这样有利于网络的收敛，这个思想就像Q-Learning与Sarsa的区别一样，Sarsa的动作值更新过程和行为选择过程是相互关联的，这样当状态过多时容易导致算法难以收敛，而Q-Learning的动作值更新和动作选择是两个相对独立的过程，这样可以使算法更容易收敛，同时，在对存储的状态行为进行随机采样时也可以打乱行为之间的联系，也是促进算法收敛的一种方法(算法第12行)。 参考资料： 深度强化学习系列 第一讲 DQN DQN从入门到放弃5 深度解读DQN算法 DQN 算法更新 (Tensorflow) DQN 思维决策 (Tensorflow)","tags":[{"name":"RL","slug":"RL","permalink":"http://luojiaji.github.io/tags/RL/"}]},{"title":"勇士VS马刺 G1","date":"2017-05-17T12:39:56.000Z","path":"2017/05/17/勇士VS马刺-G1/","text":"一场充满争议的比赛，一场谁都不服气的比赛。当小卡又一次倒在几乎同样的位置的时候，全世界的人们似乎都把目光投向了球场上，每个人都化身篮球专家，指点江山，义愤填膺。首先从波波开始，小卡这场比赛在回更衣室之前，比赛进行到了第三节还剩8分钟左右，也就是比赛一共进行了28分钟，而技术统计中小卡的上场时间是24分钟(ESPN的统计)，也就是说就算小卡不受伤这场比赛的出场时间也冲着40分钟以上去了。波波难道忘记了小卡在打火箭的时候伤过了吗？难道忽略了一分钟之前小卡已经扭伤过脚踝了吗？受伤这种事情一方面是球员的不正当动作造成的，但也有很大一部分原因是疲劳所导致的。当运动员感到疲劳时，也是比较容易受伤的，所以波波在这场比赛的用人上有点问题。可能是波波看到开场是的优势有点心动，想抓住机会把勇士一棍打死，但是却忽略了球员的使用，也没有想到球场上竟然出现了这样的事情。 波波维奇对帕楚里亚的炮轰应该也有其他的目的吧，他应该还记得上赛季总决赛身处舆论漩涡的格林的表现吧，他应该知道帕楚里亚是勇士唯一可以和马刺内线高度抗衡的球员吧，他应该也知道这样的舆论对球员的影响吧。波波脑子里想的应该是如何让球队获得尽可能多的优势吧！ 联盟里像帕楚里亚这样的球员不止一个，德拉维多瓦，贝弗利…他们永远在冲锋陷阵的最前面，永远做着最脏最累的工作，他们需要盯防对手的球星，需要打扰对方主力的心态，打乱对手的节奏。当球队需要的时候你必须义无反顾地付出，在通往冠军的路上，他们就像垫脚石，护送那些光芒万丈的球星最终站在最高荣誉之上。而多年以后，他们也许早已被人们忘记，只能躲在角落里抚摸着曾经的荣耀与伤痛。 马刺 勇士这两个球队都将各自引领着联盟的两种风格 一个球风华丽，进攻如水银泻地 一个作风严密，防守如铜墙铁壁 凌晨爬起来的我们也是为了看一场巅峰对决 但是却意外地看到了这一幕 那一刻我只感受到了小卡的疼痛与无助 揪心 无奈 希望伤病远离球员 希望比赛依旧精彩 希望球场上只打球 希望留下的是美好的回忆 希望带走的是篮球的快乐 希望左右比赛的是球员的发挥 希望双方较量的是球队的战术 希望胜者可以温柔以对 希望败者可以昂首挺胸","tags":[{"name":"随笔","slug":"随笔","permalink":"http://luojiaji.github.io/tags/随笔/"}]},{"title":"基于TensorFlow的卷积神经网络设计","date":"2017-05-12T13:08:37.000Z","path":"2017/05/12/基于TensorFlow的卷积神经网络设计/","text":"今天继续来写一篇关于TensorFlow的，用TensorFlow来设计一个卷积神经网络，并用于手写体识别。卷积神经网络(Convolutional Neural Network,CNN)，应该算是一种比较经典的网络模型，很多深度学习的框架中都可以看到CNN的身影。因此今天就用TensorFlow来实现一个卷积神经网络。 今天用到的模块和版本号：Python版本：3.5.3Tensorflow版本：1.0.1 第一步跟之前的一样，先导入数据：12from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets('MNIST_data', one_hot=True) 然后定义一下网络节点的权重和偏置1234567def weight_variable(shape): initial = tf.truncated_normal(shape,stddev=0.1) return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1,shape=shape) return tf.Variable(initial) 然后来定义卷基层和池化层1234567def conv2d(x,W): # stride [1,x_movement,y_movement,1] return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME') # must have strides[3] = 1def max_pool_2X2(x): # stride [1,x_movement,y_movement,1] return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') tf.nn.conv2d()是卷积层其中x为输入，W为卷积参数，strides表示卷积模板的移动步长，都是1代表会不遗漏地划过图片的每一个点。padding代表边界的处理方式，这里的SAME参数代表给边界加上padding让卷积的输入和输出保持相同的尺寸。tf.nn.max_pool()是池化层，这里使用2*2的最大池化，既将一个2*2的像素块将为1*1的像素块。最大池化会保留像素块中灰度值最高的一个像素。 然后来定义网络模型123456789101112131415161718192021222324252627282930313233343536xs = tf.placeholder(tf.float32, [None,784]) # 28*28ys = tf.placeholder(tf.float32, [None,10])keep_prop = tf.placeholder(tf.float32)x_image = tf.reshape(xs,[-1,28,28,1])# print(x_image.shape) #[n_sample,28,28,1]## convl layer ##W_conv1 = weight_variable([5,5,1,32]) # patch:5*5, in size:1, outsize:32b_conv1 = bias_variable([32])h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size:28*28*32h_pool1 = max_pool_2X2(h_conv1) # output size: 14*14*32## conv2 layer ##W_conv2 = weight_variable([5,5,32,64]) # patch:5*5, in size:32, out size:64b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size:14*14*64h_pool2 = max_pool_2X2(h_conv2) # output size: 7*7*64##func1W_fc1 = weight_variable([7*7*64,1024])b_fc1 = bias_variable([1024])h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])#n_samples,7,7,64 -&gt; n_samples,7*7*64h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)h_fc1_drop = tf.nn.dropout(h_fc1,keep_prop)##func2W_fc2 = weight_variable([1024,10])b_fc2 = bias_variable([10])prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+ b_fc2)cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction), reduction_indices=[1])) # losstrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) 在CNN网络模型中包含两个卷基层和两个全连接层，用ReLU作为激活函数，这样可以避免多层神经网络的梯度弥散和梯度爆炸。在每层之间再加上一个dropout层，这是为了防止模型过拟合。用cross entropy作为损失函数，优化器使用Adam学习速率设为1e-4 然后定义一个用来计算网络模型识别正确率的函数1234567def compute_accuracy(v_xs , v_ys): global prediction y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs, keep_prop: 1&#125;) correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys, keep_prop: 1&#125;) return result 最后对模型进行训练，并通过compute_accuracy()来验证模型的正确率，并打印出正确率12345for i in range(3000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train_step,feed_dict=&#123;xs: batch_xs, ys: batch_ys, keep_prop : 0.5&#125;) if i % 100 == 0: print(i/100,':',compute_accuracy(mnist.test.images, mnist.test.labels)) 最后可以得到，正确率为98.4% ，如果增加迭代的次数，模型的正确率还能再高一点，大约在99%左右。 参考资料: 《TensorFlow实战》","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"ML","slug":"ML","permalink":"http://luojiaji.github.io/tags/ML/"}]},{"title":"Q-Learing,Sarsa和Sarsa-lambda","date":"2017-05-07T10:47:16.000Z","path":"2017/05/07/Q-Learing-Sarsa和Sarsa-lambda/","text":"最近看了一些关于强化学习(Reinforcement Learning)的资料，今天来总结一下RL中一些基本的算法。强化学习 (Reinforcement Learning) 是一个机器学习领域中的一个分支, 由于近些年来的技术突破, 和深度学习 (Deep Learning) 的整合, 使得强化学习有了进一步的运用。比如让计算机学着玩游戏, AlphaGo 挑战世界围棋高手, 都是强化学习在行的事。 第一个是Q-Learning先看一下算法的学习过程： Q-Learning算法更新过程 Q-Learning在每一次循环中会计算当前的状态和要采取的动作与下一步的状态中所有动作最大值的差，如果这个误差为零，那么算法不会对状态进行更新，如果这个误差不为零(一般情况下正值代表奖励，负值代表惩罚)，则会将这个误差乘以一个固定的学习效率跟新到上一次的状态中去。算法的学习过程一般会从最靠近奖励或者惩罚的地方开始，因为这些奖励和惩罚是算法跟新的依据。每次迭代过程，算法都会讲这个奖励或者惩罚向前传递，直到传递到第一步，这样算法就算是学会了相应规则下的整个动作。如果想让算法在学习到的经验的基础上探索未知，可以在动作选择的部分加上一个在相对较小的概率下随机选择动作的过程，这样就可以让算法在已有经验的基础上继续探索新的动作。Q-Learning是一种off-policy的跟新过程，因为算法的跟新部分跟动作选择部分是相对独立的两个部分(虽然都是取Q表中相应的最大值，但是这两部分的计算是独立进行的，互相并不影响)。 第二个是Sarsa(state-action-reward-state_-action_)Sarsa中，state和action代表当前的状态和要采取的而动作，state_和action_代表的是下一次的状态的要采取的动作。算法的更新过程如下图： Sarsa算法的更新过程 相较于Q-learing来说Sarsa的跟新过程和就是算法下一个状态所采取的动作，因此Sarsa是一种on-policy的更新方法。相较于Q-Learning来说，Sarsa更加谨慎小心，他会严格安装学习的过程来采取行动，但同时这样也会降低算法探索未知路径的能力，应该说两个算法的性格不相同，Q-Learning更加冒险，勇于探索未知。而Sarsa则更加保守，尽量按照已有的经验来采取行动。 最后一个是Sarsa-Lambda算法的学习过程如下图： Sarsa-Lambda算法的更新过程 Q-Learning和Sarsa每一次只能向前跟新一步，而Sarsa-lambda则可以在一次更新中对多步进行跟新，在Sarsa-Lambda中除了有Q表来存储状态之外，还有一个E表，这个表格会记录算法在获得奖励之前的每一步，当计算的误差值不为零的时候，算法会将之前的每一步乘以相应的系数一起跟新在Q表中。Lambda这个参数可以改变算法跟新过程中每一步对应的权重，当Lambda为0时，算法就是Sarsa算法，当Lambda为1时，算法所走过的每一步的权重都相同，当Lambda的权重为0~1之间时，越接近奖励或惩罚的步权重越大，跟新的幅度也会越大，而距离奖励或惩罚较远的步则权重相对较小，更新的幅度也会比较小。 参考资料： 强化学习入门 第四讲 时间差分法（TD方法）","tags":[{"name":"RL","slug":"RL","permalink":"http://luojiaji.github.io/tags/RL/"}]},{"title":"基于TensorFlow的多层神经网络设计","date":"2017-05-05T00:09:28.000Z","path":"2017/05/05/基于TensorFlow的多层神经网络设计/","text":"今天利用TensorFlow来实现多层神经网络的设计，并用手写数字数据库对模型进行训练和测试。多层神经网络又叫多层感知机（Multi-layer Perception，MLP），多层神经网络包含输入层，输出层，隐藏层。隐藏层相当于模型的黑箱部分。理论上只要隐藏层包含的节点足够多，即使只有一个隐藏层的神经网络也可以拟合任意函数。隐藏层越多，越容易拟合复杂函数。理论研究表明，喂你喝复杂函数需要的隐藏层节点的数目，基本上随着隐藏层的数量增多成指数下降趋势。也就是说层数越多，神经网络所需要的隐含节点可以越少。 今天用到的模块和版本号：Python版本：3.5.3Tensorflow版本：1.0.1 首先导入数据12from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) 然后就可以建立模型了123456789101112131415161718in_units = 784h1_units = 300W1 = tf.Variable(tf.truncated_normal([in_units, h1_units], stddev=0.1))b1 = tf.Variable(tf.zeros([h1_units]))W2 = tf.Variable(tf.zeros([h1_units, 10]))b2 = tf.Variable(tf.zeros([10]))x = tf.placeholder(tf.float32, [None, in_units])y_ = tf.placeholder(tf.float32, [None, 10])keep_prob = tf.placeholder(tf.float32)hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1)hidden1_drop = tf.nn.dropout(hidden1, keep_prob)y = tf.nn.softmax(tf.matmul(hidden1_drop, W2) + b2)# Define loss and optimizercross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))train_step = tf.train.AdagradOptimizer(0.3).minimize(cross_entropy) 模型中，隐藏层的节点数设为300，在隐藏层中，用ReLU作为激活函数，这样可以防止多层神经网络中的梯度弥散。并在隐藏层中添加dropout层，Dropout可以用来防止过拟合。输出层用Softmax作为激活函数。 模型设计完成之后，就可以对模型参数进行初始化12sess = tf.InteractiveSession()tf.global_variables_initializer().run() 最后就可以对模型进行训练，并验证识别的正确率。对模型进行3000次训练，训练过程中，每训练100次用测试数据对模型进行测试并输出测试结果1234567for i in range(3001): batch_xs, batch_ys = mnist.train.next_batch(100) train_step.run(&#123;x: batch_xs, y_: batch_ys, keep_prob: 0.75&#125;) if (i) % 100 == 0: correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) print(int((i) / 100), &apos;:&apos;, accuracy.eval(&#123;x: mnist.test.images, y_: mnist.test.labels,keep_prob: 1.0&#125;)) 最后得到输出图如下 可以看出，最终模型的正确率在98%左右，相比较之前的单层神经网络有了不小的提高。 参考资料： 《TensorFlow 实战》","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"ML","slug":"ML","permalink":"http://luojiaji.github.io/tags/ML/"}]},{"title":"新的狂想","date":"2017-05-02T11:13:23.000Z","path":"2017/05/02/新的狂想/","text":"今天看了哈登在The Players Tribune上发表的文章，感觉写的不错，就翻译了一下。正文 : 在这之前，我从来都不是一个作家，但是你知道吗？在这个赛季之前我也从来都不是一名控卫。所以，那就试一试吧！ 前几天，阿里扎给我看了他写的文章，而这也让我开始思考关于这个球队，这个赛季以及队友们为我所做的一切。 不仅仅是我的队友，还有教练。 从某种程度上说，这一切开始于去年夏天德安东尼教练疯狂的想法。 德安东尼教练接受这个工作之后，我们立刻通了电话——谈论了上赛季的失误，谈论了球队的阵容，还谈论了我们要做的改变。聊的是一些平常的问题。显然，他在篮球方面非常聪明，而且也很随和。他询问问题，认真倾听，而不是一副无所不知自大的样子。我喜欢这种氛围。 在我们要挂断电话之前，他停下来直截了当地说：老实说，我们需要你成为控球后卫。 我听到了他的话，我的意思是我听到了他说的每一个字。但是并没有放在心上。 那次通话之后，留在脑海里的是他说话的方式，而不是他说了什么。 “我们需要你成为一名控卫” 需要 不是想，不是希望 需要 这不是一个随便选择的词汇。我知道我至少需要听一下他的想法。 但是当时有件事一直困扰着我，因此我并没有立刻告诉他。 那个夏天，我们多次见面。教练非常重视看录像，我们看了许多录像。有时我们看火箭的比赛，但更多的时候看的是一些老的比赛——他执教的那支打炮轰的太阳队的录像。我们主要看了许多史蒂夫·纳什的比赛。教练说他想让我学习这位历史上伟大的控球后卫。 这是在录像室最大的乐趣。我总能看到教练指着电视，因为纳什在场上的表现而激动。他暂停录像，然后我们谈论纳什节奏变化，阅读防守的能力，以及他总能够把球传给在几个回合没有楚球的人。教练谈论纳什怎样成为一名领袖——这也是我每一年都在想提高的地方。而且他还告诉我纳什在每个赛季是如何自我发展的。 一次又一次，让我改打控卫的想法被提出来。我认为他其实想说：如果你愿意少得一些分，多持球，你可以打出太阳队那样的进攻。 然后他会指着电视屏幕上的纳什。 有一天我不得不告诉他我脑海中的想法。 “恩，教练，我不得不说，我并不是7秒炮轰战术的爱好者” 这就是我告诉他的。现在想起来，我非常吃惊我说了那些话。7秒炮轰战术使他在菲尼克斯名声大噪。但是我不想否定这个战术， 我只是想坦诚地说：这些适合当年的太阳队的打法但并不一定适合我们。 我知道我们的球队需要增加一些实力，但是一支跑轰球队？这并不像我们的风格。我们应该利用更长的进攻时间来获得一个更好的投篮机会。 教练的反应让我感到吃惊。他没有辩解，也没有生气，他只是告诉我我理解错他的意思了。 忘记场上的位置吧，他说。看录像并不是要复制太阳的进攻，甚至控卫的打法。这根本就跟场上的位置没有关系。 教练想说的是要在更重要的事情上牺牲自我。 五年前，我来到休斯顿的时候还是个菜鸟。那时候还不知道如何对教练的要求做出反应。但是这几年不同了。我变得更加成熟，与球队的关系比之前待过的任何一支球队都要紧密。这就是我们的打球方式。我们坚信团队的作用要大于个人。我们在场上和场下相处相处很好。每个人都有自己的角色。每个人都做好自己的事情。每个人为彼此做出牺牲。 你可以在贝弗利身上看到这些。 贝弗利自称自己是条狗，在我们的生命中总有那么一个人，你可以放心地把脆弱的后背交给他。从球队的角度来说，那个人就是贝弗利。每晚，他都做好了战斗的准备，他不会向任何人屈服。 在季后赛的第一场，当他遇到亚当斯的挡拆，每个人都看到他被重重地撞在地上。但是你或许没有注意到接下来发生的事情——贝弗利站起来，并用手指指向天空，此时替补席的反应。然后，球队被他点燃了。我们没有纠结于过去。我们赢得了比赛，并赢得了整个系列赛。 这样的比赛为我们定下了整个赛季的基调。 这正是火箭精神的所在。 不仅仅是贝弗利，埃里克·戈登来到这里想成为一名首发，但却接受了替补球员的角色——因为我们告诉他这样球队可以变得更好。他并没有提出质疑。相信我，联盟里大多数人做不到这一点。 球队里的每个人都是如此。内内使我们当中最智慧的男人，当我们出现错误的时候他总会告诉我们。卡佩拉还是个年轻人，希望让可以在我的帮助下成长。他是我见过的最善于学习的球员。这可以使他走的更远，他对于处在季后赛中的我们也是至关重要的。 要想在季后赛中走得更远，我们需要互相依靠彼此。 Everyone does their part. We really believe we’re better together than we are as individuals. —— James Harden 我真的希望可以和我的队友们一直走下去，也希望能一直留在这座城市，当我来到这里的第一天，休斯顿就向我展现出了他们的爱。这对我来说意味着一切。我在这里成长为一名更好的球员。 当我第一次来到这里，我在脑海中列出了许多个人方面的目标。你知道，这是每一个年轻球员的都会考虑的。我想去证明我能做到。这并没有错，但是现在不同了。 现在要考虑的是：球队如何才能赢得比赛？ 这是我现在为之执着的事情，成为一名对胜利有所贡献的领袖。 其他的呢？其他的都不重要了。我将停下来而且用比赛来说话。 还有另一场季后赛的战斗在前面等着我们。 休斯顿你准备好了吗？ 我早就知道了。 原文：https://www.theplayerstribune.com/james-harden-houston-rockets-2017-playoffs/","tags":[{"name":"随笔","slug":"随笔","permalink":"http://luojiaji.github.io/tags/随笔/"}]},{"title":"基于TensorFlow的交通标志识别","date":"2017-04-30T05:01:51.000Z","path":"2017/04/30/基于TensorFlow的交通标志识别/","text":"趁五一假期，再写一篇用Tensorflow实现交通标志识别。 今天的任务是通过Tensorflow搭建一个机器学习模型，通过训练来实现识别交通标志。 Python版本：3.5.3Tensorflow版本：1.0.1其中还用到了一些其他的库12345678import osimport randomimport skimage.dataimport skimage.transformimport matplotlibimport matplotlib.pyplot as pltimport numpy as npimport tensorflow as tf 模型训练和测试用到的数据集来自比利时的交通标志数据集，下载BelgiumTS for Classification (cropped images)中的BelgiumTSC_Training (171.3MBytes) 和 BelgiumTSC_Testing(76.5MBytes)，training的数据集用来训练模型，Testing的数据集用来测试模型。训练集和测试集各包含62个子目录，目录名字是从00000到00061，这些目录代表的是相应交通标志的标签，而每个目录下的图片就是该标签的样本。 首先我们要加载训练数据数据集中的图片数据是用.ppm格式存储的，可以通过Scikit Image库来读取图片数据123456789101112131415161718192021222324def load_data(data_dir): \"\"\"Loads a data set and returns two lists: images: a list of Numpy arrays, each representing an image. labels: a list of numbers that represent the images labels. \"\"\" # Get all subdirectories of data_dir. Each represents a label. directories = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))] # print(directories) # Loop through the label directories and collect the data in # two lists, labels and images. labels = [] images = [] for d in directories: label_dir = os.path.join(data_dir, d) file_names = [os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".ppm\")] # For each label, load it's images and add them to the images list. # And add the label number (i.e. directory name) to the labels list. for f in file_names: images.append(skimage.data.imread(f)) labels.append(int(d)) return images, labels 加载数据之后返回两个列表，images列表包含图像信息，每个图像信息为numpy数字；labels列表包含列表信息，数值为0到61的整数 然后我们可以看一下一共有多少图像和标签12images, labels = load_data(train_data_dir)print(\"Unique Labels: &#123;0&#125;\\n Total Images: &#123;1&#125;\".format(len(set(labels)), len(images))) 从打印出的结果可以看到，一共有62个标签，4575个训练数据 我们可以显示一下每一组标签的第一幅图像12345678910111213141516def display_images_and_labels(images, labels): \"\"\"Display the first image of each label.\"\"\" unique_labels = set(labels) plt.figure(figsize=(10, 10),dpi=50) i = 1 for label in unique_labels: # Pick the first image for each label. image = images[labels.index(label)] # print(labels.index(label)) plt.subplot(8, 8, i) # A grid of 8 rows x 8 columns plt.axis('off') plt.title(\"Label &#123;0&#125; (&#123;1&#125;)\".format(label, labels.count(label))) i += 1 _ = plt.imshow(image) plt.show()display_images_and_labels(images, labels) 标签和图像信息 同样，我们也可以显示每一个标签中的图片数据，来看一下第42号标签的数据1234567891011121314151617def display_label_images(images, label): \"\"\"Display images of a specific label.\"\"\" limit = 24 # show a max of 24 images plt.figure(figsize=(15, 5)) i = 1 start = labels.index(label) end = start + labels.count(label) for image in images[start:end][:limit]: # 这句话写的还是很巧妙的，防止过界，超出图片的种类的索引范围 # for image in images[start:start+limit]: # 这么写的话如果某种图片的数量没有24张的话会直接显示到下一种的图片 plt.subplot(3, 8, i) # 3 rows, 8 per row plt.axis('off') i += 1 plt.imshow(image) plt.show()display_label_images(images, 42) 42号标签的图像数据 通过上面的图像显示，我们会发现，这些图片的大小是不一样的。但是大多数的机器学习模型需要输入数据的维数是固定的，因此需要对图像数据进行处理，保证相同的输入数据格式。1images32 = [skimage.transform.resize(image, (32, 32)) for image in images] 这样就可以将图片数据转换成32*32*3的图片。 接下来的工作就是搭建神经网络模型12345678910111213141516171819202122232425262728# Placeholders for inputs and labels.images_ph = tf.placeholder(tf.float32, [None, 32, 32, 3])labels_ph = tf.placeholder(tf.int32, [None])# Flatten input from: [None, height, width, channels]# To: [None, height * width * channels] == [None, 3072]images_flat = tf.contrib.layers.flatten(images_ph)# hidden = tf.contrib.layers.fully_connected(images_flat,500,tf.nn.relu)# Fully connected layer.# Generates logits of size [None, 62]logits = tf.contrib.layers.fully_connected(images_flat, 62, tf.nn.relu)# Convert logits to label indexes (int).# Shape [None], which is a 1D vector of length == batch_size.predicted_labels = tf.argmax(logits, 1)# Define the loss function.# Cross-entropy is a good choice for classification.loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels_ph))# Create training op.train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)# And, finally, an initialization op to execute before training.init = tf.global_variables_initializer() 在模型当中，首先改变一下输入数据的维数，将32*32*3的数据展开成一维的数据(1*3072)，然后建立一个3072-62的全连接网络，使用ReLU作为激活函数。用交叉熵作为损失函数，使用ADAM优化器来优化参数，最后初始化模型。 模型搭建好之后，就可以通过训练数据来对模型进行训练，设置训练次数为201次，每训练数次输出一下损失函数的的值12345678910session = tf.Session()# First step is always to initialize all variables.# We don't care about the return value, though. It's None._ = session.run([init])for i in range(201): _, loss_value = session.run([train, loss], feed_dict=&#123;images_ph: images_a, labels_ph: labels_a&#125;) if i % 10 == 0: print(i/10,\"Loss: \", loss_value) 损失函数值 模型训练好之后，既可以用测试数据来见一下模型的性能。随机抽取测试数据中的10张图片，然后打印出对应的实际标签和识别标签。123456789101112131415161718192021222324sample_indexes = random.sample(range(len(images32)), 10)sample_images = [images32[i] for i in sample_indexes]sample_labels = [labels[i] for i in sample_indexes]# Run the \"predicted_labels\" op.predicted = session.run([predicted_labels], feed_dict=&#123;images_ph: sample_images&#125;)[0]print(sample_labels)print(predicted)# Display the predictions and the ground truth visually.fig = plt.figure(figsize=(10, 10))for i in range(len(sample_images)): truth = sample_labels[i] prediction = predicted[i] plt.subplot(5, 2,1+i) plt.axis('off') color='green' if truth == prediction else 'red' plt.text(40, 10, \"Truth: &#123;0&#125;\\nPrediction: &#123;1&#125;\".format(truth, prediction), fontsize=12, color=color) plt.imshow(sample_images[i])# plt.ion()plt.show() 测试样本 从中可以看到，在10个测试数据中，有7个可以正确识别。 最后，加载所有的测试数据，计算并打印模型的识别正确率。123456789101112131415test_images, test_labels = load_data(test_data_dir)# Transform the images, just like we did with the training set.test_images32 = [skimage.transform.resize(image, (32, 32)) for image in test_images]# display_images_and_labels(test_images32, test_labels)# Run predictions against the full test set.predicted = session.run([predicted_labels], feed_dict=&#123;images_ph: test_images32&#125;)[0]# Calculate how many matches we got.match_count = sum([int(y == y_) for y, y_ in zip(test_labels, predicted)])accuracy = match_count / len(test_labels)print(\"Accuracy: &#123;:.3f&#125;\".format(accuracy)) 模型识别正确率 可以看出，模型的正确率在70%左右。 参考资料： https://github.com/waleedka/traffic-signs-tensorflow/blob/master/notebook1.ipynb https://yq.aliyun.com/articles/67167 http://www.jianshu.com/p/d8feaddc7bdf","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"ML","slug":"ML","permalink":"http://luojiaji.github.io/tags/ML/"}]},{"title":"基于TensorFlow的Softmax Regression单层神经网络","date":"2017-04-26T12:18:29.000Z","path":"2017/04/26/基于TensorFlow的Softmax Regression单层神经网络/","text":"今天来挖个新坑，来用Google出的深度学习框架TensorFlow来搭建一个SoftMax Regression模型,来识别手写数字。MNIST(Mixed National Institute of Standards and Technology database)是一个机器学习视觉数据集，由像素为28*28的手写数字构成，这些图片只包含灰度值信息，因此每一张图片就是一个28*28*1的矩阵，需要做的就是对这些手写数字图片进行分类，转成0~9共10类。 MNIST手写数字图片示例 MNIST灰度信息示例 首先需要做的就是对MNIST数据进行加载，TensorFlow已经为我们封装这些功能，直接调用就可实现数据的加载。 12from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(\"MNIST_data/\"， one_hot=True) MNIST包含训练集和测试集，每一个样本都有对应的标注信息(label)，训练集用来训练设计好的模型，测试集则用来对训练后的模型进行测试。我们可以通过print()函数打印出MNIST的数据信息12print(mnist.train.images.shape， mnist.train.labels.shape)print(mnist.test.images.shape， mnist.test.labels.shape) 可以看出训练集有55000个样本，测试集有5000个样本，每个样本的维数为784，也就是将每个图像的28*28个点展开成1维的结果(28*28=784)，本模型中输入就是这个1维向量，其实这样会失去空间结构的信息，也算是对模型的简化。因此，模型的输入为55000x784的Tensor，同时Labels为55000x10的tensor。 MNIST训练数据 MNIST训练数据的Label Softmax Regression的工作原理比较简单，将可以判断为某一类的特征相加，然后将这些特征转化为判定是这一类的概率。上述特征可以通过一些简单的方法得到，比如对所有像素求一个加权和，而权重是模型根据数据西东学习，训练出来的。比如某个像素的灰度值大代表很可能是数字n时，这个像素的权重就大;反之，如果某个像素的灰度大代表不太可能是数字n时，这个像素的权重就比较小，甚至可能是负值。下图为一些这样的特征，其中，明亮的区域代表负的权重，灰暗的区域代表正的权重。 不同数字对应的特征权重 接下来我们将这些特征公式化$i$代表第$i$类，$j$代表一张图片的第$j$个像素。$$feature_i = \\sum_1^n W_{i,j} x_j + b_i$$接下来对所有特征计算softmax$$ softmax(x) = normalize(exp(x)) $$其中第i类的的概率就可以有下面的公式得到:$$ softmax(x)_i = {exp(x_i) \\over \\sum_j exp(x_j)} $$ 先对各类特征求$\\exp$函数，然后对他们标准化，使得和为1，特征是越大的类，最后输出的概率也越大;反之，特征的值越小，输出的概率也就越小. Softmax Regression 流程 然后就是通过TensorFlow来实现Softmax Regression模型。首先导入TensorFlow库1import tensorflow as tf 然后设置输入和输出，并初始化Weights和Bias1234x = tf.placeholder(tf.float32, [None, 784])y_ = tf.placeholder(tf.float32, [None, 10])W = tf.Variable(tf.zeros([784, 10]))b = tf.Variable(tf.zeros([10])) 接下来实现Softmax Regression 算法1y = tf.nn.softmax(tf.matmul(x, W) + b))) 恩，一行就搞定! 然后用cross-entropy作为loss function.1cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) 接下来再定义一个优化方式，直接调用tf.train.GradientDescentOptimizer，并将学习速率设置为0.5，优化目标设置为cross-entropy1train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) 下一步就是初始化并执行模型 1tf.global_variables_initializer().run() 加下来就是进行迭代来训练并优化模型。设置迭代次数为1000次，并且每迭代100次用测试数据来测试一下模型的识别正确率，并打印出来1234567for i in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) train_step.run(&#123;x: batch_xs, y_: batch_ys&#125;) if (i+1)%100 == 0: correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) print(int((i+1)/100),':',accuracy.eval(&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)) Softmax Regression 模型识别正确率 最后在打印出的结果中可以看到，最后Softmax Regression的准确率为92%左右。 参考资料: MNIST For ML Beginners 《TensorFlow 实战》","tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://luojiaji.github.io/tags/TensorFlow/"},{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"ML","slug":"ML","permalink":"http://luojiaji.github.io/tags/ML/"}]},{"title":"爬虫抓取唐诗三百首","date":"2017-04-22T04:56:37.000Z","path":"2017/04/22/爬虫抓取唐诗三百首/","text":"今天继续爬虫练习，今天来抓一下古诗文网上的唐诗三百首，并保存在文本文件中。网页的地址是:http://so.gushiwen.org/gushi/tangshi.aspx 其实抓取的思路跟之前的都差不多，没有什么太新颖的东西，就当做一次联系了吧。唯一的不懂应该就是编程思路，今天用面向对象的方式来实现以下爬虫(有时间把之前的程序也改成面向对象的方式) Python版本:3.5.3 用到的库有1.requests:用来获取网页源代码2.BeautifulSoup:用来解析网页，获得相关信息 首先获取网页的源代码，并解析网页。123def geturl(self): html = requests.get(url=self.page_url) return html.text 打开网页找到相应信息所在的位置 发现所有古诗都在’leftlei’的标签中，从中就可以获得所有古诗的题目，作者以及对应链接的信息。通过BeautifulSoup获取相应信息，并构造相应的url123456789soup = BeautifulSoup(html, \"html.parser\") items = soup.find('div',class_='leftlei').find_all('span') cont = 1 for item in items: gushi_url = item.find('a') if gushi_url != None: title = item.find('a').get_text() author = item.get_text()[len(title) + 1:-1] cont += 1 从中可以发现，在当前页面中可以找到古诗的题目和作者的信息，找到其中一首古诗的元素，可以找到相应的链接，如图: 构造对应古诗的url 然后打开对应的链接，从地址上可以发现，每一首古诗对应的网页是http://so.gushiwen.org再加上相应古诗的链接 构造对应的url1gushi_url = 'http://so.gushiwen.org'+gushi_url['href'] 然后依然在对应的古诗网页中找到古诗内容所在的位置，发现古诗的内容都位于id为’cont’的标签中 获取相应网页，并从中找到古诗内容12345def getgushi(self,gushiurl): html = requests.get(url=gushiurl) soup = BeautifulSoup(html.text, \"html.parser\") gushi = soup.find('div', id='cont').get_text().replace('\\n','') return gushi 这样就得到了所有的信息，然后在将每一次得到的古诗信息存在一个txt文本中1234567def savetotxt(self,cont,title,author,gushi): f = open('tangshi.txt','a') f.write(str(cont)+'\\n') f.write(title+'\\n') f.write(author+'\\n') f.write(gushi+'\\n\\n') f.close() 最后运行程序12gushi = gushiwen()gushi.getitem() 打开文件，发现唐诗三百首中的内容已经存在文本中了","tags":[{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://luojiaji.github.io/tags/爬虫/"}]},{"title":"16-17赛季NBA常规赛球队数据不完全分析","date":"2017-04-13T02:21:01.000Z","path":"2017/04/13/16-17赛季NBA球队数据不完全分析/","text":"16-17赛季NBA常规赛到今天为止就已经全部打完了，接下来进入季后赛的球队需要为即将到来的季后赛做准备，未能打进季后赛的球队则需要考虑夏天的引援或交易来提高球队的水平。今天就来分析一下常规赛个球队的数据情况。数据来源:http://stats.nba.com/ 先来看得分方面,场均得分方面，勇士队以115.9分高居榜首。达拉斯小牛以97.9分排在最后一位，并且也是联盟中场均得得唯一没有上100的球队。全联盟平均场均得分105.6分，平均总得分8658分。 排名 球队 场均得分 总得分 1 金州勇士 115.9 9503 2 休斯顿火箭 115.3 9458 3 丹佛掘金 111.7 9161 4 克利夫兰骑士 110.3 9048 5 华盛顿奇才 109.2 8953 ··· ··· ··· ··· 26 底特律活塞 101.3 8309 27 奥兰多魔术 101.1 8288 28 犹他爵士 100.7 8258 29 孟菲斯灰熊 100.5 8239 30 达拉斯小牛 97.9 8029 其中先发得分第一的依然是金州勇士(毕竟首发非常豪华):83.1分 排名 球队 首发得分 1 金州勇士 83.1 2 明尼苏达森林狼 82.8 3 华盛顿奇才 82.2 4 克利夫兰骑士 81.2 5 波特兰开拓者 77.3 ··· ··· ··· 板凳得分当中，排在第一位的是洛杉矶湖人，47.1分 排名 球队 板凳得分 1 洛杉矶湖人 47.1 2 布鲁克林篮网 45.5 3 丹佛掘金 40.3 4 费城76人 39.8 5 休斯顿火箭 39.0 ··· ··· ··· 让对手得分方面，排在第一的是犹他爵士，场均让对手得分96.8分。爵士，马刺，灰熊都不愧是以防守著称的球队！ 排名 球队 场均让对手得分 1 犹他爵士 96.8 2 圣安东尼奥马刺 98.1 3 孟菲斯灰熊 100.0 4 达拉斯小牛 100.8 5 迈阿密热火 102.1 ··· ··· ··· 三分球方面，火箭队以1181个三分球高居榜首(休斯顿浪投大队的名号果然名不虚传) 排名 球队 场均三分球数 三分球总数 1 休斯顿火箭 14.4 1181 2 克利夫兰骑士 13.0 1067 3 波士顿凯尔特人 12.0 985 4 金州勇士 12.0 982 5 达拉斯小牛 10.7 878 ··· ··· ··· ··· 在正负值方面，勇士以11.6分位居第一 排名 球队 +/- 1 金州勇士 11.6 2 圣安东尼奥马刺 7.2 3 休斯顿火箭 5.8 4 洛杉矶快船 4.3 5 多伦多猛龙 4.2 ··· ··· ··· 助攻方面，勇士队以场均30.4次远远地把其他球队甩在了身后(一支把团队篮球发挥到极致的球队) 排名 球队 场均助攻 助攻总数 1 金州勇士 30.4 2491 2 丹佛掘金 25.3 2077 3 休斯顿火箭 25.2 2070 4 波士顿凯尔特人 25.2 2069 5 密尔沃基雄鹿 24.2 1984 ··· ··· ··· ··· 此外，东部和西部之间，一共打了450场比赛(每个球队30场)，其中，西部246胜，东部204胜，西部略站上风。 其他的一些更高阶的数据也可以在网站上找到。不过个人认为，数据可以反映一个球队的状态，以及球队的水平。但是最终的胜负还是要看教练的安排，球员的发挥，以及场外因素的影响。 常规赛的硝烟渐渐散去，接踵而来的是更加激烈的季后赛的征程。最终谁会笑到最后，让我们拭目以待。","tags":[{"name":"Data Analysis","slug":"Data-Analysis","permalink":"http://luojiaji.github.io/tags/Data-Analysis/"}]},{"title":"爬虫抓取高清壁纸","date":"2017-04-07T11:24:32.000Z","path":"2017/04/07/爬虫抓取高清壁纸/","text":"今天来抓取一下壁纸网站上的一些高清无码图片，并保存在本地。索要抓取的网站是https://unsplash.com/其实今天这篇不是完全意义上的原创，也是参考了网上的一片文章，原文40行动态爬虫代码搞定N张高清无码壁纸下载 之所以来抓这个图片网站主要是为了学习一下json的基本功能和用法，而且也发现了原文中一些小Bug，而且原文的代码是基于Python2.7的，有一些语法和库的使用跟我用的Python3.5的版本还是有些差别的。 Python版本:3.5.3今天用到的库有1.requests:用来获取网页的源代码2.json:用来解析抓到的json文件2.re:正则表达式模块，用来匹配特性的字符串2.time:显示当前时间和对程序进行休眠(感觉无所谓，可有可无) 1234import requestsimport jsonimport reimport time 首先跟往常一样先用Chrome浏览器的工具看一下，从Network中可以看到，这个网站的加载是一个类似于瀑布流的效果，当鼠标不断向下滚动的时候，网页会不断加载图片 图上显示的就是所对应加载的json文件，打开文件看一下，发现文件中包含当前页面中图片的id和下个一页面的网址，我们只要获取到这两个信息就能重复不断地抓取网页上的图片了。 原文里面提到，第一个url是:https://api.unsplash.com/napi/feeds/home但是我仔细找了半天也没找到这个文件，不过这个链接是有效的，而且确实是第一个页面的链接，那就拿来直接用吧(其实也无所谓，我们可以根据任意一个文件开始来顺次抓取相应的图片，只不过这样就不是我们在网页上看到的第一个图片了，并没有太大的影响) 找到相应文件的url，如图所示，不过需要注意的是文件当中的地址和我们需要的文件地址基本相同，只是地址中间多了一个/napi/ 当我们点击网页上某一幅图片的下载按钮的时候网页会跳转到下图的链接，并且发下中间那部分就是图片的id 因此，拿到图片的id之后就可以下载图片了。 分析到此结束，开始写程序! 首先构造url和header 123456789101112Header = &#123; 'authorization':'Client-ID d69927c7ea5c770fa2ce9a2f1e3589bd896454f7068f689d8e41a25b54fa6042', 'accept-version':'v1', 'Host':'unsplash.com', 'x-unsplash-client':'web', 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2986.0 Safari/537.36', 'Referer':'https://unsplash.com/', 'Connection':'keep-alive', 'Accept':'*/*'&#125;page_url = 'https://api.unsplash.com/napi/feeds/home' 然后通过url和header得到json文件，并解析文件中的next_page和photo信息1234html = requests.get(url=page_url,headers=Header)hjson = json.loads(html.text)next_page = hjson[u'next_page'] # 获取下一个页面的链接photos = hjson[u'photos'] # 获取当前页面的图片信息 然后用re模块得到下一个页面的链接，然后可以通过匹配的字符串构造出下一个页面的链接，并用于下一个页面的抓取。 得到photos之后可以用过循环依次获取每一张图片的链接地址，并将得到图片保存在本地，这些和上次抓取LOFTER上图片的方法基本上是相似的所以就不详细介绍了，看了代码应该就都懂了 123456789for each in photos: print(time.strftime('%X'),'正在保存第'+str(cnt)+'张图片...') bianhao = each['id'] pic = requests.get('https://unsplash.com/photos/'+bianhao+'/download?force=true') file = open('./pic/' +str(cnt) +'.jpg', 'wb') file.write(pic.content) file.close() cnt += 1 time.sleep(5) cnt同样是用来做计数和相应的文件名的。time.strftime(‘%X’)是显示当前的时间，主要是用来查看程序运行的时间以及保存每一幅图片所需要的时间，’%X’为显示格式-只显示小时分钟和秒每一次循环之后让程序暂定5秒钟，后来发现好像没什么用，本来图片下载就挺慢的了，再加一个延时就更慢了。。。 如果有地方不太了解，可以把相应的参数打印出来看一下程序运行的过程 这样就实现了一个页面的图片的抓取与保存，并别我们也从当前的文件中获取了下一个页面文件的链接，通过循环就可以实现多个页面图片的抓取与保存 我尝试抓了5个页面的图片，一共花了大约30分钟，因为图片比较大，下载了49张图片一共约500M，平均每张图片10M左右","tags":[{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://luojiaji.github.io/tags/爬虫/"}]},{"title":"爬虫抓取LOFTER上年度热门摄影作品","date":"2017-03-31T04:10:46.000Z","path":"2017/03/31/爬虫抓取LOFTER上年度热门摄影作品/","text":"今天来抓一下LOFTER上2016年度热门摄影作品的网页，并且把页面上的热门摄影作品保存在本地。Python版本:3.5.3代码用到的库有1.requests ：用来获取网页源代码2.BeautifulSoup：用来解析网页获得图片链接12import requestsfrom bs4 import BeautifulSoup 下面开始写代码首先要找到所需要抓取的网页地址，打开Chrome浏览器，找到需要抓取的网页 但是仅仅用url这一个参数还不能够得到网页的代码，还需要程序伪造成浏览器进行爬去，因此还要构造一个Headers作为参数和url一起传给requests，打开索要抓取的网页然后按F12在Network中可以找到Headers的参数 找到Headers之后，就可以构造一个Headers的参数来传递给requests来伪造浏览器进行网页的抓取1234567891011121314 page_url = 'http://www.lofter.com/selection?id=1334100&amp;type=2'Header = &#123; 'Accept':'', 'Accept-Encoding':'', 'Accept-Language':'', 'Cache-Control':'', 'Cookie':'', 'Host':'', 'Referer':'', 'Upgrade-Insecure-Requests':'', 'User-Agent':''&#125; 字典里的参数就是浏览器得到的参数(后来试了一下发现只要有Cookie好像就能抓到网页)，这里就不把参数贴出来了，不同的电脑参数应该是不一样的。 然后就是网页的抓取12html = requests.get(url=page_url, headers=Header)soup = BeautifulSoup(html.text,'html.parser') 抓取到所需要的页面之后然后开始在页面中找到我们想要的图片的地址信息首先找到所有照片的页面标签 然后在找到单独每个照片的标签 然后用BeautifulSoup找到相应的标签1pics = soup.find('div',class_='m-bd').find_all('div',class_='img') 打印得到的pics可以看到img标签中的src便是图片的地址 然后再获得标签中的信息，并且发现src中’?’之前的便是图片的地址，因此获取图片的地址1pic_url = i.find('img')['src'].split('?')[0] 打印pic_url可以得到 我们已经得到了图片的地址，下面就是获取图片的信息并且保存在本地1234img = requests.get(pic_url)f = open('img/' + str(count) + '.jpg', 'ab')f.write(img.content)f.close() 其中count是一个计数器并且为保存的照片命名。 最终打开文件夹，发现图片已经保存在了本地 类似的方法还可以获取年度热门绘画作品,年度热门美食作品,年度热门旅行作品等等 仔细看一下这些照片的质量还是蛮高的，完全可以拿来当壁纸用~哈哈","tags":[{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://luojiaji.github.io/tags/爬虫/"}]},{"title":"豆瓣电影top250不完全分析","date":"2017-03-26T10:45:01.000Z","path":"2017/03/26/豆瓣电影top250不完全分析/","text":"数据来源：截止到2017-3-24的豆瓣电影top250排行榜第1名:肖申克的救赎第2名:这个杀手不太冷第3名:霸王别姬第250名:黑鹰坠落 从评价来看最高分9.6 共有两部:肖申克的救赎、控方证人评分最低为8.1，只有一部:两小无猜平均评分:8.75分 评分包含电影最多的是8.7分，一共47部电影 按照评论人数来看评论人数最多的是:肖申克的救赎-803167人评价评论人数最少的是:城市之光-36978人评论平均评论人数:227831 按照导演来排序，其中不止一部作品上榜的有31位导演宫崎骏和克里斯托弗·诺兰以7部电影上榜并列第一位具体排名如下: 排名 导演 数量 1 宫崎骏HayaoMiyazaki 7 2 克里斯托弗·诺兰ChristopherNolan 7 3 史蒂文·斯皮尔伯格StevenSpielberg 5 4 詹姆斯·卡梅隆JamesCameron 5 5 大卫·芬奇DavidFincher 4 6 王家卫KarWaiWong 4 7 朱塞佩·托纳多雷GiuseppeTornatore 3 8 刘镇伟JeffreyLau 3 9 弗朗西斯·福特·科波拉FrancisFordCoppola 3 10 彼得·杰克逊PeterJackson 3 11 李安AngLee 3 12 姜文WenJiang 3 13 理查德·林克莱特RichardLinklater 3 14 理查德·柯蒂斯RichardCurtis 3 15 吴宇森JohnWoo 3 16 彼得·威尔PeterWeir 2 17 罗伯·莱纳RobReiner 2 18 岩井俊二ShunjiIwai 2 19 SergioLeone 2 20 中岛哲也TetsuyaNakashima 2 21 TimBurton 2 22 昆汀·塔伦蒂诺QuentinTarantino 2 23 雅克·贝汉JacquesPerrin/雅克·克鲁奥德JacquesCluzaud 2 24 保罗·格林格拉斯PaulGreengrass 2 25 黑泽明AkiraKurosawa 2 26 今敏SatoshiKon 2 27 森淳一JunichiMori 2 28 安德鲁·尼科尔AndrewNiccol 2 29 约翰·卡尼JohnCarney 2 30 雷德利·斯科特RidleyScott 2 31 邓肯·琼斯DuncanJones 2 其中纪录片有四部 排名 电影名 评分 评论人数 导演 41 海豚湾 9.3 173367 LouiePsihoyos 175 迁徙的鸟 9.1 48550 雅克·贝汉JacquesPerrin/雅克·克鲁奥德JacquesCluzaud 106 海洋 9 93788 雅克·贝汉JacquesPerrin/雅克·克鲁奥德JacquesCluzaud 244 寿司之神 8.8 72254 大卫·贾柏DavidGelb 按照年代分2000到2009年包含的电影最多 一共96部 最新上榜的是疯狂动物城(大话西游大圣娶亲2017年重上映不算在内)最老的电影是卓别林的城市之光(1931) 按照国家来看，因为有些电影不止一个国家，这里暂时用第一国家来对待，电影数量最多的国家是美国，一共123部，第二是中国大陆以及香港台湾地区，一共35部(大陆10部，香港20部，台湾5部)， 第三是日本，一共20部 国语电影榜单如下 大陆: 排名 电影名 评分 评论人数 导演 3 霸王别姬 9.5 567648 陈凯歌KaigeChen 33 鬼子来了 9.1 210345 姜文WenJiang 40 活着 9 242527 张艺谋YimouZhang 78 阳光灿烂的日子 8.7 249280 姜文WenJiang 79 让子弹飞 8.7 583572 姜文WenJiang 83 大闹天宫 9.2 88018 万籁鸣LaimingWan/唐澄ChengTang 165 可可西里 8.6 117203 陆川ChuanLu 168 心迷宫 8.6 133245 忻钰坤YukunXin 204 哪吒闹海 8.8 70254 严定宪DingxianYan/王树忱ShuchenWang 241 疯狂的石头 8.2 275105 宁浩HaoNing 香港: 排名 电影名 评分 评论人数 导演 15 大话西游之大圣娶亲 9.1 431249 刘镇伟JeffreyLau 26 无间道 9 369527 刘伟强/麦兆辉 32 大话西游之月光宝盒 8.9 367557 刘镇伟JeffreyLau 81 春光乍泄 8.7 219426 王家卫 82 射雕英雄传之东成西就 8.7 253540 刘镇伟JeffreyLau 85 重庆森林 8.6 296304 王家卫KarWaiWong 88 甜蜜蜜 8.7 214003 陈可辛PeterChan 119 倩女幽魂 8.6 222921 程小东Siu-TungChing 120 岁月神偷 8.6 284516 罗启锐AlexLaw 127 东邪西毒 8.6 229740 王家卫KarWaiWong 139 英雄本色 8.7 132531 吴宇森JohnWoo 146 纵横四海 8.7 126714 吴宇森JohnWoo 149 喜剧之王 8.4 271401 周星驰StephenChow/李力持Lik-ChiLee 160 花样年华 8.4 218309 王家卫KarWaiWong 169 唐伯虎点秋香 8.3 281209 李力持Lik-ChiLee 178 阿飞正传 8.5 158106 王家卫KarWaiWong 210 青蛇 8.4 194277 徐克HarkTsui 212 新龙门客栈 8.4 163691 李惠民RaymondLee 222 麦兜故事 8.5 116777 袁建滔ToeYuen 242 枪火 8.6 86252 杜琪峰JohnnieTo 台湾: 排名 电影名 评分 评论人数 导演 63 饮食男女 9 170861 李安AngLee 91 一一 8.9 140332 杨德昌 138 喜宴 8.8 121439 李安 201 牯岭街少年杀人事件 8.7 90814 杨德昌EdwardYang 221 蓝色大门 8.2 252424 易智言Chih-yenYee","tags":[{"name":"Data Analysis","slug":"Data-Analysis","permalink":"http://luojiaji.github.io/tags/Data-Analysis/"}]},{"title":"爬虫抓取豆瓣top250电影信息","date":"2017-03-24T03:53:30.000Z","path":"2017/03/24/爬虫抓取豆瓣top250电影信息/","text":"这篇文章主要介绍介绍用Python以及相关的库来抓取豆瓣电影top250排行榜中的相关电影信息，并保存在本地，用来后续的分析和处理。Python版本:3.5.3代码用到的库有:1.urllib.request:用来获取网页代码2.pandas:建立列表，保存网页信息3.BeautifulSoup:解析网页源代码，得到需要的电影信息4.time:让程序终止，防止访问过于频繁导致IP被禁1234import urllib.requestimport pandas as pdfrom bs4 import BeautifulSoupimport time 要得到网页信息，首先需要找到相应网页的url，打开Chrome浏览器，找到豆瓣电影top250的网页，发现网址是 往下翻了几页之后发现链接变成了 每页25部电影，一共需要10页便可以抓取全部250部电影的相关网页。通过验证start后面的参数为当前网页起始电影，因此构造url1url = 'https://movie.douban.com/top250?start='+str(25*page)+'&amp;filter=' 连接中page为传入的网页的页数。 然后用urllib库得到得想相应的网页源代码 1234request = urllib.request.Request(url)response = urllib.request.urlopen(request)html = response.read()html = html.decode('utf-8') 打印所得到的结果，发现网页已经被抓下来了 然后用beautifulsoup解析网页，按F10打开开发者模式，首先找到列表的主题位置，如图所示， 用find(),找到当前页面电影的信息，然后再找到每一步电影的信息的位置，如图 然后用find_all()保存在列表中，12soup = BeautifulSoup(html, \"html.parser\") # 解析网页movie_all = soup.find('div', class_='article').find_all('div', class_='info') 打印出的结果如下图所示 然后在上面得到的列表中找到电影的名称，评分，评论人数，导演，年代，国家，类型等信息，主要用到find()用来得到相应信息，然后用repalce()和split()去掉多余的字符。然后根据得到信息的格式将信息分类，调试的时候遇到问题可以直接把得到的结果打印出来然后根据打印的结果来修改代码，具体的实现过程就不详细解释了，直接上代码:1234567891011121314for movie in movie_all: name = movie.find('span', class_='title').get_text() # 获取电影名称 ratingnum = movie.find('div', class_='star').get_text().replace(\"\\n\", \" \") # 获取电影评分和评论人数 ratingnum = ratingnum.split(' ') rating = ratingnum[2] # 获取豆瓣评分 num = ratingnum[4] # 获取评论人数 url = movie.find('a')['href'] # 获取电影豆瓣链接 info = movie.find('p', class_='').get_text() # 获取电影信息 info = info.split('\\n') daoyan = info[1].replace(' ', '').split('\\xa0\\xa0\\xa0')[0].split(':')[1] # 获取导演信息 zhuyan = info[1].replace(' ', '').split('\\xa0\\xa0\\xa0')[1] # 获取主演信息 year = info[2].replace('\\xa0', '').split('/')[0].replace(' ', '').replace('\\xa0', '') # 获取年代信息 country = info[2].replace('\\xa0', '').split('/')[1] # 获取国家信息 type = info[2].replace('\\xa0', '').split('/')[2] # 获取类型信息 把得到的电影信息打印出来 为了保存电影的信息，需要先创建一个列表1df = pd.DataFrame(columns=['名称', '评分','评论人数', '导演','主演','年代','国家','类型','豆瓣链接']) 然后把得到的电影信息存到列表当中123456789df.loc[No] = &#123;'名称': name, '评分': rating, '评论人数': num, '导演': daoyan, '主演': zhuyan, '年代': year, '国家': country, '类型': type, '豆瓣链接':url&#125; 其中，No为电影的排名 最后将得到的列表存储在本地，便于以后的查看与分析。1df.to_csv(&apos;movie.csv&apos;) # 保存到CSV文件中 用Excel打开movie.csv文件可以看到，所需要的电影信息已经保存下来了。 爬虫的工作到这里就基本上结束了，得到的电影信息可以用来后续的分析和处理","tags":[{"name":"Python","slug":"Python","permalink":"http://luojiaji.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://luojiaji.github.io/tags/爬虫/"}]},{"title":"向往","date":"2017-03-11T07:41:53.000Z","path":"2017/03/11/向往/","text":"追求纸醉金迷的买醉却无法感受内心的伤悲 向往未来的光鲜明媚却不能忍受自己的卑微 向往璀璨的霓虹闪烁却无法承受身后的疲惫 感受着世界的喧嚣却不能抑制内心的寂寥 向往这世界的车水马龙却不知只是庸人自扰 感受着窗外的人流涌动却停不下自己慌乱的脚步","tags":[{"name":"随笔","slug":"随笔","permalink":"http://luojiaji.github.io/tags/随笔/"}]},{"title":"年少轻狂","date":"2017-03-01T09:38:55.000Z","path":"2017/03/01/年少轻狂/","text":"年少轻狂裹挟着青春的梦想深深浅浅的街巷有多少秘密在隐藏 被奔跑抛给身后的时光有人在浅吟低唱无需记录成长飞扬的永远飞扬 年少疯狂挥汗如雨的球场不着边际的幻想无忧无虑的时光总想独自去流浪 承载希望的课堂充满欢笑的操场那段美好的时光永远也不会遗忘 念念不忘的脸庞是谁的模样不到最后时刻谁也不许提前退场 年少的时光充满了向往有时会迷茫有时也会彷徨 青春已逝，年华未央前程似海，来日方长 承载着希望的梦想背上爱的行囊张开梦的翅膀奔向未知的远方 –写于高考之后","tags":[{"name":"随笔","slug":"随笔","permalink":"http://luojiaji.github.io/tags/随笔/"}]},{"title":"清单2016","date":"2016-12-31T02:00:00.000Z","path":"2016/12/31/清单2016/","text":"读书 那些年我们一起追过的球星——天下足球 明朝那些事(壹):洪武大帝——当年明月 黑客与画家——Paul Graham(美)阮一峰(译) 明朝那些事(贰):万国来朝——当年明月 明朝那些事(叁):妖孽宫廷——当年明月 明朝那些事(肆):粉饰太平——当年明月 明朝那些事(伍):帝国飘摇——当年明月 明朝那些事(陆):日暮西山——当年明月 明朝那些事(柒):大结局——当年明月 日和手帖001:我们终究是一个人 ——苏静 日和手帖002:生活整理术 ——苏静 日和手帖003:打包你的人生 ——苏静 日和手帖004:跟自己说声晚安 ——苏静 日和手帖005:日用即道——苏静 日和手帖006:人生有一百万种活法 ——苏静 日和手帖007:每间屋子都是一个小宇宙 ——苏静 岛上书店——加布瑞埃拉·泽文(美) 我是爬行者——江一燕 此生未完成——于娟 城南旧事——林海音 褚时健传——周桦 传奇在路上——张佳玮 丈量世界——丹尼尔·凯曼(德) 无声告白——伍绮诗(美) 暗时间——刘未鹏 科比：黄金年代——张佳玮 你要相信没有到不了的明天——卢思浩 愿有人陪你颠沛流离——卢思浩 影视 惊天魔盗团2 海洋之歌 X战警：天启 北京遇上西药图之不二情书 路边野餐——毕赣 谍影重重5 ——格里戈拉斯 我们诞生在中国 你的名字——新海诚 釜山行 间谍之桥 梦想改造家第一季 梦想改造家第二季 梦想改造家第三季 湄公河行动 垫底辣妹 机械师2：复活 追击者 踏雪寻梅 寿司之神 瑞士军刀男 了不起的匠人 饮食男女——李安 推手——李安 喜宴——李安 比利林恩的中场休息——李安 但丁密码 侣行第一季 侣行第二季 侣行第三季 家园 斯诺登——斯通 边境风云——程耳 罗曼蒂克消亡史——程耳 小戏骨 白蛇传","tags":[{"name":"随笔","slug":"随笔","permalink":"http://luojiaji.github.io/tags/随笔/"}]}]